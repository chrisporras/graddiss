# -*- coding: utf-8 -*-
"""GradientDissentersHackathon2023.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/chrisporras/graddiss/blob/main/GradientDissentersHackathon2023.ipynb

# Hackathon 2023
ML for Biomedical Data Science
Team Gradient Dissenters

Members: Audrey Lee, Christian Porras, Joy Jiang

## Description

What worked for us


What didn't work for us
"""

!nvidia-smi

"""## Mount Google Drive
To save and access saved models

For saving and loading models
"""

import google.colab

from google.colab import drive
drive.mount('/content/drive')

save_models_dir = "/content/drive/MyDrive/ML for BDS/Hackathon - graddiss/"

"""## Install and load Kaggle mammography"""

# Clone project git repo
!git clone https://github.com/chrisporras/graddiss.git

# install Kaggle public api
! pip install -q kaggle
# Choose the kaggle.json file that you downloaded
! mkdir ~/.kaggle
! cp ./graddiss/kaggle.json ~/.kaggle/
# Make directory named kaggle and copy kaggle.json file there.
!chmod 600 ~/.kaggle/kaggle.json
#Change the permissions of the file.
! kaggle datasets list

!kaggle competitions download -c mammography-image-patch-classification-2023

# data directory
!mkdir data
# unzip data there,
!unzip mammography-image-patch-classification-2023.zip -d data

"""## Explore and prepare data"""

# Configuration class
class Config:
    resize = False
    batch_size = 32
    numworkers = 0

!pip install torchvision

!printf 'y\ny\ny\n' | conda install pytorch==1.12.1 torchvision==0.13.1 torchaudio==0.12.1 cudatoolkit=11.6 -c pytorch -c conda-forge

import os
from PIL import Image
# import torchvision
# from skimage import io, img_as_float32
# import numpy as np
# import torch
# from skimage.io import imread
# from skimage.util import img_as_ubyte
# from skimage import exposure
# import cv2

import torchvision

!python -m pip install -U scikit-image

!pip install opencv-python

from skimage import io, img_as_float32
import numpy as np
import torch
from skimage.io import imread
from skimage.util import img_as_ubyte
from skimage import exposure
import cv2

import os
from PIL import Image
import torchvision
from skimage import io, img_as_float32
import numpy as np
import torch
from skimage.io import imread
from skimage.util import img_as_ubyte
from skimage import exposure
import cv2

class ToTensor3D(object):
    """Convert ndarrays in sample to Tensors."""
    def __call__(self, image):
        image = img_as_float32(image)

        # The following two lines are to duplicate the grayscale image onto
        # 3 channels. That's to make the input compatible with those models
        # trained on color images. If you don't use pretrained models, you can
        # delete these two lines.
        new_shape = (3,) + image.shape
        dup_img = np.broadcast_to(image, new_shape)

        return torch.from_numpy(dup_img.copy())

class CustomImageDataset(torch.utils.data.Dataset):
    """Make a custom dataset for the mammography patches"""  
    def __init__(self, image_dir, df, transform=None, testset=False):
        # Create one iterable that can be __getitemed__
        self.image_dir = image_dir
        self.df = df
        self.transform = transform # added transform
        self.testset = testset # indicates if dataset is the test set

    def __len__(self): # Denotes the total number of samples
        # return self.df.shape[0] # orig
        return len(self.df) # try this

    def normalize(self, image):
      """
      Apply image-level normalization for pre-processing.
      For more background, read here: 
      https://towardsdatascience.com/train-a-neural-network-to-detect-breast-mri-tumors-with-pytorch-250a02be7777
      https://scikit-image.org/docs/stable/user_guide/data_types.html
      https://www.di.ubi.pt/~lfbaa/pubs/recpad2017b.pdf 
      """
      # OLD
      # image = image.astype(float) * 255. / image.max()
      # # Convert float --> uint8. This maps pixel intensities from 0 to 255
      # # Source: above and here: https://scikit-image.org/docs/stable/user_guide/data_types.html
      # image = image.astype(np.uint8)

      # NEW
      # Convert to 8-bit uint (going from [0 to 65535] to [0 to 255])
      # I read the skimage page more closely, where it cautions against using
      # astype. It calls for the below usage instead. These functions convert 
      # images to the desired dtype and properly rescale their values:
      image = img_as_ubyte(image) 

      # Histogram equalization --> poor val acc
      # image = exposure.equalize_hist(image) # skimage implementation
      # image = cv2.equalizeHist(image) # OpenCV implementation

      # Subtract image mean and divide by standard deviation --> poor val acc
      # image_mean = image.mean()
      # image_std = image.std()
      # image = (image - image_mean) / image_std

      return image

    def __getitem__(self, index): # Generates one sample of data
        
        # added this
        if torch.is_tensor(index):
          index = index.tolist()

        # Goes to image_tensor below
        image_path = os.path.join(self.image_dir, self.df.iloc[index]['img_name'])
        # image_og = Image.open(image_path)
        image_og = imread(image_path, as_gray=True) # read in png or jpg

        # Apply image-level normalization for preprocessing
        image = self.normalize(image_og)

        # Convert to 3D tensor
        t = ToTensor3D()
        image = t(image)

        if self.transform:
          image = self.transform(image)
          # image = self.transform(image_og)

        # Since the test set has no label_num, we get the image id
        if not(self.testset):
          label = torch.tensor(self.df.iloc[index]['label_num'],dtype=torch.long)
        else:
          label = self.df.iloc[index]['id'] 

        # # Resize, depending on the network ---> CAN REMOVE
        # if Config.resize:
        #     resize = torchvision.transforms.Resize(384)
        #     image = resize(image)
        
        return image, label

import pandas as pd

# New numeric labels.
labels_num = {'background': 0, 'calc_ben': 1, 'calc_mal': 2, 
              'mass_ben': 3, 'mass_mal': 4}

# Read image metadata
traindf = pd.read_csv('data/train.csv') 
traindf['label_num'] = traindf['label'].map(labels_num)

testdf = pd.read_csv('data/test.csv')

# print(traindf)
# print()
# print(testdf)

# Get how many in each label category
traindf.groupby(["label_num"]).count()

"""Visualize the distribution of the raw data. Notice the class imbalance such that the majority of the data is "background"."""

!pip install seaborn

import seaborn as sns
import matplotlib.pyplot as plt

# Visualize the different classes
fig, ax = plt.subplots()
ax = sns.countplot(data=traindf,
                   x="label")

# For more ease getting word labels from numerical predictions later
num_labels = {v:k for k,v in labels_num.items()}
num_labels

"""Consider the data augmentation steps we would like to apply to the mammography patches. 

Here are some helpful resources:
*   https://www.kaggle.com/competitions/rsna-breast-cancer-detection/discussion/372567
*   https://www.nature.com/articles/s41598-019-48995-4#Sec2


"""

from torch.utils.data import TensorDataset, DataLoader, WeightedRandomSampler
from torchvision import datasets, transforms

from torch.utils.data import TensorDataset, DataLoader, WeightedRandomSampler
from torchvision import datasets, transforms

# First, work with some minimal transforms
initial_transforms = transforms.Compose([
      transforms.Resize((224,224)),
      transforms.Normalize([0, 0, 0], [1, 1, 1])
      ])

# First, create the original train dataset without transforms
untransformed_train_dataset = CustomImageDataset('data/train_imgs', traindf,
                                                 transform = initial_transforms)
# Create the original val dataset, which is basically a copy of the 
# orig_train_dataset, but with a different set of transformations
untransformed_val_dataset = CustomImageDataset('data/train_imgs', traindf,
                                                 transform = initial_transforms)

# Split the orig_train_dataset into preliminary train and val datasets
train_size = int(0.9 * len(untransformed_train_dataset))
val_size = len(untransformed_train_dataset) - train_size
temp_train_dataset, temp_val_dataset = torch.utils.data.random_split(untransformed_train_dataset, 
                                                     [train_size, val_size])

# Keep track of the indices for each dataset for later
train_indices = temp_train_dataset.indices
val_indices = temp_val_dataset.indices

image_loader = DataLoader(temp_train_dataset, batch_size=Config.batch_size,
                          shuffle=False, num_workers=Config.numworkers,
                          pin_memory=True)

image_loader

torch.__version__

def batch_mean_and_sd(loader):
    """
    Helper function to get mean and std of dataset using the dataloader.
    See: https://www.google.com/url?q=https://www.binarystudy.com/2022/04/how-to-normalize-image-dataset-inpytorch.html&sa=D&source=editors&ust=1679883727112650&usg=AOvVaw0FvYMWXTnXnGFI5RooK_pJ
    """
    cnt = 0
    fst_moment = torch.empty(3)
    snd_moment = torch.empty(3)

    for images, _ in loader:
        b, c, h, w = images.shape
        nb_pixels = b * h * w
        sum_ = torch.sum(images, dim=[0, 2, 3])
        sum_of_square = torch.sum(images ** 2,
                                  dim=[0, 2, 3])
        fst_moment = (cnt * fst_moment + sum_) / (
                      cnt + nb_pixels)
        snd_moment = (cnt * snd_moment + sum_of_square) / (
                            cnt + nb_pixels)
        cnt += nb_pixels

    mean, std = fst_moment, torch.sqrt(snd_moment - fst_moment ** 2)        
    return mean,std
  
train_ds_mean, train_ds_std = batch_mean_and_sd(image_loader)
print("mean and std: \n", train_ds_mean, train_ds_std)

from torchvision import datasets, transforms

# Define transforms I want to use
data_transforms = {
  "train": transforms.Compose([
      transforms.Resize((224,224)),
      # transforms.Resize(256),
      # transforms.CenterCrop(224),
      # transforms.RandomResizedCrop(224), # Some data augmentation --> get rid of? Seems to get padded areas
      # transforms.Normalize(train_ds_mean, [1., 1., 1.]),
      transforms.RandomHorizontalFlip(), # Some data augmentation
      transforms.RandomVerticalFlip(), # Data augmentation
      transforms.RandomRotation(25), # Data augmentation
      # transforms.Normalize(train_ds_mean, [1., 1., 1.])
      transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),
      # transforms.RandomAutocontrast(),
      transforms.Normalize(train_ds_mean, train_ds_std)
      ]),

  "val": transforms.Compose([
      transforms.Resize((224,224)),
      transforms.Normalize(train_ds_mean, train_ds_std)
  ]),
  "test": transforms.Compose([
      transforms.Resize((224,224)),
      transforms.Normalize(train_ds_mean, train_ds_std)
  ])
}

"""Before addressing class imbalance, note how each batch had so much more "background"
"""

# BEFORE ADDRESSING CLASS IMBALANCE
# Make datasets 

# train_dataset = CustomImageDataset('data/train_imgs', traindf, 
#                                    transform=data_transforms["train"])

# train_size = int(0.5 * len(train_dataset))
# val_size = len(train_dataset) - train_size
# train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, 
#                                                      [train_size, val_size])

# test_dataset = CustomImageDataset('data/test_imgs', testdf)

# # Make dataloaders
# train_loader = torch.utils.data.DataLoader(train_dataset, Config.batch_size, 
#                                            shuffle=True, num_workers=Config.numworkers)

# val_loader = torch.utils.data.DataLoader(val_dataset, Config.batch_size, 
#                                          shuffle=True, num_workers=Config.numworkers)

# # Build batches - check distribution of classes per batch
# for step, (img,label) in enumerate(train_loader):
#   print("batch index {}, 0/1/2/3/4: {}/{}/{}/{}/{}".format(step,
#                                                            len(np.where(label.numpy() == 0)[0]),
#                                                            len(np.where(label.numpy() == 1)[0]),
#                                                            len(np.where(label.numpy() == 2)[0]),
#                                                            len(np.where(label.numpy() == 3)[0]),
#                                                            len(np.where(label.numpy() == 4)[0]))
#   )

# # Putting these into a dict format for compatibility with the train function later
# dataloaders = {"train": train_loader,
#                "val": val_loader
#                }

# dataset_sizes = {"train": len(train_dataset),
#                  "val": len(val_dataset)
#                  }

"""### Address class imbalance
We can address class imbalance by creating weights for each class and then doing weighted random sampling.

Side note: I will split the original train set into 90% train and 10% validation. There is a tradeoff between how representative the validation accuracy is and how much data my models can train on.
"""

from torch.utils.data import TensorDataset, DataLoader, WeightedRandomSampler

# Want to create separate training and validation datasets, each having their
# own transformations. We also want to prevent leakage!

# First, create the original train dataset
orig_train_dataset = CustomImageDataset('data/train_imgs', traindf, 
                                   transform=data_transforms["train"])
# Create the original val dataset, which is basically a copy of the 
# orig_train_dataset, but with a different set of transformations
orig_val_dataset = CustomImageDataset('data/train_imgs', traindf, 
                                   transform=data_transforms["val"])

# Split the orig_train_dataset into preliminary train and val datasets
# train_size = int(0.9 * len(orig_train_dataset))
# val_size = len(orig_train_dataset) - train_size
# train_dataset, temp_val_dataset = torch.utils.data.random_split(orig_train_dataset, 
#                                                      [train_size, val_size])

# Get the indices for the data that belongs to the temp_val_dataset, and use it 
# to subset the orig_val_dataset. Since we are not shuffling anything, the 
# indices should be the same between train and val.
train_dataset = torch.utils.data.Subset(orig_train_dataset, train_indices)
val_dataset = torch.utils.data.Subset(orig_val_dataset, val_indices)

test_dataset = CustomImageDataset('data/test_imgs', testdf, 
                                  transform=data_transforms["test"],
                                  testset=True)

# Making sure there is no overlap to avoid data leakage into val --> should be False if no overlap
bool(set(val_dataset.indices) & set(train_dataset.indices))

# Addressing class imbalance by weighting samples 
# Adjust sample weights within each batch to balance the five classes.
y_train = [orig_train_dataset.df.loc[i]["label_num"] for i in train_dataset.indices]
class_sample_count = np.array([len(np.where(y_train == t)[0]) for t in np.unique(y_train)])
weight = 1. / class_sample_count
samples_weight = np.array([weight[t] for t in y_train])
samples_weight = torch.from_numpy(samples_weight)

# sampler = WeightedRandomSampler(samples_weight.type('torch.DoubleTensor'), len(samples_weight))
sampler = WeightedRandomSampler(samples_weight, len(samples_weight))

# Remake the train dataloader
train_loader = DataLoader(train_dataset, sampler=sampler, batch_size=Config.batch_size,
                          num_workers=Config.numworkers)
val_loader = torch.utils.data.DataLoader(val_dataset, Config.batch_size, 
                                         shuffle=True, num_workers=Config.numworkers)
test_loader = torch.utils.data.DataLoader(test_dataset, Config.batch_size, 
                                         shuffle=False)
# Can uncomment to see the distribution of each batch
# # Build batches - check distribution of classes per batch
# for step, (img,label) in enumerate(train_loader):
#   print("batch index {}, 0/1/2/3/4: {}/{}/{}/{}/{}".format(step,
#                                                            len(np.where(label.numpy() == 0)[0]),
#                                                            len(np.where(label.numpy() == 1)[0]),
#                                                            len(np.where(label.numpy() == 2)[0]),
#                                                            len(np.where(label.numpy() == 3)[0]),
#                                                            len(np.where(label.numpy() == 4)[0]))
#   )


# Putting these into a dict format for easier use later
dataloaders = {"train": train_loader,
               "val": val_loader,
               "test": test_loader
               }

dataset_sizes = {"train": len(train_dataset),
                 "val": len(val_dataset),
                 "test": len(test_dataset)
                 }

def imshow(inp, title=None):
    """Imshow for Tensor."""
    inp = inp.numpy().transpose((1, 2, 0))
    mean = train_ds_mean.numpy()
    std = train_ds_std.numpy()
    
    # mean = np.array([0.485, 0.456, 0.406])
    # std = np.array([0.229, 0.224, 0.225])
    inp = std * inp + mean
    inp = np.clip(inp, 0, 1)
    plt.imshow(inp)
    if title is not None:
        plt.title(title)
    plt.pause(0.001)  # pause a bit so that plots are updated

device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
print("Using device: ", device)

device = torch.device("cuda")

torch.cuda.is_available()

!nvidia-smi

torch.__version__

import matplotlib.pyplot as plt
from skimage import io, img_as_float32
import numpy as np
import torch

# To get one image:
# temp_img, temp_lab = train_dataset[0]
# print(temp_img.shape)
# imshow(temp_img, title=num_labels[temp_lab.item()])
# plt.title(num_labels[temp_lab.item()])

# To get a batch of images
temp_img, temp_lab = next(iter(dataloaders["train"]))
# Make a grid from batch
out = torchvision.utils.make_grid(temp_img)
imshow(out)
# imshow(out, title=[num_labels[x.item()] for x in temp_lab])
labels_list = [num_labels[x.item()] for x in temp_lab]
print(labels_list)
plt.show()

# To get a batch of images
temp_img, temp_lab = next(iter(dataloaders["val"]))
# Make a grid from batch
out = torchvision.utils.make_grid(temp_img)
imshow(out)
# imshow(out, title=[num_labels[x.item()] for x in temp_lab])
labels_list = [num_labels[x.item()] for x in temp_lab]
print(labels_list)
plt.show()

# To get a batch of images
temp_img, temp_lab = next(iter(dataloaders["test"]))
# Make a grid from batch
out = torchvision.utils.make_grid(temp_img)
imshow(out)
# imshow(out, title=[num_labels[x.item()] for x in temp_lab])

plt.show()

"""## Setting up training functions

Resources:
* https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html
"""

from __future__ import print_function, division

import torch
import torch.nn as nn
import torch.optim as optim
from torch.optim import lr_scheduler
import torch.backends.cudnn as cudnn
import numpy as np
import torchvision
from torchvision import datasets, models, transforms
import matplotlib.pyplot as plt
import time
import os
import copy
import random

cudnn.benchmark = True
plt.ion()   # interactive mode

def train_model(model, criterion, optimizer, scheduler, num_epochs=25):
    since = time.time()

    best_model_wts = copy.deepcopy(model.state_dict())
    best_acc = 0.0

    # # For book-keeping the losses and accuracies
    # epoch_ls = []
    # train_loss_ls = []
    # val_loss_ls = []
    # train_acc_ls = []
    # val_acc_ls = []

    for epoch in range(num_epochs):
        print(f'Epoch {epoch}/{num_epochs - 1}')
        print('-' * 10)

        # Each epoch has a training and validation phase
        for phase in ['train', 'val']:
            if phase == 'train':
                model.train()  # Set model to training mode
            else:
                model.eval()   # Set model to evaluate mode

            running_loss = 0.0
            running_corrects = 0

            # Iterate over data.
            for inputs, labels in dataloaders[phase]:
                inputs = inputs.to(device)
                labels = labels.to(device)

                # zero the parameter gradients
                optimizer.zero_grad()

                # forward
                # track history if only in train
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    _, preds = torch.max(outputs, 1)
                    loss = criterion(outputs, labels)

                    # backward + optimize only if in training phase
                    if phase == 'train':
                        loss.backward()
                        optimizer.step()

                # statistics
                running_loss += loss.item() * inputs.size(0)
                running_corrects += torch.sum(preds == labels.data)

            if phase == 'train':
                scheduler.step()

            epoch_loss = running_loss / dataset_sizes[phase]
            epoch_acc = running_corrects.double() / dataset_sizes[phase]

            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')

            # deep copy the model
            if phase == 'val' and epoch_acc > best_acc:
                best_acc = epoch_acc
                best_model_wts = copy.deepcopy(model.state_dict())

        print()

    time_elapsed = time.time() - since
    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')
    print(f'Best val Acc: {best_acc:4f}')

    # load best model weights
    model.load_state_dict(best_model_wts)
    return model

def visualize_model(model, num_images=6):
    was_training = model.training
    model.eval()
    images_so_far = 0
    fig = plt.figure()

    with torch.no_grad():
        for i, (inputs, labels) in enumerate(dataloaders['val']):
            inputs = inputs.to(device)
            labels = labels.to(device)

            outputs = model(inputs)
            _, preds = torch.max(outputs, 1)

            for j in range(inputs.size()[0]):
                images_so_far += 1
                ax = plt.subplot(num_images//2, 2, images_so_far)
                ax.axis('off')
                ax.set_title(f'predicted: {num_labels[preds[j]]}')
                imshow(inputs.cpu().data[j])

                if images_so_far == num_images:
                    model.train(mode=was_training)
                    return
        model.train(mode=was_training)

"""# Best ResNet18 Results"""

model_ft = models.resnet18(weights="DEFAULT")
num_ftrs = model_ft.fc.in_features

model_ft.fc = nn.Linear(num_ftrs, 5)

model_ft = model_ft.to(device)

criterion = nn.CrossEntropyLoss()

# Observe that all parameters are being optimized
optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.0001)

# Decay LR by a factor of 0.1 every 10 epochs
exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)

model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,
                       num_epochs=25)

# Save the best model
torch.save(model_ft.state_dict(), save_models_dir+'best_resnet18_dsnormalized.pt')

"""# Best ResNet50 Results
Read from bottom up, since most updated model training is higher up.

## With new TRAIN DATASET mean std normalization
"""

model_ft = models.resnet50(weights="DEFAULT")
num_ftrs = model_ft.fc.in_features

model_ft.fc = nn.Linear(num_ftrs, 5)

model_ft = model_ft.to(device)

criterion = nn.CrossEntropyLoss()

# Observe that all parameters are being optimized
optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.0001)

# Decay LR by a factor of 0.1 every 10 epochs
exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)

model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,
                       num_epochs=25)

# Save the best model
torch.save(model_ft.state_dict(), save_models_dir+'best_resnet50_dsnormalized.pt')

"""# Best VGG16_BN Results

## VGG16_BN, 25 epochs
"""

model_ft = models.vgg16_bn(weights="DEFAULT")
# num_ftrs = model_ft.fc.in_features

num_ftrs = model_ft.classifier[6].in_features # the 6 gets me to the linear layer of VGG
model_ft.classifier[6] = nn.Linear(num_ftrs, 5)


model_ft = model_ft.to(device)

criterion = nn.CrossEntropyLoss()

# Observe that all parameters are being optimized
optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.0001)

# Decay LR by a factor of 0.1 every 7 epochs
exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)

model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,
                       num_epochs=25)

# Save the best model
torch.save(model_ft.state_dict(), save_models_dir+'best_vgg16_new.pt')

# Save checkpoint
torch.save({'epoch': 25,
            'model_state_dict': model_ft.state_dict(),
            'optimizer_state_dict': optimizer_ft.state_dict(),
            }, save_models_dir+'best_vgg16_new_CHECKPOINT25.pt')

"""# Best VGG19 Results

## VGG19_BN for 25 epochs
"""

model_ft = models.vgg19_bn(weights="DEFAULT")
num_ftrs = model_ft.classifier[6].in_features # the 6 gets me to the linear layer of VGG
model_ft.classifier[6] = nn.Linear(num_ftrs, 5)

model_ft = model_ft.to(device)

criterion = nn.CrossEntropyLoss()

# Observe that all parameters are being optimized
optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.0001)

# Decay LR by a factor of 0.1 every 7 epochs
exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)

model_ft

model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,
                       num_epochs=25)

torch.save(model_ft.state_dict(), save_models_dir+'best_vgg19_new.pt')

# Save checkpoint
torch.save({'epoch': 25,
            'model_state_dict': model_ft.state_dict(),
            'optimizer_state_dict': optimizer_ft.state_dict(),
            }, save_models_dir+'best_vgg19_new_CHECKPOINT25.pt')

"""# Best EfficientNet Results (EfficientNet B3)"""

efficentnet_model = models.efficientnet_b3(weights="DEFAULT")
num_ftrs = efficentnet_model.classifier[1].in_features
# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).
efficentnet_model.classifier[1] = nn.Linear(num_ftrs, 5)

efficentnet_model = efficentnet_model.to(device)

criterion = nn.CrossEntropyLoss()

# Observe that all parameters are being optimized
optimizer_ft = optim.Adam(efficentnet_model.parameters(), lr=0.0001)

# Decay LR by a factor of 0.1 every (step_size) epochs
exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)# Save the best model

efficentnet_model = train_model(efficentnet_model, criterion, optimizer_ft, exp_lr_scheduler,
                       num_epochs=25)

# Save the best model
torch.save(efficentnet_model.state_dict(), save_models_dir+'best_efficientnetb3_model.pt')

# Save checkpoint
torch.save({'epoch': 25,
            'model_state_dict': efficentnet_model.state_dict(),
            'optimizer_state_dict': optimizer_ft.state_dict(),
            }, save_models_dir+'best_efficientnetb3_CHECKPOINT25.pt')

"""# Training Ensemble (Stacking/blending)

## Stacked ensemble
"""

class load_VGG19_BN(nn.Module):
    def __init__(self):
        super(load_VGG19_BN, self).__init__()
        self.model = torchvision.models.vgg19_bn()
        #print(self.model)
        num_ftrs = self.model.classifier[6].in_features
        self.model.classifier[6] = nn.Linear(num_ftrs, 5)
        self.model.load_state_dict(torch.load(save_models_dir+'best_vgg19_new.pt'))
        # self.model.eval()
    def forward(self, x):        
        return self.model(x)

class load_VGG16_BN(nn.Module):
    def __init__(self):
        super(load_VGG16_BN, self).__init__()
        self.model = torchvision.models.vgg16_bn()
        #print(self.model)
        num_ftrs = self.model.classifier[6].in_features
        self.model.classifier[6] = nn.Linear(num_ftrs, 5)
        self.model.load_state_dict(torch.load(save_models_dir+'best_vgg16_new.pt'))
        # self.model.eval()         
    def forward(self, x):        
        return self.model(x)

class load_ResNet50(nn.Module):
    def __init__(self):
        super(load_ResNet50, self).__init__()
        self.model = torchvision.models.resnet50()
        #print(self.model)
        num_ftrs = self.model.fc.in_features
        self.model.fc = nn.Linear(num_ftrs, 5)
        self.model.load_state_dict(torch.load(save_models_dir+'best_resnet50_dsnormalized.pt'))
        # self.model.eval()        
    def forward(self, x):        
        return self.model(x)

class StackedEnsemble(nn.Module):
    """
    Stacked ensembling / blending ensemble technique
    """

    def __init__(self,  modelA, modelB, modelC):
        super(StackedEnsemble, self).__init__()
        
        self.modelA = modelA
        self.modelB = modelB
        self.modelC = modelC

        self.classifier = nn.Linear(5*3, 5)
                
    def forward(self, x):
        # self.modelA.eval()  
        x1 = self.modelA(x)

        # self.modelB.eval()
        x2 = self.modelB(x)

        # self.modelC.eval()
        x3 = self.modelC(x)

        x = torch.cat((x1, x2, x3), dim=1)
        out = self.classifier(x)
        return out

# ResNet50
resnet50_model = load_ResNet50()
# num_ftrs = resnet50_model.fc.in_features
# resnet50_model.fc = nn.Linear(num_ftrs, 5)
# resnet50_model.load_state_dict(torch.load(save_models_dir+'best_resnet50_dsnormalized.pt'))
# resnet50_model = resnet50_model.to(device)

# VGG16_BN
vgg16_bn_model = load_VGG16_BN()
# num_ftrs = vgg16_bn_model.classifier[6].in_features
# vgg16_bn_model.fc = nn.Linear(num_ftrs, 5)
# vgg16_bn_model.load_state_dict(torch.load(save_models_dir+'best_vgg16.pt'))
# vgg16_bn_model = vgg16_bn_model.to(device)

# VGG19_BN
vgg19_bn_model = load_VGG19_BN()
# num_ftrs = vgg19_bn_model.classifier[6].in_features
# vgg19_bn_model.fc = nn.Linear(num_ftrs, 5)
# vgg19_bn_model.load_state_dict(torch.load(save_models_dir+'best_vgg19_bn_model.pt'))
# vgg19_bn_model = vgg19_bn_model.to(device)

vgg19_bn_model

vgg16_bn_model

resnet50_model

# models = [resnet50_model, vgg16_bn_model, vgg19_bn_model]
stacked_ensemble_model = StackedEnsemble(resnet50_model, vgg16_bn_model, vgg19_bn_model)

for param in stacked_ensemble_model.parameters():
  param.requires_grad = False

# Training for only this layer - what weights and biases can best combine each 
# sub-model prediction?
for param in stacked_ensemble_model.classifier.parameters():
  param.requires_grad = True

stacked_ensemble_model = stacked_ensemble_model.to(device)

criterion = nn.CrossEntropyLoss()

# Observe that all parameters are being optimized
optimizer = optim.Adam(stacked_ensemble_model.parameters(), lr=0.0001)

# Decay LR by a factor of 0.1 every 7 epochs
exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)

stacked_ensemble_model = train_model(stacked_ensemble_model , criterion, optimizer, exp_lr_scheduler,
                       num_epochs=25)

# Save the best model
torch.save(stacked_ensemble_model.state_dict(), save_models_dir+'stacked_ensemble_attempt2_vgg16bn_vgg19bn_resnet50.pt')

"""# Entry Submissions"""

def model_test(model):
  results = {}
  
  model.to(device)
  with torch.no_grad():
    for i, (inputs, labels) in enumerate(dataloaders['test']):
      inputs = inputs.to(device)
      # labels = labels.to(device)
      # print(len(labels))

      outputs = model(inputs)
      _, preds = torch.max(outputs, 1)

      # print(preds)
      preds_list = [num_labels[x.item()] for x in preds]
      # print(len(preds_list))

      for i in range(len(labels)):
        results[labels[i]] = preds_list[i]

  return results

def ensemble_averaging(modelA, modelB, modelC):
  """
  This function implements a simple ensemble technique of averaging model 
  predictions to directly make a prediction
  """
  results = {}
  
  modelA.to(device)
  modelB.to(device)
  modelC.to(device)

  with torch.no_grad():
    for i, (inputs, labels) in enumerate(dataloaders['test']):
      inputs = inputs.to(device)
      # labels = labels.to(device)
      # print(len(labels))

      # outputs = model(inputs)
      out_modelA = modelA(inputs)
      print(out_modelA.shape)
      out_modelB = modelB(inputs)
      print(out_modelB.shape)
      out_modelC = modelC(inputs)
      print(out_modelC.shape)

      outputs = (out_modelA + out_modelB + out_modelC) / 3
      print("\nAveraged outputs for this batch:\n{}\n".format(outputs))
      _, preds = torch.max(outputs, 1)

      # print(preds)
      preds_list = [num_labels[x.item()] for x in preds]
      # print(len(preds_list))

      for i in range(len(labels)):
        results[labels[i]] = preds_list[i]

  return results

"""For 4 models"""

def ensemble_averaging(modelA, modelB, modelC, modelD):
  """
  This function implements a simple ensemble technique of averaging model 
  predictions to directly make a prediction
  """
  results = {}
  
  modelA.to(device)
  modelB.to(device)
  modelC.to(device)
  modelD.to(device)

  with torch.no_grad():
    for i, (inputs, labels) in enumerate(dataloaders['test']):
      inputs = inputs.to(device)
      # labels = labels.to(device)
      # print(len(labels))

      # outputs = model(inputs)
      out_modelA = modelA(inputs)
      print(out_modelA.shape)
      out_modelB = modelB(inputs)
      print(out_modelB.shape)
      out_modelC = modelC(inputs)
      print(out_modelC.shape)
      out_modelD = modelD(inputs)
      print(out_modelD.shape)

      outputs = (out_modelA + out_modelB + out_modelC + out_modelD) / 4
      print("\nAveraged outputs for this batch:\n{}\n".format(outputs))
      _, preds = torch.max(outputs, 1)

      # print(preds)
      preds_list = [num_labels[x.item()] for x in preds]
      # print(len(preds_list))

      for i in range(len(labels)):
        results[labels[i]] = preds_list[i]

  return results

"""For 5 models"""

def ensemble_averaging(modelA, modelB, modelC, modelD, modelE):
  """
  This function implements a simple ensemble technique of averaging model 
  predictions to directly make a prediction
  """
  results = {}
  
  modelA.to(device)
  modelB.to(device)
  modelC.to(device)
  modelD.to(device)
  modelE.to(device)

  with torch.no_grad():
    for i, (inputs, labels) in enumerate(dataloaders['test']):
      inputs = inputs.to(device)
      # labels = labels.to(device)
      # print(len(labels))

      # outputs = model(inputs)
      out_modelA = modelA(inputs)
      print(out_modelA.shape)
      out_modelB = modelB(inputs)
      print(out_modelB.shape)
      out_modelC = modelC(inputs)
      print(out_modelC.shape)
      out_modelD = modelD(inputs)
      print(out_modelD.shape)
      out_modelE = modelE(inputs)
      print(out_modelE.shape)

      outputs = (out_modelA + out_modelB + out_modelC + out_modelD + out_modelE) / 5
      # print("\nAveraged outputs for this batch:\n{}\n".format(outputs))
      _, preds = torch.max(outputs, 1)

      # print(preds)
      preds_list = [num_labels[x.item()] for x in preds]
      # print(len(preds_list))

      for i in range(len(labels)):
        results[labels[i]] = preds_list[i]

  return results

"""## Ensemble though simple, unweighted averaging of 5 individual model predictions
Val acc: 

See different ensemble techniques here: https://web.archive.org/web/20210724194837/https://mlwave.com/kaggle-ensembling-guide/
"""

class load_VGG19_BN(nn.Module):
    def __init__(self):
        super(load_VGG19_BN, self).__init__()
        self.model = torchvision.models.vgg19_bn()
        #print(self.model)
        num_ftrs = self.model.classifier[6].in_features
        self.model.classifier[6] = nn.Linear(num_ftrs, 5)
        self.model.load_state_dict(torch.load(save_models_dir+'best_vgg19_new.pt'))
        self.model.eval()
    def forward(self, x):        
        return self.model(x)

class load_VGG16_BN(nn.Module):
    def __init__(self):
        super(load_VGG16_BN, self).__init__()
        self.model = torchvision.models.vgg16_bn()
        #print(self.model)
        num_ftrs = self.model.classifier[6].in_features
        self.model.classifier[6] = nn.Linear(num_ftrs, 5)
        self.model.load_state_dict(torch.load(save_models_dir+'best_vgg16_new.pt'))
        self.model.eval()         
    def forward(self, x):        
        return self.model(x)

class load_ResNet50(nn.Module):
    def __init__(self):
        super(load_ResNet50, self).__init__()
        self.model = torchvision.models.resnet50()
        #print(self.model)
        num_ftrs = self.model.fc.in_features
        self.model.fc = nn.Linear(num_ftrs, 5)
        self.model.load_state_dict(torch.load(save_models_dir+'best_resnet50_dsnormalized.pt'))
        self.model.eval()        
    def forward(self, x):        
        return self.model(x)

class load_ResNet18(nn.Module):
    def __init__(self):
        super(load_ResNet18, self).__init__()
        self.model = torchvision.models.resnet18()
        #print(self.model)
        num_ftrs = self.model.fc.in_features
        self.model.fc = nn.Linear(num_ftrs, 5)
        self.model.load_state_dict(torch.load(save_models_dir+'best_resnet18_dsnormalized.pt'))
        self.model.eval()        
    def forward(self, x):        
        return self.model(x)

class load_EfficientNet_B3(nn.Module):
    def __init__(self):
        super(load_EfficientNet_B3, self).__init__()
        self.model = torchvision.models.efficientnet_b3()
        #print(self.model)
        num_ftrs = self.model.classifier[1].in_features
        self.model.classifier[1] = nn.Linear(num_ftrs, 5)
        self.model.load_state_dict(torch.load(save_models_dir+'best_efficientnetb3_model.pt'))
        self.model.eval()        
    def forward(self, x):        
        return self.model(x)

# ResNet50
resnet50_model = load_ResNet50()
# print(resnet50_model)
# resnet50_model = resnet50_model.to(device)

# ResNet18
resnet18_model = load_ResNet18()
# print(resnet50_model)
# resnet50_model = resnet50_model.to(device)

# VGG16_BN
vgg16_bn_model = load_VGG16_BN()
# print(vgg16_bn_model)
# vgg16_bn_model = vgg16_bn_model.to(device)

# VGG19_BN
vgg19_bn_model = load_VGG19_BN()
# print(vgg19_bn_model)
# vgg19_bn_model = vgg19_bn_model.to(device)

results = ensemble_averaging(resnet50_model, resnet18_model, vgg16_bn_model, vgg19_bn_model)

submission_df = pd.DataFrame.from_dict(results, orient="index",
                                       columns=["label"])
submission_df = submission_df.reset_index()
submission_df = submission_df.rename({"index":"id"}, axis="columns")
submission_df

# Save to two places - Google Drive and content
submission_df.to_csv(save_models_dir+'submissions/ensemble_avg_vgg16_vgg19_resnet50_resnet18.csv',
                    index=False)

submission_df.to_csv('/content/submission.csv',
                    index=False)

"""## Stacked ensemble attempt 2 """

stacked_ensemble_model.eval()
results = model_test(stacked_ensemble_model)
submission_df = pd.DataFrame.from_dict(results, orient="index",
                                       columns=["label"])
submission_df = submission_df.reset_index()
submission_df = submission_df.rename({"index":"id"}, axis="columns")
submission_df

# Save to two places - Google Drive and content
submission_df.to_csv(save_models_dir+'submissions/stacked_ensemble_attempt2_avg_vgg16_vgg19_resnet50.csv',
                    index=False)

submission_df.to_csv('/content/submission.csv',
                    index=False)

"""## Ensemble though simple, unweighted averaging of 4 individual model predictions
Val acc: 0.80388

See different ensemble techniques here: https://web.archive.org/web/20210724194837/https://mlwave.com/kaggle-ensembling-guide/
"""

class load_VGG19_BN(nn.Module):
    def __init__(self):
        super(load_VGG19_BN, self).__init__()
        self.model = torchvision.models.vgg19_bn()
        #print(self.model)
        num_ftrs = self.model.classifier[6].in_features
        self.model.classifier[6] = nn.Linear(num_ftrs, 5)
        self.model.load_state_dict(torch.load(save_models_dir+'best_vgg19_new.pt'))
        self.model.eval()
    def forward(self, x):        
        return self.model(x)

class load_VGG16_BN(nn.Module):
    def __init__(self):
        super(load_VGG16_BN, self).__init__()
        self.model = torchvision.models.vgg16_bn()
        #print(self.model)
        num_ftrs = self.model.classifier[6].in_features
        self.model.classifier[6] = nn.Linear(num_ftrs, 5)
        self.model.load_state_dict(torch.load(save_models_dir+'best_vgg16_new.pt'))
        self.model.eval()         
    def forward(self, x):        
        return self.model(x)

class load_ResNet50(nn.Module):
    def __init__(self):
        super(load_ResNet50, self).__init__()
        self.model = torchvision.models.resnet50()
        #print(self.model)
        num_ftrs = self.model.fc.in_features
        self.model.fc = nn.Linear(num_ftrs, 5)
        self.model.load_state_dict(torch.load(save_models_dir+'best_resnet50_dsnormalized.pt'))
        self.model.eval()        
    def forward(self, x):        
        return self.model(x)

class load_ResNet18(nn.Module):
    def __init__(self):
        super(load_ResNet18, self).__init__()
        self.model = torchvision.models.resnet18()
        #print(self.model)
        num_ftrs = self.model.fc.in_features
        self.model.fc = nn.Linear(num_ftrs, 5)
        self.model.load_state_dict(torch.load(save_models_dir+'best_resnet18_dsnormalized.pt'))
        self.model.eval()        
    def forward(self, x):        
        return self.model(x)

# ResNet50
resnet50_model = load_ResNet50()
# print(resnet50_model)
# resnet50_model = resnet50_model.to(device)

# ResNet18
resnet18_model = load_ResNet18()
# print(resnet50_model)
# resnet50_model = resnet50_model.to(device)

# VGG16_BN
vgg16_bn_model = load_VGG16_BN()
# print(vgg16_bn_model)
# vgg16_bn_model = vgg16_bn_model.to(device)

# VGG19_BN
vgg19_bn_model = load_VGG19_BN()
# print(vgg19_bn_model)
# vgg19_bn_model = vgg19_bn_model.to(device)

results = ensemble_averaging(resnet50_model, resnet18_model, vgg16_bn_model, vgg19_bn_model)

submission_df = pd.DataFrame.from_dict(results, orient="index",
                                       columns=["label"])
submission_df = submission_df.reset_index()
submission_df = submission_df.rename({"index":"id"}, axis="columns")
submission_df

# Save to two places - Google Drive and content
submission_df.to_csv(save_models_dir+'submissions/ensemble_avg_vgg16_vgg19_resnet50_resnet18.csv',
                    index=False)

submission_df.to_csv('/content/submission.csv',
                    index=False)

"""## Ensemble stacking - attempt 1
I am a bit skeptical of the higher val accuracy than training accuracy

Val acc: 0.73419
"""

class load_VGG19_BN(nn.Module):
    def __init__(self):
        super(load_VGG19_BN, self).__init__()
        self.model = torchvision.models.vgg19_bn()
        #print(self.model)
        num_ftrs = self.model.classifier[6].in_features
        self.model.classifier[6] = nn.Linear(num_ftrs, 5)
        # self.model.load_state_dict(torch.load(save_models_dir+'best_vgg19_new.pt'))
        # self.model.eval()
    def forward(self, x):        
        return self.model(x)

class load_VGG16_BN(nn.Module):
    def __init__(self):
        super(load_VGG16_BN, self).__init__()
        self.model = torchvision.models.vgg16_bn()
        #print(self.model)
        num_ftrs = self.model.classifier[6].in_features
        self.model.classifier[6] = nn.Linear(num_ftrs, 5)
        # self.model.load_state_dict(torch.load(save_models_dir+'best_vgg16_new.pt'))
        # self.model.eval()         
    def forward(self, x):        
        return self.model(x)

class load_ResNet50(nn.Module):
    def __init__(self):
        super(load_ResNet50, self).__init__()
        self.model = torchvision.models.resnet50()
        #print(self.model)
        num_ftrs = self.model.fc.in_features
        self.model.fc = nn.Linear(num_ftrs, 5)
        # self.model.load_state_dict(torch.load(save_models_dir+'best_resnet50_dsnormalized.pt'))
        # self.model.eval()        
    def forward(self, x):        
        return self.model(x)

class StackedEnsemble(nn.Module):
    """
    Stacked ensembling / blending ensemble technique
    """

    def __init__(self,  modelA, modelB, modelC):
        super(StackedEnsemble, self).__init__()
        
        self.modelA = modelA
        self.modelB = modelB
        self.modelC = modelC

        self.classifier = nn.Linear(5*3, 5)
                
    def forward(self, x):
        self.modelA.eval()  
        x1 = self.modelA(x)

        self.modelB.eval()
        x2 = self.modelB(x)

        self.modelC.eval()
        x3 = self.modelC(x)

        x = torch.cat((x1, x2, x3), dim=1)
        out = self.classifier(x)
        return out

# ResNet50
resnet50_model = load_ResNet50()

# VGG16_BN
vgg16_bn_model = load_VGG16_BN()

# VGG19_BN
vgg19_bn_model = load_VGG19_BN()

stacked_ensemble_model = StackedEnsemble(resnet50_model, vgg16_bn_model, vgg19_bn_model)
stacked_ensemble_model.load_state_dict(torch.load(save_models_dir+'stacked_ensemble_vgg16bn_vgg19bn_resnet50.pt'))
stacked_ensemble_model.eval()

results = model_test(stacked_ensemble_model)

submission_df = pd.DataFrame.from_dict(results, orient="index",
                                       columns=["label"])
submission_df = submission_df.reset_index()
submission_df = submission_df.rename({"index":"id"}, axis="columns")
submission_df

# Save to two places - Google Drive and content
submission_df.to_csv(save_models_dir+'submissions/stacked_ensemble_avg_vgg16_vgg19_resnet50.csv',
                    index=False)

submission_df.to_csv('/content/submission.csv',
                    index=False)

"""## Ensemble though simple, unweighted averaging of individual model predictions ⭐
Val acc: 0.79578

See different ensemble techniques here: https://web.archive.org/web/20210724194837/https://mlwave.com/kaggle-ensembling-guide/
"""

class load_VGG19_BN(nn.Module):
    def __init__(self):
        super(load_VGG19_BN, self).__init__()
        self.model = torchvision.models.vgg19_bn()
        #print(self.model)
        num_ftrs = self.model.classifier[6].in_features
        self.model.classifier[6] = nn.Linear(num_ftrs, 5)
        self.model.load_state_dict(torch.load(save_models_dir+'best_vgg19_new.pt'))
        self.model.eval()
    def forward(self, x):        
        return self.model(x)

class load_VGG16_BN(nn.Module):
    def __init__(self):
        super(load_VGG16_BN, self).__init__()
        self.model = torchvision.models.vgg16_bn()
        #print(self.model)
        num_ftrs = self.model.classifier[6].in_features
        self.model.classifier[6] = nn.Linear(num_ftrs, 5)
        self.model.load_state_dict(torch.load(save_models_dir+'best_vgg16_new.pt'))
        self.model.eval()         
    def forward(self, x):        
        return self.model(x)

class load_ResNet50(nn.Module):
    def __init__(self):
        super(load_ResNet50, self).__init__()
        self.model = torchvision.models.resnet50()
        #print(self.model)
        num_ftrs = self.model.fc.in_features
        self.model.fc = nn.Linear(num_ftrs, 5)
        self.model.load_state_dict(torch.load(save_models_dir+'best_resnet50_dsnormalized.pt'))
        self.model.eval()        
    def forward(self, x):        
        return self.model(x)

# ResNet50
resnet50_model = load_ResNet50()
# print(resnet50_model)
# resnet50_model = resnet50_model.to(device)

# VGG16_BN
vgg16_bn_model = load_VGG16_BN()
# print(vgg16_bn_model)
# vgg16_bn_model = vgg16_bn_model.to(device)

# VGG19_BN
vgg19_bn_model = load_VGG19_BN()
# print(vgg19_bn_model)
# vgg19_bn_model = vgg19_bn_model.to(device)

results = ensemble_averaging(resnet50_model, vgg16_bn_model, vgg19_bn_model)

submission_df = pd.DataFrame.from_dict(results, orient="index",
                                       columns=["label"])
submission_df = submission_df.reset_index()
submission_df = submission_df.rename({"index":"id"}, axis="columns")
submission_df

# Save to two places - Google Drive and content
submission_df.to_csv(save_models_dir+'submissions/ensemble_avg_vgg16_vgg19_resnet50.csv',
                    index=False)

submission_df.to_csv('/content/submission.csv',
                    index=False)

"""## VGG19_BN
Test accuracy: 
"""

model = models.vgg19_bn(weights="DEFAULT")
num_ftrs = model.classifier[6].in_features # the 6 gets me to the linear layer of VGG
model.fc = nn.Linear(num_ftrs, 5)

model.load_state_dict(torch.load(save_models_dir+'best_vgg19_bn_model.pt'))
model.eval()

results = model_test(model)

submission_df = pd.DataFrame.from_dict(results, orient="index",
                                       columns=["label"])
submission_df = submission_df.reset_index()
submission_df = submission_df.rename({"index":"id"}, axis="columns")
submission_df

# Save to two places - Google Drive and content
submission_df.to_csv('/content/drive/MyDrive/ML for BDS/Hackathon - graddiss/submissions/vgg19_bn_submission.csv',
                    index=False)

submission_df.to_csv('/content/submission.csv',
                    index=False)

"""## Ensemble Approach - VGG16_BN, VGG19_BN, ResNet50 - 25 epochs"""

# ResNet50
resnet50_model = load_ResNet50()
resnet50_model = resnet50_model.to(device)

# VGG16_BN
vgg16_bn_model = load_VGG16_BN()
vgg16_bn_model = vgg16_bn_model.to(device)

# VGG19_BN
vgg19_bn_model = load_VGG19_BN()
vgg19_bn_model = vgg19_bn_model.to(device)
models = [resnet50_model, vgg16_bn_model, vgg19_bn_model]
model = EnsembleModels(models)
model.load_state_dict(torch.load(save_models_dir+'ensemble_vgg16bn_vgg19bn_resnet50.pt'))
model.eval()

results = model_test(model)

submission_df = pd.DataFrame.from_dict(results, orient="index",
                                       columns=["label"])
submission_df = submission_df.reset_index()
submission_df = submission_df.rename({"index":"id"}, axis="columns")
submission_df

# Save to two places - Google Drive and content
submission_df.to_csv('/content/drive/MyDrive/ML for BDS/Hackathon - graddiss/submissions/ensemble_vgg16bn_vgg19bn_resnet50_25epochs.csv',
                    index=False)

submission_df.to_csv('/content/submission.csv',
                    index=False)

"""## Ensemble Approach - VGG16_BN, VGG19_BN, ResNet50 - 5 epochs"""

resnet50_model = load_ResNet50()
resnet50_model = resnet50_model.to(device)

# VGG16_BN
vgg16_bn_model = load_VGG16_BN()
vgg16_bn_model = vgg16_bn_model.to(device)

# VGG19_BN
vgg19_bn_model = load_VGG19_BN()
vgg19_bn_model = vgg19_bn_model.to(device)
models = [resnet50_model, vgg16_bn_model, vgg19_bn_model]
model = EnsembleModels(models)
model.load_state_dict(torch.load(save_models_dir+'ensemble_vgg16bn_vgg19bn_resnet50.pt'))
model.eval()

results = model_test(model)

submission_df = pd.DataFrame.from_dict(results, orient="index",
                                       columns=["label"])
submission_df = submission_df.reset_index()
submission_df = submission_df.rename({"index":"id"}, axis="columns")
submission_df

# Save to two places - Google Drive and content
submission_df.to_csv('/content/drive/MyDrive/ML for BDS/Hackathon - graddiss/submissions/ensemble_vgg16bn_vgg19bn_resnet50.pt',
                    index=False)

submission_df.to_csv('/content/submission.csv',
                    index=False)

"""## VGG16_BN
Test accuracy: 0.79416
"""

model = models.vgg16_bn(weights="DEFAULT")
num_ftrs = model.classifier[6].in_features # the 6 gets me to the linear layer of VGG
model.fc = nn.Linear(num_ftrs, 5)

model.load_state_dict(torch.load(save_models_dir+'best_vgg16.pt'))
model.eval()

results = model_test(model)

submission_df = pd.DataFrame.from_dict(results, orient="index",
                                       columns=["label"])
submission_df = submission_df.reset_index()
submission_df = submission_df.rename({"index":"id"}, axis="columns")
submission_df

# Save to two places - Google Drive and content
submission_df.to_csv('/content/drive/MyDrive/ML for BDS/Hackathon - graddiss/submissions/vgg16_bn_submission.csv',
                    index=False)

submission_df.to_csv('/content/submission.csv',
                    index=False)

"""## VGG16_BN"""

results = model_test(model)

submission_df = pd.DataFrame.from_dict(results, orient="index",
                                       columns=["label"])
submission_df = submission_df.reset_index()
submission_df = submission_df.rename({"index":"id"}, axis="columns")
submission_df

# Save to two places - Google Drive and content
submission_df.to_csv('/content/drive/MyDrive/ML for BDS/Hackathon - graddiss/submissions/submission.csv',
                    index=False)

submission_df.to_csv('/content/submission.csv',
                    index=False)

# !kaggle competitions submit -c mammography-image-patch-classification-2023 -f submission.csv -m "GradientDissenters - 03212023"

"""## ResNet50 with normalization and lr 0.0005"""

model = models.resnet50()
num_ftrs = model.fc.in_features
model.fc = nn.Linear(num_ftrs, 5)

model.load_state_dict(torch.load(save_models_dir+'best_resnet50_dsnormalized_lrincr.pt'))
model.eval()

results = model_test(model)
submission_df = pd.DataFrame.from_dict(results, orient="index",
                                       columns=["label"])
submission_df = submission_df.reset_index()
submission_df = submission_df.rename({"index":"id"}, axis="columns")
submission_df

# Save to two places - Google Drive and content
submission_df.to_csv(save_models_dir+'submissions/resnet50dsnorm_incrlr_submission.csv',
                    index=False)

submission_df.to_csv('/content/submission.csv',
                    index=False)

"""## ResNet50 with normalization"""

model = models.resnet50()
num_ftrs = model.fc.in_features
model.fc = nn.Linear(num_ftrs, 5)

model.load_state_dict(torch.load(save_models_dir+'best_resnet50_dsnormalized.pt'))
model.eval()

results = model_test(model)
submission_df = pd.DataFrame.from_dict(results, orient="index",
                                       columns=["label"])
submission_df = submission_df.reset_index()
submission_df = submission_df.rename({"index":"id"}, axis="columns")
submission_df

# Save to two places - Google Drive and content
submission_df.to_csv(save_models_dir+'submissions/resnet50dsnorm_submission.csv',
                    index=False)

submission_df.to_csv('/content/submission.csv',
                    index=False)

"""## VGG16_BN"""

model = models.vgg16_bn(weights="DEFAULT")
num_ftrs = model.classifier[6].in_features # the 6 gets me to the linear layer of VGG
model.fc = nn.Linear(num_ftrs, 5)

model.load_state_dict(torch.load('/content/drive/MyDrive/ML for BDS/Hackathon - graddiss/best_vgg16_bnmodel_Adam_balanced.pt'))
model.eval()

results = model_test(model)

submission_df = pd.DataFrame.from_dict(results, orient="index",
                                       columns=["label"])
submission_df = submission_df.reset_index()
submission_df = submission_df.rename({"index":"id"}, axis="columns")
submission_df

# Save to two places - Google Drive and content
submission_df.to_csv('/content/drive/MyDrive/ML for BDS/Hackathon - graddiss/submissions/submission.csv',
                    index=False)

submission_df.to_csv('/content/submission.csv',
                    index=False)

# !kaggle competitions submit -c mammography-image-patch-classification-2023 -f submission.csv -m "GradientDissenters - 03212023"

"""## ResNet50 multistage"""

model = models.resnet50(weights="DEFAULT")
num_ftrs = model.fc.in_features
model.fc = nn.Linear(num_ftrs, 5)

model.load_state_dict(torch.load('/content/drive/MyDrive/ML for BDS/Hackathon - graddiss/best_resnet50_multistage_train.pt'))
model.eval()

results = model_test(model)

submission_df = pd.DataFrame.from_dict(results, orient="index",
                                       columns=["label"])
submission_df = submission_df.reset_index()
submission_df = submission_df.rename({"index":"id"}, axis="columns")
submission_df

# Save to two places - Google Drive and content
submission_df.to_csv('/content/drive/MyDrive/ML for BDS/Hackathon - graddiss/submissions/resnet50_submission.csv',
                    index=False)

submission_df.to_csv('/content/submission.csv',
                    index=False)

"""## ResNet50 - 90/10 train/val"""

model = models.resnet50()
num_ftrs = model.fc.in_features
model.fc = nn.Linear(num_ftrs, 5)

model.load_state_dict(torch.load('/content/drive/MyDrive/ML for BDS/Hackathon - graddiss/best_resnet50_balanced_AdamOptim.pt'))
model.eval()

results = model_test(model)

submission_df = pd.DataFrame.from_dict(results, orient="index",
                                       columns=["label"])
submission_df = submission_df.reset_index()
submission_df = submission_df.rename({"index":"id"}, axis="columns")
submission_df

# Save to two places - Google Drive and content
submission_df.to_csv('/content/drive/MyDrive/ML for BDS/Hackathon - graddiss/submissions/resnet50_90_10_submission.csv',
                    index=False)

submission_df.to_csv('/content/submission.csv',
                    index=False)

"""## Multi-stage ResNet"""

model = models.resnet50()
num_ftrs = model.fc.in_features
model.fc = nn.Linear(num_ftrs, 5)

model.load_state_dict(torch.load(save_models_dir + "best_resnet50_multistage_train.pt"))
model.eval()

results = model_test(model)

submission_df = pd.DataFrame.from_dict(results, orient="index",
                                       columns=["label"])
submission_df = submission_df.reset_index()
submission_df = submission_df.rename({"index":"id"}, axis="columns")
submission_df

# Save to two places - Google Drive and content
submission_df.to_csv('/content/drive/MyDrive/ML for BDS/Hackathon - graddiss/submissions/resnet50_multistage_submission.csv',
                    index=False)

submission_df.to_csv('/content/submission.csv',
                    index=False)