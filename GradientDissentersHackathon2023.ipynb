{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chrisporras/graddiss/blob/dev/GradientDissentersHackathon2023.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hackathon 2023\n",
        "ML for Biomedical Data Science\n",
        "Team Gradient Dissenters\n",
        "\n",
        "Members: Audrey Lee, Christian Porras, Joy Jiang"
      ],
      "metadata": {
        "id": "1jU-jsvdRqVH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mount Google Drive"
      ],
      "metadata": {
        "id": "cbYZjTPEedAS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For saving and loading models "
      ],
      "metadata": {
        "id": "xVZ1lDK8en30"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBE0Kcr3AUZC",
        "outputId": "14316106-8f05-48bc-ed8d-5a824c6fe3ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_models_dir = \"/content/drive/MyDrive/ML for BDS/Hackathon - graddiss/\""
      ],
      "metadata": {
        "id": "ndVQv5TrAwdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install and load Kaggle mammography"
      ],
      "metadata": {
        "id": "6n6lhqeiRqVT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone project git repo\n",
        "!git clone https://github.com/chrisporras/graddiss.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e4e8c07-cbae-4871-dc2a-6b64aeb8997a",
        "id": "iGfdlDpRRqVU"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'graddiss'...\n",
            "remote: Enumerating objects: 56, done.\u001b[K\n",
            "remote: Counting objects: 100% (56/56), done.\u001b[K\n",
            "remote: Compressing objects: 100% (56/56), done.\u001b[K\n",
            "remote: Total 56 (delta 28), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (56/56), 884.08 KiB | 2.10 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install Kaggle public api\n",
        "! pip install -q kaggle\n",
        "# Choose the kaggle.json file that you downloaded\n",
        "! mkdir ~/.kaggle\n",
        "! cp ./graddiss/kaggle.json ~/.kaggle/\n",
        "# Make directory named kaggle and copy kaggle.json file there.\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "#Change the permissions of the file.\n",
        "! kaggle datasets list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c25a65cd-dde4-4a6d-8bc6-a1e0d0ce69ed",
        "id": "SnytcqIJRqVW"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ref                                                           title                                          size  lastUpdated          downloadCount  voteCount  usabilityRating  \n",
            "------------------------------------------------------------  ---------------------------------------------  ----  -------------------  -------------  ---------  ---------------  \n",
            "salvatorerastelli/spotify-and-youtube                         Spotify and Youtube                             9MB  2023-03-20 15:43:25           1220         45  1.0              \n",
            "dgoenrique/netflix-movies-and-tv-shows                        Netflix Movies and TV Shows                     2MB  2023-03-13 18:49:00            855         29  1.0              \n",
            "rajkumarpandey02/list-of-countries-by-gdp-sector-composition  List of Countries by GDP Sector Composition     8KB  2023-03-20 04:42:10           1039         38  1.0              \n",
            "datascientistanna/customers-dataset                           Shop Customer Data                             23KB  2023-02-07 18:42:21          14524        318  1.0              \n",
            "ajaypalsinghlo/world-happiness-report-2023                    World Happiness Report 2023                     7KB  2023-03-22 07:29:42            673         29  0.9411765        \n",
            "amaanansari09/most-streamed-songs-all-time                    Most Streamed Songs (All Time)                  8KB  2023-03-08 10:56:24           2896         69  1.0              \n",
            "rkiattisak/student-performance-in-mathematics                 Student performance prediction                  9KB  2023-03-12 04:32:56           2954         71  1.0              \n",
            "darshanpatel3112/top-rated-movies-from-tmdb                   Top Rated Movies  from TMDB                     1MB  2023-03-22 12:56:39            431         22  1.0              \n",
            "arnabchaki/popular-video-games-1980-2023                      Popular Video Games 1980 - 2023 üéÆ               1MB  2023-03-23 16:16:51            782         38  1.0              \n",
            "ramkrijal/tomato-daily-prices                                 Tomato Daily Prices                            10KB  2023-03-10 15:39:14           1636         49  1.0              \n",
            "themrityunjaypathak/covid-cases-and-deaths-worldwide          Covid Cases and Deaths WorldWide                8KB  2023-02-01 12:22:51          15516        494  1.0              \n",
            "anandaramg/apartment-cost-in-new-york-city                    Housing Cost in New York                        1MB  2023-03-22 02:48:15            644         24  1.0              \n",
            "zusmani/pakistan-toshakhana-files                             Pakistan ToshaKhana Files                       1MB  2023-03-15 16:25:43           2492        126  1.0              \n",
            "mehmettahiraslan/customer-shopping-dataset                    Customer Shopping Dataset - Retail Sales Data   2MB  2023-03-09 07:44:35           1983         64  1.0              \n",
            "shreyajagani13/imdb-movies-data                               imdb movies data                               27KB  2023-03-15 04:26:49            703         27  1.0              \n",
            "thedevastator/airbnb-prices-in-european-cities                Airbnb Prices in European Cities                4MB  2023-02-20 09:48:04           5723        101  1.0              \n",
            "arnabchaki/fitness-trackers-products-ecommerce                Fitness Trackers Products Ecommerce ‚åö          14KB  2023-03-23 09:15:56            618         26  1.0              \n",
            "priyankkhanna/flipkart-product-dataset-by-priyank-khanna      Flipkart Product Dataset                        2MB  2023-03-03 13:44:42           1345         32  1.0              \n",
            "gianinamariapetrascu/top-250-anime-2023                       üç• Top 250 Anime 2023                           10KB  2023-03-20 20:09:40            543         36  1.0              \n",
            "shreyajagani13/used-car-dataset                               Used Car Dataset                               12KB  2023-03-19 06:38:54            866         23  1.0              \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4daeacbb-2658-466c-bae5-7b933b1da129",
        "id": "5WRkW9saRqVX"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading mammography-image-patch-classification-2023.zip to /content\n",
            "100% 460M/460M [00:13<00:00, 36.5MB/s]\n",
            "100% 460M/460M [00:13<00:00, 35.5MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle competitions download -c mammography-image-patch-classification-2023"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data directory\n",
        "!mkdir data\n",
        "# unzip data there,\n",
        "!unzip mammography-image-patch-classification-2023.zip -d data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42ad6b65-505c-44d3-8344-30c06bd16d28",
        "id": "izHq8fYzRqVZ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "  inflating: data/train_imgs/P000435.png  \n",
            "  inflating: data/train_imgs/P000436.png  \n",
            "  inflating: data/train_imgs/P000437.png  \n",
            "  inflating: data/train_imgs/P000438.png  \n",
            "  inflating: data/train_imgs/P000439.png  \n",
            "  inflating: data/train_imgs/P000440.png  \n",
            "  inflating: data/train_imgs/P000441.png  \n",
            "  inflating: data/train_imgs/P000442.png  \n",
            "  inflating: data/train_imgs/P000443.png  \n",
            "  inflating: data/train_imgs/P000444.png  \n",
            "  inflating: data/train_imgs/P000445.png  \n",
            "  inflating: data/train_imgs/P000446.png  \n",
            "  inflating: data/train_imgs/P000447.png  \n",
            "  inflating: data/train_imgs/P000448.png  \n",
            "  inflating: data/train_imgs/P000449.png  \n",
            "  inflating: data/train_imgs/P000450.png  \n",
            "  inflating: data/train_imgs/P000451.png  \n",
            "  inflating: data/train_imgs/P000452.png  \n",
            "  inflating: data/train_imgs/P000453.png  \n",
            "  inflating: data/train_imgs/P000454.png  \n",
            "  inflating: data/train_imgs/P000455.png  \n",
            "  inflating: data/train_imgs/P000456.png  \n",
            "  inflating: data/train_imgs/P000457.png  \n",
            "  inflating: data/train_imgs/P000458.png  \n",
            "  inflating: data/train_imgs/P000459.png  \n",
            "  inflating: data/train_imgs/P000460.png  \n",
            "  inflating: data/train_imgs/P000461.png  \n",
            "  inflating: data/train_imgs/P000462.png  \n",
            "  inflating: data/train_imgs/P000463.png  \n",
            "  inflating: data/train_imgs/P000464.png  \n",
            "  inflating: data/train_imgs/P000465.png  \n",
            "  inflating: data/train_imgs/P000466.png  \n",
            "  inflating: data/train_imgs/P000467.png  \n",
            "  inflating: data/train_imgs/P000468.png  \n",
            "  inflating: data/train_imgs/P000469.png  \n",
            "  inflating: data/train_imgs/P000470.png  \n",
            "  inflating: data/train_imgs/P000471.png  \n",
            "  inflating: data/train_imgs/P000472.png  \n",
            "  inflating: data/train_imgs/P000473.png  \n",
            "  inflating: data/train_imgs/P000474.png  \n",
            "  inflating: data/train_imgs/P000475.png  \n",
            "  inflating: data/train_imgs/P000476.png  \n",
            "  inflating: data/train_imgs/P000477.png  \n",
            "  inflating: data/train_imgs/P000478.png  \n",
            "  inflating: data/train_imgs/P000479.png  \n",
            "  inflating: data/train_imgs/P000480.png  \n",
            "  inflating: data/train_imgs/P000481.png  \n",
            "  inflating: data/train_imgs/P000482.png  \n",
            "  inflating: data/train_imgs/P000483.png  \n",
            "  inflating: data/train_imgs/P000484.png  \n",
            "  inflating: data/train_imgs/P000485.png  \n",
            "  inflating: data/train_imgs/P000486.png  \n",
            "  inflating: data/train_imgs/P000487.png  \n",
            "  inflating: data/train_imgs/P000488.png  \n",
            "  inflating: data/train_imgs/P000489.png  \n",
            "  inflating: data/train_imgs/P000490.png  \n",
            "  inflating: data/train_imgs/P000491.png  \n",
            "  inflating: data/train_imgs/P000492.png  \n",
            "  inflating: data/train_imgs/P000493.png  \n",
            "  inflating: data/train_imgs/P000494.png  \n",
            "  inflating: data/train_imgs/P000495.png  \n",
            "  inflating: data/train_imgs/P000496.png  \n",
            "  inflating: data/train_imgs/P000497.png  \n",
            "  inflating: data/train_imgs/P000498.png  \n",
            "  inflating: data/train_imgs/P000499.png  \n",
            "  inflating: data/train_imgs/P000500.png  \n",
            "  inflating: data/train_imgs/P000501.png  \n",
            "  inflating: data/train_imgs/P000502.png  \n",
            "  inflating: data/train_imgs/P000503.png  \n",
            "  inflating: data/train_imgs/P000504.png  \n",
            "  inflating: data/train_imgs/P000505.png  \n",
            "  inflating: data/train_imgs/P000506.png  \n",
            "  inflating: data/train_imgs/P000507.png  \n",
            "  inflating: data/train_imgs/P000508.png  \n",
            "  inflating: data/train_imgs/P000509.png  \n",
            "  inflating: data/train_imgs/P000510.png  \n",
            "  inflating: data/train_imgs/P000511.png  \n",
            "  inflating: data/train_imgs/P000512.png  \n",
            "  inflating: data/train_imgs/P000513.png  \n",
            "  inflating: data/train_imgs/P000514.png  \n",
            "  inflating: data/train_imgs/P000515.png  \n",
            "  inflating: data/train_imgs/P000516.png  \n",
            "  inflating: data/train_imgs/P000517.png  \n",
            "  inflating: data/train_imgs/P000518.png  \n",
            "  inflating: data/train_imgs/P000519.png  \n",
            "  inflating: data/train_imgs/P000520.png  \n",
            "  inflating: data/train_imgs/P000521.png  \n",
            "  inflating: data/train_imgs/P000522.png  \n",
            "  inflating: data/train_imgs/P000523.png  \n",
            "  inflating: data/train_imgs/P000524.png  \n",
            "  inflating: data/train_imgs/P000525.png  \n",
            "  inflating: data/train_imgs/P000526.png  \n",
            "  inflating: data/train_imgs/P000527.png  \n",
            "  inflating: data/train_imgs/P000528.png  \n",
            "  inflating: data/train_imgs/P000529.png  \n",
            "  inflating: data/train_imgs/P000530.png  \n",
            "  inflating: data/train_imgs/P000531.png  \n",
            "  inflating: data/train_imgs/P000532.png  \n",
            "  inflating: data/train_imgs/P000533.png  \n",
            "  inflating: data/train_imgs/P000534.png  \n",
            "  inflating: data/train_imgs/P000535.png  \n",
            "  inflating: data/train_imgs/P000536.png  \n",
            "  inflating: data/train_imgs/P000537.png  \n",
            "  inflating: data/train_imgs/P000538.png  \n",
            "  inflating: data/train_imgs/P000539.png  \n",
            "  inflating: data/train_imgs/P000540.png  \n",
            "  inflating: data/train_imgs/P000541.png  \n",
            "  inflating: data/train_imgs/P000542.png  \n",
            "  inflating: data/train_imgs/P000543.png  \n",
            "  inflating: data/train_imgs/P000544.png  \n",
            "  inflating: data/train_imgs/P000545.png  \n",
            "  inflating: data/train_imgs/P000546.png  \n",
            "  inflating: data/train_imgs/P000547.png  \n",
            "  inflating: data/train_imgs/P000548.png  \n",
            "  inflating: data/train_imgs/P000549.png  \n",
            "  inflating: data/train_imgs/P000550.png  \n",
            "  inflating: data/train_imgs/P000551.png  \n",
            "  inflating: data/train_imgs/P000552.png  \n",
            "  inflating: data/train_imgs/P000553.png  \n",
            "  inflating: data/train_imgs/P000554.png  \n",
            "  inflating: data/train_imgs/P000555.png  \n",
            "  inflating: data/train_imgs/P000556.png  \n",
            "  inflating: data/train_imgs/P000557.png  \n",
            "  inflating: data/train_imgs/P000558.png  \n",
            "  inflating: data/train_imgs/P000559.png  \n",
            "  inflating: data/train_imgs/P000560.png  \n",
            "  inflating: data/train_imgs/P000561.png  \n",
            "  inflating: data/train_imgs/P000562.png  \n",
            "  inflating: data/train_imgs/P000563.png  \n",
            "  inflating: data/train_imgs/P000564.png  \n",
            "  inflating: data/train_imgs/P000565.png  \n",
            "  inflating: data/train_imgs/P000566.png  \n",
            "  inflating: data/train_imgs/P000567.png  \n",
            "  inflating: data/train_imgs/P000568.png  \n",
            "  inflating: data/train_imgs/P000569.png  \n",
            "  inflating: data/train_imgs/P000570.png  \n",
            "  inflating: data/train_imgs/P000571.png  \n",
            "  inflating: data/train_imgs/P000572.png  \n",
            "  inflating: data/train_imgs/P000573.png  \n",
            "  inflating: data/train_imgs/P000574.png  \n",
            "  inflating: data/train_imgs/P000575.png  \n",
            "  inflating: data/train_imgs/P000576.png  \n",
            "  inflating: data/train_imgs/P000577.png  \n",
            "  inflating: data/train_imgs/P000578.png  \n",
            "  inflating: data/train_imgs/P000579.png  \n",
            "  inflating: data/train_imgs/P000580.png  \n",
            "  inflating: data/train_imgs/P000581.png  \n",
            "  inflating: data/train_imgs/P000582.png  \n",
            "  inflating: data/train_imgs/P000583.png  \n",
            "  inflating: data/train_imgs/P000584.png  \n",
            "  inflating: data/train_imgs/P000585.png  \n",
            "  inflating: data/train_imgs/P000586.png  \n",
            "  inflating: data/train_imgs/P000587.png  \n",
            "  inflating: data/train_imgs/P000588.png  \n",
            "  inflating: data/train_imgs/P000589.png  \n",
            "  inflating: data/train_imgs/P000590.png  \n",
            "  inflating: data/train_imgs/P000591.png  \n",
            "  inflating: data/train_imgs/P000592.png  \n",
            "  inflating: data/train_imgs/P000593.png  \n",
            "  inflating: data/train_imgs/P000594.png  \n",
            "  inflating: data/train_imgs/P000595.png  \n",
            "  inflating: data/train_imgs/P000596.png  \n",
            "  inflating: data/train_imgs/P000597.png  \n",
            "  inflating: data/train_imgs/P000598.png  \n",
            "  inflating: data/train_imgs/P000599.png  \n",
            "  inflating: data/train_imgs/P000600.png  \n",
            "  inflating: data/train_imgs/P000601.png  \n",
            "  inflating: data/train_imgs/P000602.png  \n",
            "  inflating: data/train_imgs/P000603.png  \n",
            "  inflating: data/train_imgs/P000604.png  \n",
            "  inflating: data/train_imgs/P000605.png  \n",
            "  inflating: data/train_imgs/P000606.png  \n",
            "  inflating: data/train_imgs/P000607.png  \n",
            "  inflating: data/train_imgs/P000608.png  \n",
            "  inflating: data/train_imgs/P000609.png  \n",
            "  inflating: data/train_imgs/P000610.png  \n",
            "  inflating: data/train_imgs/P000611.png  \n",
            "  inflating: data/train_imgs/P000612.png  \n",
            "  inflating: data/train_imgs/P000613.png  \n",
            "  inflating: data/train_imgs/P000614.png  \n",
            "  inflating: data/train_imgs/P000615.png  \n",
            "  inflating: data/train_imgs/P000616.png  \n",
            "  inflating: data/train_imgs/P000617.png  \n",
            "  inflating: data/train_imgs/P000618.png  \n",
            "  inflating: data/train_imgs/P000619.png  \n",
            "  inflating: data/train_imgs/P000620.png  \n",
            "  inflating: data/train_imgs/P000621.png  \n",
            "  inflating: data/train_imgs/P000622.png  \n",
            "  inflating: data/train_imgs/P000623.png  \n",
            "  inflating: data/train_imgs/P000624.png  \n",
            "  inflating: data/train_imgs/P000625.png  \n",
            "  inflating: data/train_imgs/P000626.png  \n",
            "  inflating: data/train_imgs/P000627.png  \n",
            "  inflating: data/train_imgs/P000628.png  \n",
            "  inflating: data/train_imgs/P000629.png  \n",
            "  inflating: data/train_imgs/P000630.png  \n",
            "  inflating: data/train_imgs/P000631.png  \n",
            "  inflating: data/train_imgs/P000632.png  \n",
            "  inflating: data/train_imgs/P000633.png  \n",
            "  inflating: data/train_imgs/P000634.png  \n",
            "  inflating: data/train_imgs/P000635.png  \n",
            "  inflating: data/train_imgs/P000636.png  \n",
            "  inflating: data/train_imgs/P000637.png  \n",
            "  inflating: data/train_imgs/P000638.png  \n",
            "  inflating: data/train_imgs/P000639.png  \n",
            "  inflating: data/train_imgs/P000640.png  \n",
            "  inflating: data/train_imgs/P000641.png  \n",
            "  inflating: data/train_imgs/P000642.png  \n",
            "  inflating: data/train_imgs/P000643.png  \n",
            "  inflating: data/train_imgs/P000644.png  \n",
            "  inflating: data/train_imgs/P000645.png  \n",
            "  inflating: data/train_imgs/P000646.png  \n",
            "  inflating: data/train_imgs/P000647.png  \n",
            "  inflating: data/train_imgs/P000648.png  \n",
            "  inflating: data/train_imgs/P000649.png  \n",
            "  inflating: data/train_imgs/P000650.png  \n",
            "  inflating: data/train_imgs/P000651.png  \n",
            "  inflating: data/train_imgs/P000652.png  \n",
            "  inflating: data/train_imgs/P000653.png  \n",
            "  inflating: data/train_imgs/P000654.png  \n",
            "  inflating: data/train_imgs/P000655.png  \n",
            "  inflating: data/train_imgs/P000656.png  \n",
            "  inflating: data/train_imgs/P000657.png  \n",
            "  inflating: data/train_imgs/P000658.png  \n",
            "  inflating: data/train_imgs/P000659.png  \n",
            "  inflating: data/train_imgs/P000660.png  \n",
            "  inflating: data/train_imgs/P000661.png  \n",
            "  inflating: data/train_imgs/P000662.png  \n",
            "  inflating: data/train_imgs/P000663.png  \n",
            "  inflating: data/train_imgs/P000664.png  \n",
            "  inflating: data/train_imgs/P000665.png  \n",
            "  inflating: data/train_imgs/P000666.png  \n",
            "  inflating: data/train_imgs/P000667.png  \n",
            "  inflating: data/train_imgs/P000668.png  \n",
            "  inflating: data/train_imgs/P000669.png  \n",
            "  inflating: data/train_imgs/P000670.png  \n",
            "  inflating: data/train_imgs/P000671.png  \n",
            "  inflating: data/train_imgs/P000672.png  \n",
            "  inflating: data/train_imgs/P000673.png  \n",
            "  inflating: data/train_imgs/P000674.png  \n",
            "  inflating: data/train_imgs/P000675.png  \n",
            "  inflating: data/train_imgs/P000676.png  \n",
            "  inflating: data/train_imgs/P000677.png  \n",
            "  inflating: data/train_imgs/P000678.png  \n",
            "  inflating: data/train_imgs/P000679.png  \n",
            "  inflating: data/train_imgs/P000680.png  \n",
            "  inflating: data/train_imgs/P000681.png  \n",
            "  inflating: data/train_imgs/P000682.png  \n",
            "  inflating: data/train_imgs/P000683.png  \n",
            "  inflating: data/train_imgs/P000684.png  \n",
            "  inflating: data/train_imgs/P000685.png  \n",
            "  inflating: data/train_imgs/P000686.png  \n",
            "  inflating: data/train_imgs/P000687.png  \n",
            "  inflating: data/train_imgs/P000688.png  \n",
            "  inflating: data/train_imgs/P000689.png  \n",
            "  inflating: data/train_imgs/P000690.png  \n",
            "  inflating: data/train_imgs/P000691.png  \n",
            "  inflating: data/train_imgs/P000692.png  \n",
            "  inflating: data/train_imgs/P000693.png  \n",
            "  inflating: data/train_imgs/P000694.png  \n",
            "  inflating: data/train_imgs/P000695.png  \n",
            "  inflating: data/train_imgs/P000696.png  \n",
            "  inflating: data/train_imgs/P000697.png  \n",
            "  inflating: data/train_imgs/P000698.png  \n",
            "  inflating: data/train_imgs/P000699.png  \n",
            "  inflating: data/train_imgs/P000700.png  \n",
            "  inflating: data/train_imgs/P000701.png  \n",
            "  inflating: data/train_imgs/P000702.png  \n",
            "  inflating: data/train_imgs/P000703.png  \n",
            "  inflating: data/train_imgs/P000704.png  \n",
            "  inflating: data/train_imgs/P000705.png  \n",
            "  inflating: data/train_imgs/P000706.png  \n",
            "  inflating: data/train_imgs/P000707.png  \n",
            "  inflating: data/train_imgs/P000708.png  \n",
            "  inflating: data/train_imgs/P000709.png  \n",
            "  inflating: data/train_imgs/P000710.png  \n",
            "  inflating: data/train_imgs/P000711.png  \n",
            "  inflating: data/train_imgs/P000712.png  \n",
            "  inflating: data/train_imgs/P000713.png  \n",
            "  inflating: data/train_imgs/P000714.png  \n",
            "  inflating: data/train_imgs/P000715.png  \n",
            "  inflating: data/train_imgs/P000716.png  \n",
            "  inflating: data/train_imgs/P000717.png  \n",
            "  inflating: data/train_imgs/P000718.png  \n",
            "  inflating: data/train_imgs/P000719.png  \n",
            "  inflating: data/train_imgs/P000720.png  \n",
            "  inflating: data/train_imgs/P000721.png  \n",
            "  inflating: data/train_imgs/P000722.png  \n",
            "  inflating: data/train_imgs/P000723.png  \n",
            "  inflating: data/train_imgs/P000724.png  \n",
            "  inflating: data/train_imgs/P000725.png  \n",
            "  inflating: data/train_imgs/P000726.png  \n",
            "  inflating: data/train_imgs/P000727.png  \n",
            "  inflating: data/train_imgs/P000728.png  \n",
            "  inflating: data/train_imgs/P000729.png  \n",
            "  inflating: data/train_imgs/P000730.png  \n",
            "  inflating: data/train_imgs/P000731.png  \n",
            "  inflating: data/train_imgs/P000732.png  \n",
            "  inflating: data/train_imgs/P000733.png  \n",
            "  inflating: data/train_imgs/P000734.png  \n",
            "  inflating: data/train_imgs/P000735.png  \n",
            "  inflating: data/train_imgs/P000736.png  \n",
            "  inflating: data/train_imgs/P000737.png  \n",
            "  inflating: data/train_imgs/P000738.png  \n",
            "  inflating: data/train_imgs/P000739.png  \n",
            "  inflating: data/train_imgs/P000740.png  \n",
            "  inflating: data/train_imgs/P000741.png  \n",
            "  inflating: data/train_imgs/P000742.png  \n",
            "  inflating: data/train_imgs/P000743.png  \n",
            "  inflating: data/train_imgs/P000744.png  \n",
            "  inflating: data/train_imgs/P000745.png  \n",
            "  inflating: data/train_imgs/P000746.png  \n",
            "  inflating: data/train_imgs/P000747.png  \n",
            "  inflating: data/train_imgs/P000748.png  \n",
            "  inflating: data/train_imgs/P000749.png  \n",
            "  inflating: data/train_imgs/P000750.png  \n",
            "  inflating: data/train_imgs/P000751.png  \n",
            "  inflating: data/train_imgs/P000752.png  \n",
            "  inflating: data/train_imgs/P000753.png  \n",
            "  inflating: data/train_imgs/P000754.png  \n",
            "  inflating: data/train_imgs/P000755.png  \n",
            "  inflating: data/train_imgs/P000756.png  \n",
            "  inflating: data/train_imgs/P000757.png  \n",
            "  inflating: data/train_imgs/P000758.png  \n",
            "  inflating: data/train_imgs/P000759.png  \n",
            "  inflating: data/train_imgs/P000760.png  \n",
            "  inflating: data/train_imgs/P000761.png  \n",
            "  inflating: data/train_imgs/P000762.png  \n",
            "  inflating: data/train_imgs/P000763.png  \n",
            "  inflating: data/train_imgs/P000764.png  \n",
            "  inflating: data/train_imgs/P000765.png  \n",
            "  inflating: data/train_imgs/P000766.png  \n",
            "  inflating: data/train_imgs/P000767.png  \n",
            "  inflating: data/train_imgs/P000768.png  \n",
            "  inflating: data/train_imgs/P000769.png  \n",
            "  inflating: data/train_imgs/P000770.png  \n",
            "  inflating: data/train_imgs/P000771.png  \n",
            "  inflating: data/train_imgs/P000772.png  \n",
            "  inflating: data/train_imgs/P000773.png  \n",
            "  inflating: data/train_imgs/P000774.png  \n",
            "  inflating: data/train_imgs/P000775.png  \n",
            "  inflating: data/train_imgs/P000776.png  \n",
            "  inflating: data/train_imgs/P000777.png  \n",
            "  inflating: data/train_imgs/P000778.png  \n",
            "  inflating: data/train_imgs/P000779.png  \n",
            "  inflating: data/train_imgs/P000780.png  \n",
            "  inflating: data/train_imgs/P000781.png  \n",
            "  inflating: data/train_imgs/P000782.png  \n",
            "  inflating: data/train_imgs/P000783.png  \n",
            "  inflating: data/train_imgs/P000784.png  \n",
            "  inflating: data/train_imgs/P000785.png  \n",
            "  inflating: data/train_imgs/P000786.png  \n",
            "  inflating: data/train_imgs/P000787.png  \n",
            "  inflating: data/train_imgs/P000788.png  \n",
            "  inflating: data/train_imgs/P000789.png  \n",
            "  inflating: data/train_imgs/P000790.png  \n",
            "  inflating: data/train_imgs/P000791.png  \n",
            "  inflating: data/train_imgs/P000792.png  \n",
            "  inflating: data/train_imgs/P000793.png  \n",
            "  inflating: data/train_imgs/P000794.png  \n",
            "  inflating: data/train_imgs/P000795.png  \n",
            "  inflating: data/train_imgs/P000796.png  \n",
            "  inflating: data/train_imgs/P000797.png  \n",
            "  inflating: data/train_imgs/P000798.png  \n",
            "  inflating: data/train_imgs/P000799.png  \n",
            "  inflating: data/train_imgs/P000800.png  \n",
            "  inflating: data/train_imgs/P000801.png  \n",
            "  inflating: data/train_imgs/P000802.png  \n",
            "  inflating: data/train_imgs/P000803.png  \n",
            "  inflating: data/train_imgs/P000804.png  \n",
            "  inflating: data/train_imgs/P000805.png  \n",
            "  inflating: data/train_imgs/P000806.png  \n",
            "  inflating: data/train_imgs/P000807.png  \n",
            "  inflating: data/train_imgs/P000808.png  \n",
            "  inflating: data/train_imgs/P000809.png  \n",
            "  inflating: data/train_imgs/P000810.png  \n",
            "  inflating: data/train_imgs/P000811.png  \n",
            "  inflating: data/train_imgs/P000812.png  \n",
            "  inflating: data/train_imgs/P000813.png  \n",
            "  inflating: data/train_imgs/P000814.png  \n",
            "  inflating: data/train_imgs/P000815.png  \n",
            "  inflating: data/train_imgs/P000816.png  \n",
            "  inflating: data/train_imgs/P000817.png  \n",
            "  inflating: data/train_imgs/P000818.png  \n",
            "  inflating: data/train_imgs/P000819.png  \n",
            "  inflating: data/train_imgs/P000820.png  \n",
            "  inflating: data/train_imgs/P000821.png  \n",
            "  inflating: data/train_imgs/P000822.png  \n",
            "  inflating: data/train_imgs/P000823.png  \n",
            "  inflating: data/train_imgs/P000824.png  \n",
            "  inflating: data/train_imgs/P000825.png  \n",
            "  inflating: data/train_imgs/P000826.png  \n",
            "  inflating: data/train_imgs/P000827.png  \n",
            "  inflating: data/train_imgs/P000828.png  \n",
            "  inflating: data/train_imgs/P000829.png  \n",
            "  inflating: data/train_imgs/P000830.png  \n",
            "  inflating: data/train_imgs/P000831.png  \n",
            "  inflating: data/train_imgs/P000832.png  \n",
            "  inflating: data/train_imgs/P000833.png  \n",
            "  inflating: data/train_imgs/P000834.png  \n",
            "  inflating: data/train_imgs/P000835.png  \n",
            "  inflating: data/train_imgs/P000836.png  \n",
            "  inflating: data/train_imgs/P000837.png  \n",
            "  inflating: data/train_imgs/P000838.png  \n",
            "  inflating: data/train_imgs/P000839.png  \n",
            "  inflating: data/train_imgs/P000840.png  \n",
            "  inflating: data/train_imgs/P000841.png  \n",
            "  inflating: data/train_imgs/P000842.png  \n",
            "  inflating: data/train_imgs/P000843.png  \n",
            "  inflating: data/train_imgs/P000844.png  \n",
            "  inflating: data/train_imgs/P000845.png  \n",
            "  inflating: data/train_imgs/P000846.png  \n",
            "  inflating: data/train_imgs/P000847.png  \n",
            "  inflating: data/train_imgs/P000848.png  \n",
            "  inflating: data/train_imgs/P000849.png  \n",
            "  inflating: data/train_imgs/P000850.png  \n",
            "  inflating: data/train_imgs/P000851.png  \n",
            "  inflating: data/train_imgs/P000852.png  \n",
            "  inflating: data/train_imgs/P000853.png  \n",
            "  inflating: data/train_imgs/P000854.png  \n",
            "  inflating: data/train_imgs/P000855.png  \n",
            "  inflating: data/train_imgs/P000856.png  \n",
            "  inflating: data/train_imgs/P000857.png  \n",
            "  inflating: data/train_imgs/P000858.png  \n",
            "  inflating: data/train_imgs/P000859.png  \n",
            "  inflating: data/train_imgs/P000860.png  \n",
            "  inflating: data/train_imgs/P000861.png  \n",
            "  inflating: data/train_imgs/P000862.png  \n",
            "  inflating: data/train_imgs/P000863.png  \n",
            "  inflating: data/train_imgs/P000864.png  \n",
            "  inflating: data/train_imgs/P000865.png  \n",
            "  inflating: data/train_imgs/P000866.png  \n",
            "  inflating: data/train_imgs/P000867.png  \n",
            "  inflating: data/train_imgs/P000868.png  \n",
            "  inflating: data/train_imgs/P000869.png  \n",
            "  inflating: data/train_imgs/P000870.png  \n",
            "  inflating: data/train_imgs/P000871.png  \n",
            "  inflating: data/train_imgs/P000872.png  \n",
            "  inflating: data/train_imgs/P000873.png  \n",
            "  inflating: data/train_imgs/P000874.png  \n",
            "  inflating: data/train_imgs/P000875.png  \n",
            "  inflating: data/train_imgs/P000876.png  \n",
            "  inflating: data/train_imgs/P000877.png  \n",
            "  inflating: data/train_imgs/P000878.png  \n",
            "  inflating: data/train_imgs/P000879.png  \n",
            "  inflating: data/train_imgs/P000880.png  \n",
            "  inflating: data/train_imgs/P000881.png  \n",
            "  inflating: data/train_imgs/P000882.png  \n",
            "  inflating: data/train_imgs/P000883.png  \n",
            "  inflating: data/train_imgs/P000884.png  \n",
            "  inflating: data/train_imgs/P000885.png  \n",
            "  inflating: data/train_imgs/P000886.png  \n",
            "  inflating: data/train_imgs/P000887.png  \n",
            "  inflating: data/train_imgs/P000888.png  \n",
            "  inflating: data/train_imgs/P000889.png  \n",
            "  inflating: data/train_imgs/P000890.png  \n",
            "  inflating: data/train_imgs/P000891.png  \n",
            "  inflating: data/train_imgs/P000892.png  \n",
            "  inflating: data/train_imgs/P000893.png  \n",
            "  inflating: data/train_imgs/P000894.png  \n",
            "  inflating: data/train_imgs/P000895.png  \n",
            "  inflating: data/train_imgs/P000896.png  \n",
            "  inflating: data/train_imgs/P000897.png  \n",
            "  inflating: data/train_imgs/P000898.png  \n",
            "  inflating: data/train_imgs/P000899.png  \n",
            "  inflating: data/train_imgs/P000900.png  \n",
            "  inflating: data/train_imgs/P000901.png  \n",
            "  inflating: data/train_imgs/P000902.png  \n",
            "  inflating: data/train_imgs/P000903.png  \n",
            "  inflating: data/train_imgs/P000904.png  \n",
            "  inflating: data/train_imgs/P000905.png  \n",
            "  inflating: data/train_imgs/P000906.png  \n",
            "  inflating: data/train_imgs/P000907.png  \n",
            "  inflating: data/train_imgs/P000908.png  \n",
            "  inflating: data/train_imgs/P000909.png  \n",
            "  inflating: data/train_imgs/P000910.png  \n",
            "  inflating: data/train_imgs/P000911.png  \n",
            "  inflating: data/train_imgs/P000912.png  \n",
            "  inflating: data/train_imgs/P000913.png  \n",
            "  inflating: data/train_imgs/P000914.png  \n",
            "  inflating: data/train_imgs/P000915.png  \n",
            "  inflating: data/train_imgs/P000916.png  \n",
            "  inflating: data/train_imgs/P000917.png  \n",
            "  inflating: data/train_imgs/P000918.png  \n",
            "  inflating: data/train_imgs/P000919.png  \n",
            "  inflating: data/train_imgs/P000920.png  \n",
            "  inflating: data/train_imgs/P000921.png  \n",
            "  inflating: data/train_imgs/P000922.png  \n",
            "  inflating: data/train_imgs/P000923.png  \n",
            "  inflating: data/train_imgs/P000924.png  \n",
            "  inflating: data/train_imgs/P000925.png  \n",
            "  inflating: data/train_imgs/P000926.png  \n",
            "  inflating: data/train_imgs/P000927.png  \n",
            "  inflating: data/train_imgs/P000928.png  \n",
            "  inflating: data/train_imgs/P000929.png  \n",
            "  inflating: data/train_imgs/P000930.png  \n",
            "  inflating: data/train_imgs/P000931.png  \n",
            "  inflating: data/train_imgs/P000932.png  \n",
            "  inflating: data/train_imgs/P000933.png  \n",
            "  inflating: data/train_imgs/P000934.png  \n",
            "  inflating: data/train_imgs/P000935.png  \n",
            "  inflating: data/train_imgs/P000936.png  \n",
            "  inflating: data/train_imgs/P000937.png  \n",
            "  inflating: data/train_imgs/P000938.png  \n",
            "  inflating: data/train_imgs/P000939.png  \n",
            "  inflating: data/train_imgs/P000940.png  \n",
            "  inflating: data/train_imgs/P000941.png  \n",
            "  inflating: data/train_imgs/P000942.png  \n",
            "  inflating: data/train_imgs/P000943.png  \n",
            "  inflating: data/train_imgs/P000944.png  \n",
            "  inflating: data/train_imgs/P000945.png  \n",
            "  inflating: data/train_imgs/P000946.png  \n",
            "  inflating: data/train_imgs/P000947.png  \n",
            "  inflating: data/train_imgs/P000948.png  \n",
            "  inflating: data/train_imgs/P000949.png  \n",
            "  inflating: data/train_imgs/P000950.png  \n",
            "  inflating: data/train_imgs/P000951.png  \n",
            "  inflating: data/train_imgs/P000952.png  \n",
            "  inflating: data/train_imgs/P000953.png  \n",
            "  inflating: data/train_imgs/P000954.png  \n",
            "  inflating: data/train_imgs/P000955.png  \n",
            "  inflating: data/train_imgs/P000956.png  \n",
            "  inflating: data/train_imgs/P000957.png  \n",
            "  inflating: data/train_imgs/P000958.png  \n",
            "  inflating: data/train_imgs/P000959.png  \n",
            "  inflating: data/train_imgs/P000960.png  \n",
            "  inflating: data/train_imgs/P000961.png  \n",
            "  inflating: data/train_imgs/P000962.png  \n",
            "  inflating: data/train_imgs/P000963.png  \n",
            "  inflating: data/train_imgs/P000964.png  \n",
            "  inflating: data/train_imgs/P000965.png  \n",
            "  inflating: data/train_imgs/P000966.png  \n",
            "  inflating: data/train_imgs/P000967.png  \n",
            "  inflating: data/train_imgs/P000968.png  \n",
            "  inflating: data/train_imgs/P000969.png  \n",
            "  inflating: data/train_imgs/P000970.png  \n",
            "  inflating: data/train_imgs/P000971.png  \n",
            "  inflating: data/train_imgs/P000972.png  \n",
            "  inflating: data/train_imgs/P000973.png  \n",
            "  inflating: data/train_imgs/P000974.png  \n",
            "  inflating: data/train_imgs/P000975.png  \n",
            "  inflating: data/train_imgs/P000976.png  \n",
            "  inflating: data/train_imgs/P000977.png  \n",
            "  inflating: data/train_imgs/P000978.png  \n",
            "  inflating: data/train_imgs/P000979.png  \n",
            "  inflating: data/train_imgs/P000980.png  \n",
            "  inflating: data/train_imgs/P000981.png  \n",
            "  inflating: data/train_imgs/P000982.png  \n",
            "  inflating: data/train_imgs/P000983.png  \n",
            "  inflating: data/train_imgs/P000984.png  \n",
            "  inflating: data/train_imgs/P000985.png  \n",
            "  inflating: data/train_imgs/P000986.png  \n",
            "  inflating: data/train_imgs/P000987.png  \n",
            "  inflating: data/train_imgs/P000988.png  \n",
            "  inflating: data/train_imgs/P000989.png  \n",
            "  inflating: data/train_imgs/P000990.png  \n",
            "  inflating: data/train_imgs/P000991.png  \n",
            "  inflating: data/train_imgs/P000992.png  \n",
            "  inflating: data/train_imgs/P000993.png  \n",
            "  inflating: data/train_imgs/P000994.png  \n",
            "  inflating: data/train_imgs/P000995.png  \n",
            "  inflating: data/train_imgs/P000996.png  \n",
            "  inflating: data/train_imgs/P000997.png  \n",
            "  inflating: data/train_imgs/P000998.png  \n",
            "  inflating: data/train_imgs/P000999.png  \n",
            "  inflating: data/train_imgs/P001000.png  \n",
            "  inflating: data/train_imgs/P001001.png  \n",
            "  inflating: data/train_imgs/P001002.png  \n",
            "  inflating: data/train_imgs/P001003.png  \n",
            "  inflating: data/train_imgs/P001004.png  \n",
            "  inflating: data/train_imgs/P001005.png  \n",
            "  inflating: data/train_imgs/P001006.png  \n",
            "  inflating: data/train_imgs/P001007.png  \n",
            "  inflating: data/train_imgs/P001008.png  \n",
            "  inflating: data/train_imgs/P001009.png  \n",
            "  inflating: data/train_imgs/P001010.png  \n",
            "  inflating: data/train_imgs/P001011.png  \n",
            "  inflating: data/train_imgs/P001012.png  \n",
            "  inflating: data/train_imgs/P001013.png  \n",
            "  inflating: data/train_imgs/P001014.png  \n",
            "  inflating: data/train_imgs/P001015.png  \n",
            "  inflating: data/train_imgs/P001016.png  \n",
            "  inflating: data/train_imgs/P001017.png  \n",
            "  inflating: data/train_imgs/P001018.png  \n",
            "  inflating: data/train_imgs/P001019.png  \n",
            "  inflating: data/train_imgs/P001020.png  \n",
            "  inflating: data/train_imgs/P001021.png  \n",
            "  inflating: data/train_imgs/P001022.png  \n",
            "  inflating: data/train_imgs/P001023.png  \n",
            "  inflating: data/train_imgs/P001024.png  \n",
            "  inflating: data/train_imgs/P001025.png  \n",
            "  inflating: data/train_imgs/P001026.png  \n",
            "  inflating: data/train_imgs/P001027.png  \n",
            "  inflating: data/train_imgs/P001028.png  \n",
            "  inflating: data/train_imgs/P001029.png  \n",
            "  inflating: data/train_imgs/P001030.png  \n",
            "  inflating: data/train_imgs/P001031.png  \n",
            "  inflating: data/train_imgs/P001032.png  \n",
            "  inflating: data/train_imgs/P001033.png  \n",
            "  inflating: data/train_imgs/P001034.png  \n",
            "  inflating: data/train_imgs/P001035.png  \n",
            "  inflating: data/train_imgs/P001036.png  \n",
            "  inflating: data/train_imgs/P001037.png  \n",
            "  inflating: data/train_imgs/P001038.png  \n",
            "  inflating: data/train_imgs/P001039.png  \n",
            "  inflating: data/train_imgs/P001040.png  \n",
            "  inflating: data/train_imgs/P001041.png  \n",
            "  inflating: data/train_imgs/P001042.png  \n",
            "  inflating: data/train_imgs/P001043.png  \n",
            "  inflating: data/train_imgs/P001044.png  \n",
            "  inflating: data/train_imgs/P001045.png  \n",
            "  inflating: data/train_imgs/P001046.png  \n",
            "  inflating: data/train_imgs/P001047.png  \n",
            "  inflating: data/train_imgs/P001048.png  \n",
            "  inflating: data/train_imgs/P001049.png  \n",
            "  inflating: data/train_imgs/P001050.png  \n",
            "  inflating: data/train_imgs/P001051.png  \n",
            "  inflating: data/train_imgs/P001052.png  \n",
            "  inflating: data/train_imgs/P001053.png  \n",
            "  inflating: data/train_imgs/P001054.png  \n",
            "  inflating: data/train_imgs/P001055.png  \n",
            "  inflating: data/train_imgs/P001056.png  \n",
            "  inflating: data/train_imgs/P001057.png  \n",
            "  inflating: data/train_imgs/P001058.png  \n",
            "  inflating: data/train_imgs/P001059.png  \n",
            "  inflating: data/train_imgs/P001060.png  \n",
            "  inflating: data/train_imgs/P001061.png  \n",
            "  inflating: data/train_imgs/P001062.png  \n",
            "  inflating: data/train_imgs/P001063.png  \n",
            "  inflating: data/train_imgs/P001064.png  \n",
            "  inflating: data/train_imgs/P001065.png  \n",
            "  inflating: data/train_imgs/P001066.png  \n",
            "  inflating: data/train_imgs/P001067.png  \n",
            "  inflating: data/train_imgs/P001068.png  \n",
            "  inflating: data/train_imgs/P001069.png  \n",
            "  inflating: data/train_imgs/P001070.png  \n",
            "  inflating: data/train_imgs/P001071.png  \n",
            "  inflating: data/train_imgs/P001072.png  \n",
            "  inflating: data/train_imgs/P001073.png  \n",
            "  inflating: data/train_imgs/P001074.png  \n",
            "  inflating: data/train_imgs/P001075.png  \n",
            "  inflating: data/train_imgs/P001076.png  \n",
            "  inflating: data/train_imgs/P001077.png  \n",
            "  inflating: data/train_imgs/P001078.png  \n",
            "  inflating: data/train_imgs/P001079.png  \n",
            "  inflating: data/train_imgs/P001080.png  \n",
            "  inflating: data/train_imgs/P001081.png  \n",
            "  inflating: data/train_imgs/P001082.png  \n",
            "  inflating: data/train_imgs/P001083.png  \n",
            "  inflating: data/train_imgs/P001084.png  \n",
            "  inflating: data/train_imgs/P001085.png  \n",
            "  inflating: data/train_imgs/P001086.png  \n",
            "  inflating: data/train_imgs/P001087.png  \n",
            "  inflating: data/train_imgs/P001088.png  \n",
            "  inflating: data/train_imgs/P001089.png  \n",
            "  inflating: data/train_imgs/P001090.png  \n",
            "  inflating: data/train_imgs/P001091.png  \n",
            "  inflating: data/train_imgs/P001092.png  \n",
            "  inflating: data/train_imgs/P001093.png  \n",
            "  inflating: data/train_imgs/P001094.png  \n",
            "  inflating: data/train_imgs/P001095.png  \n",
            "  inflating: data/train_imgs/P001096.png  \n",
            "  inflating: data/train_imgs/P001097.png  \n",
            "  inflating: data/train_imgs/P001098.png  \n",
            "  inflating: data/train_imgs/P001099.png  \n",
            "  inflating: data/train_imgs/P001100.png  \n",
            "  inflating: data/train_imgs/P001101.png  \n",
            "  inflating: data/train_imgs/P001102.png  \n",
            "  inflating: data/train_imgs/P001103.png  \n",
            "  inflating: data/train_imgs/P001104.png  \n",
            "  inflating: data/train_imgs/P001105.png  \n",
            "  inflating: data/train_imgs/P001106.png  \n",
            "  inflating: data/train_imgs/P001107.png  \n",
            "  inflating: data/train_imgs/P001108.png  \n",
            "  inflating: data/train_imgs/P001109.png  \n",
            "  inflating: data/train_imgs/P001110.png  \n",
            "  inflating: data/train_imgs/P001111.png  \n",
            "  inflating: data/train_imgs/P001112.png  \n",
            "  inflating: data/train_imgs/P001113.png  \n",
            "  inflating: data/train_imgs/P001114.png  \n",
            "  inflating: data/train_imgs/P001115.png  \n",
            "  inflating: data/train_imgs/P001116.png  \n",
            "  inflating: data/train_imgs/P001117.png  \n",
            "  inflating: data/train_imgs/P001118.png  \n",
            "  inflating: data/train_imgs/P001119.png  \n",
            "  inflating: data/train_imgs/P001120.png  \n",
            "  inflating: data/train_imgs/P001121.png  \n",
            "  inflating: data/train_imgs/P001122.png  \n",
            "  inflating: data/train_imgs/P001123.png  \n",
            "  inflating: data/train_imgs/P001124.png  \n",
            "  inflating: data/train_imgs/P001125.png  \n",
            "  inflating: data/train_imgs/P001126.png  \n",
            "  inflating: data/train_imgs/P001127.png  \n",
            "  inflating: data/train_imgs/P001128.png  \n",
            "  inflating: data/train_imgs/P001129.png  \n",
            "  inflating: data/train_imgs/P001130.png  \n",
            "  inflating: data/train_imgs/P001131.png  \n",
            "  inflating: data/train_imgs/P001132.png  \n",
            "  inflating: data/train_imgs/P001133.png  \n",
            "  inflating: data/train_imgs/P001134.png  \n",
            "  inflating: data/train_imgs/P001135.png  \n",
            "  inflating: data/train_imgs/P001136.png  \n",
            "  inflating: data/train_imgs/P001137.png  \n",
            "  inflating: data/train_imgs/P001138.png  \n",
            "  inflating: data/train_imgs/P001139.png  \n",
            "  inflating: data/train_imgs/P001140.png  \n",
            "  inflating: data/train_imgs/P001141.png  \n",
            "  inflating: data/train_imgs/P001142.png  \n",
            "  inflating: data/train_imgs/P001143.png  \n",
            "  inflating: data/train_imgs/P001144.png  \n",
            "  inflating: data/train_imgs/P001145.png  \n",
            "  inflating: data/train_imgs/P001146.png  \n",
            "  inflating: data/train_imgs/P001147.png  \n",
            "  inflating: data/train_imgs/P001148.png  \n",
            "  inflating: data/train_imgs/P001149.png  \n",
            "  inflating: data/train_imgs/P001150.png  \n",
            "  inflating: data/train_imgs/P001151.png  \n",
            "  inflating: data/train_imgs/P001152.png  \n",
            "  inflating: data/train_imgs/P001153.png  \n",
            "  inflating: data/train_imgs/P001154.png  \n",
            "  inflating: data/train_imgs/P001155.png  \n",
            "  inflating: data/train_imgs/P001156.png  \n",
            "  inflating: data/train_imgs/P001157.png  \n",
            "  inflating: data/train_imgs/P001158.png  \n",
            "  inflating: data/train_imgs/P001159.png  \n",
            "  inflating: data/train_imgs/P001160.png  \n",
            "  inflating: data/train_imgs/P001161.png  \n",
            "  inflating: data/train_imgs/P001162.png  \n",
            "  inflating: data/train_imgs/P001163.png  \n",
            "  inflating: data/train_imgs/P001164.png  \n",
            "  inflating: data/train_imgs/P001165.png  \n",
            "  inflating: data/train_imgs/P001166.png  \n",
            "  inflating: data/train_imgs/P001167.png  \n",
            "  inflating: data/train_imgs/P001168.png  \n",
            "  inflating: data/train_imgs/P001169.png  \n",
            "  inflating: data/train_imgs/P001170.png  \n",
            "  inflating: data/train_imgs/P001171.png  \n",
            "  inflating: data/train_imgs/P001172.png  \n",
            "  inflating: data/train_imgs/P001173.png  \n",
            "  inflating: data/train_imgs/P001174.png  \n",
            "  inflating: data/train_imgs/P001175.png  \n",
            "  inflating: data/train_imgs/P001176.png  \n",
            "  inflating: data/train_imgs/P001177.png  \n",
            "  inflating: data/train_imgs/P001178.png  \n",
            "  inflating: data/train_imgs/P001179.png  \n",
            "  inflating: data/train_imgs/P001180.png  \n",
            "  inflating: data/train_imgs/P001181.png  \n",
            "  inflating: data/train_imgs/P001182.png  \n",
            "  inflating: data/train_imgs/P001183.png  \n",
            "  inflating: data/train_imgs/P001184.png  \n",
            "  inflating: data/train_imgs/P001185.png  \n",
            "  inflating: data/train_imgs/P001186.png  \n",
            "  inflating: data/train_imgs/P001187.png  \n",
            "  inflating: data/train_imgs/P001188.png  \n",
            "  inflating: data/train_imgs/P001189.png  \n",
            "  inflating: data/train_imgs/P001190.png  \n",
            "  inflating: data/train_imgs/P001191.png  \n",
            "  inflating: data/train_imgs/P001192.png  \n",
            "  inflating: data/train_imgs/P001193.png  \n",
            "  inflating: data/train_imgs/P001194.png  \n",
            "  inflating: data/train_imgs/P001195.png  \n",
            "  inflating: data/train_imgs/P001196.png  \n",
            "  inflating: data/train_imgs/P001197.png  \n",
            "  inflating: data/train_imgs/P001198.png  \n",
            "  inflating: data/train_imgs/P001199.png  \n",
            "  inflating: data/train_imgs/P001200.png  \n",
            "  inflating: data/train_imgs/P001201.png  \n",
            "  inflating: data/train_imgs/P001202.png  \n",
            "  inflating: data/train_imgs/P001203.png  \n",
            "  inflating: data/train_imgs/P001204.png  \n",
            "  inflating: data/train_imgs/P001205.png  \n",
            "  inflating: data/train_imgs/P001206.png  \n",
            "  inflating: data/train_imgs/P001207.png  \n",
            "  inflating: data/train_imgs/P001208.png  \n",
            "  inflating: data/train_imgs/P001209.png  \n",
            "  inflating: data/train_imgs/P001210.png  \n",
            "  inflating: data/train_imgs/P001211.png  \n",
            "  inflating: data/train_imgs/P001212.png  \n",
            "  inflating: data/train_imgs/P001213.png  \n",
            "  inflating: data/train_imgs/P001214.png  \n",
            "  inflating: data/train_imgs/P001215.png  \n",
            "  inflating: data/train_imgs/P001216.png  \n",
            "  inflating: data/train_imgs/P001217.png  \n",
            "  inflating: data/train_imgs/P001218.png  \n",
            "  inflating: data/train_imgs/P001219.png  \n",
            "  inflating: data/train_imgs/P001220.png  \n",
            "  inflating: data/train_imgs/P001221.png  \n",
            "  inflating: data/train_imgs/P001222.png  \n",
            "  inflating: data/train_imgs/P001223.png  \n",
            "  inflating: data/train_imgs/P001224.png  \n",
            "  inflating: data/train_imgs/P001225.png  \n",
            "  inflating: data/train_imgs/P001226.png  \n",
            "  inflating: data/train_imgs/P001227.png  \n",
            "  inflating: data/train_imgs/P001228.png  \n",
            "  inflating: data/train_imgs/P001229.png  \n",
            "  inflating: data/train_imgs/P001230.png  \n",
            "  inflating: data/train_imgs/P001231.png  \n",
            "  inflating: data/train_imgs/P001232.png  \n",
            "  inflating: data/train_imgs/P001233.png  \n",
            "  inflating: data/train_imgs/P001234.png  \n",
            "  inflating: data/train_imgs/P001235.png  \n",
            "  inflating: data/train_imgs/P001236.png  \n",
            "  inflating: data/train_imgs/P001237.png  \n",
            "  inflating: data/train_imgs/P001238.png  \n",
            "  inflating: data/train_imgs/P001239.png  \n",
            "  inflating: data/train_imgs/P001240.png  \n",
            "  inflating: data/train_imgs/P001241.png  \n",
            "  inflating: data/train_imgs/P001242.png  \n",
            "  inflating: data/train_imgs/P001243.png  \n",
            "  inflating: data/train_imgs/P001244.png  \n",
            "  inflating: data/train_imgs/P001245.png  \n",
            "  inflating: data/train_imgs/P001246.png  \n",
            "  inflating: data/train_imgs/P001247.png  \n",
            "  inflating: data/train_imgs/P001248.png  \n",
            "  inflating: data/train_imgs/P001249.png  \n",
            "  inflating: data/train_imgs/P001250.png  \n",
            "  inflating: data/train_imgs/P001251.png  \n",
            "  inflating: data/train_imgs/P001252.png  \n",
            "  inflating: data/train_imgs/P001253.png  \n",
            "  inflating: data/train_imgs/P001254.png  \n",
            "  inflating: data/train_imgs/P001255.png  \n",
            "  inflating: data/train_imgs/P001256.png  \n",
            "  inflating: data/train_imgs/P001257.png  \n",
            "  inflating: data/train_imgs/P001258.png  \n",
            "  inflating: data/train_imgs/P001259.png  \n",
            "  inflating: data/train_imgs/P001260.png  \n",
            "  inflating: data/train_imgs/P001261.png  \n",
            "  inflating: data/train_imgs/P001262.png  \n",
            "  inflating: data/train_imgs/P001263.png  \n",
            "  inflating: data/train_imgs/P001264.png  \n",
            "  inflating: data/train_imgs/P001265.png  \n",
            "  inflating: data/train_imgs/P001266.png  \n",
            "  inflating: data/train_imgs/P001267.png  \n",
            "  inflating: data/train_imgs/P001268.png  \n",
            "  inflating: data/train_imgs/P001269.png  \n",
            "  inflating: data/train_imgs/P001270.png  \n",
            "  inflating: data/train_imgs/P001271.png  \n",
            "  inflating: data/train_imgs/P001272.png  \n",
            "  inflating: data/train_imgs/P001273.png  \n",
            "  inflating: data/train_imgs/P001274.png  \n",
            "  inflating: data/train_imgs/P001275.png  \n",
            "  inflating: data/train_imgs/P001276.png  \n",
            "  inflating: data/train_imgs/P001277.png  \n",
            "  inflating: data/train_imgs/P001278.png  \n",
            "  inflating: data/train_imgs/P001279.png  \n",
            "  inflating: data/train_imgs/P001280.png  \n",
            "  inflating: data/train_imgs/P001281.png  \n",
            "  inflating: data/train_imgs/P001282.png  \n",
            "  inflating: data/train_imgs/P001283.png  \n",
            "  inflating: data/train_imgs/P001284.png  \n",
            "  inflating: data/train_imgs/P001285.png  \n",
            "  inflating: data/train_imgs/P001286.png  \n",
            "  inflating: data/train_imgs/P001287.png  \n",
            "  inflating: data/train_imgs/P001288.png  \n",
            "  inflating: data/train_imgs/P001289.png  \n",
            "  inflating: data/train_imgs/P001290.png  \n",
            "  inflating: data/train_imgs/P001291.png  \n",
            "  inflating: data/train_imgs/P001292.png  \n",
            "  inflating: data/train_imgs/P001293.png  \n",
            "  inflating: data/train_imgs/P001294.png  \n",
            "  inflating: data/train_imgs/P001295.png  \n",
            "  inflating: data/train_imgs/P001296.png  \n",
            "  inflating: data/train_imgs/P001297.png  \n",
            "  inflating: data/train_imgs/P001298.png  \n",
            "  inflating: data/train_imgs/P001299.png  \n",
            "  inflating: data/train_imgs/P001300.png  \n",
            "  inflating: data/train_imgs/P001301.png  \n",
            "  inflating: data/train_imgs/P001302.png  \n",
            "  inflating: data/train_imgs/P001303.png  \n",
            "  inflating: data/train_imgs/P001304.png  \n",
            "  inflating: data/train_imgs/P001305.png  \n",
            "  inflating: data/train_imgs/P001306.png  \n",
            "  inflating: data/train_imgs/P001307.png  \n",
            "  inflating: data/train_imgs/P001308.png  \n",
            "  inflating: data/train_imgs/P001309.png  \n",
            "  inflating: data/train_imgs/P001310.png  \n",
            "  inflating: data/train_imgs/P001311.png  \n",
            "  inflating: data/train_imgs/P001312.png  \n",
            "  inflating: data/train_imgs/P001313.png  \n",
            "  inflating: data/train_imgs/P001314.png  \n",
            "  inflating: data/train_imgs/P001315.png  \n",
            "  inflating: data/train_imgs/P001316.png  \n",
            "  inflating: data/train_imgs/P001317.png  \n",
            "  inflating: data/train_imgs/P001318.png  \n",
            "  inflating: data/train_imgs/P001319.png  \n",
            "  inflating: data/train_imgs/P001320.png  \n",
            "  inflating: data/train_imgs/P001321.png  \n",
            "  inflating: data/train_imgs/P001322.png  \n",
            "  inflating: data/train_imgs/P001323.png  \n",
            "  inflating: data/train_imgs/P001324.png  \n",
            "  inflating: data/train_imgs/P001325.png  \n",
            "  inflating: data/train_imgs/P001326.png  \n",
            "  inflating: data/train_imgs/P001327.png  \n",
            "  inflating: data/train_imgs/P001328.png  \n",
            "  inflating: data/train_imgs/P001329.png  \n",
            "  inflating: data/train_imgs/P001330.png  \n",
            "  inflating: data/train_imgs/P001331.png  \n",
            "  inflating: data/train_imgs/P001332.png  \n",
            "  inflating: data/train_imgs/P001333.png  \n",
            "  inflating: data/train_imgs/P001334.png  \n",
            "  inflating: data/train_imgs/P001335.png  \n",
            "  inflating: data/train_imgs/P001336.png  \n",
            "  inflating: data/train_imgs/P001337.png  \n",
            "  inflating: data/train_imgs/P001338.png  \n",
            "  inflating: data/train_imgs/P001339.png  \n",
            "  inflating: data/train_imgs/P001340.png  \n",
            "  inflating: data/train_imgs/P001341.png  \n",
            "  inflating: data/train_imgs/P001342.png  \n",
            "  inflating: data/train_imgs/P001343.png  \n",
            "  inflating: data/train_imgs/P001344.png  \n",
            "  inflating: data/train_imgs/P001345.png  \n",
            "  inflating: data/train_imgs/P001346.png  \n",
            "  inflating: data/train_imgs/P001347.png  \n",
            "  inflating: data/train_imgs/P001348.png  \n",
            "  inflating: data/train_imgs/P001349.png  \n",
            "  inflating: data/train_imgs/P001350.png  \n",
            "  inflating: data/train_imgs/P001351.png  \n",
            "  inflating: data/train_imgs/P001352.png  \n",
            "  inflating: data/train_imgs/P001353.png  \n",
            "  inflating: data/train_imgs/P001354.png  \n",
            "  inflating: data/train_imgs/P001355.png  \n",
            "  inflating: data/train_imgs/P001356.png  \n",
            "  inflating: data/train_imgs/P001357.png  \n",
            "  inflating: data/train_imgs/P001358.png  \n",
            "  inflating: data/train_imgs/P001359.png  \n",
            "  inflating: data/train_imgs/P001360.png  \n",
            "  inflating: data/train_imgs/P001361.png  \n",
            "  inflating: data/train_imgs/P001362.png  \n",
            "  inflating: data/train_imgs/P001363.png  \n",
            "  inflating: data/train_imgs/P001364.png  \n",
            "  inflating: data/train_imgs/P001365.png  \n",
            "  inflating: data/train_imgs/P001366.png  \n",
            "  inflating: data/train_imgs/P001367.png  \n",
            "  inflating: data/train_imgs/P001368.png  \n",
            "  inflating: data/train_imgs/P001369.png  \n",
            "  inflating: data/train_imgs/P001370.png  \n",
            "  inflating: data/train_imgs/P001371.png  \n",
            "  inflating: data/train_imgs/P001372.png  \n",
            "  inflating: data/train_imgs/P001373.png  \n",
            "  inflating: data/train_imgs/P001374.png  \n",
            "  inflating: data/train_imgs/P001375.png  \n",
            "  inflating: data/train_imgs/P001376.png  \n",
            "  inflating: data/train_imgs/P001377.png  \n",
            "  inflating: data/train_imgs/P001378.png  \n",
            "  inflating: data/train_imgs/P001379.png  \n",
            "  inflating: data/train_imgs/P001380.png  \n",
            "  inflating: data/train_imgs/P001381.png  \n",
            "  inflating: data/train_imgs/P001382.png  \n",
            "  inflating: data/train_imgs/P001383.png  \n",
            "  inflating: data/train_imgs/P001384.png  \n",
            "  inflating: data/train_imgs/P001385.png  \n",
            "  inflating: data/train_imgs/P001386.png  \n",
            "  inflating: data/train_imgs/P001387.png  \n",
            "  inflating: data/train_imgs/P001388.png  \n",
            "  inflating: data/train_imgs/P001389.png  \n",
            "  inflating: data/train_imgs/P001390.png  \n",
            "  inflating: data/train_imgs/P001391.png  \n",
            "  inflating: data/train_imgs/P001392.png  \n",
            "  inflating: data/train_imgs/P001393.png  \n",
            "  inflating: data/train_imgs/P001394.png  \n",
            "  inflating: data/train_imgs/P001395.png  \n",
            "  inflating: data/train_imgs/P001396.png  \n",
            "  inflating: data/train_imgs/P001397.png  \n",
            "  inflating: data/train_imgs/P001398.png  \n",
            "  inflating: data/train_imgs/P001399.png  \n",
            "  inflating: data/train_imgs/P001400.png  \n",
            "  inflating: data/train_imgs/P001401.png  \n",
            "  inflating: data/train_imgs/P001402.png  \n",
            "  inflating: data/train_imgs/P001403.png  \n",
            "  inflating: data/train_imgs/P001404.png  \n",
            "  inflating: data/train_imgs/P001405.png  \n",
            "  inflating: data/train_imgs/P001406.png  \n",
            "  inflating: data/train_imgs/P001407.png  \n",
            "  inflating: data/train_imgs/P001408.png  \n",
            "  inflating: data/train_imgs/P001409.png  \n",
            "  inflating: data/train_imgs/P001410.png  \n",
            "  inflating: data/train_imgs/P001411.png  \n",
            "  inflating: data/train_imgs/P001412.png  \n",
            "  inflating: data/train_imgs/P001413.png  \n",
            "  inflating: data/train_imgs/P001414.png  \n",
            "  inflating: data/train_imgs/P001415.png  \n",
            "  inflating: data/train_imgs/P001416.png  \n",
            "  inflating: data/train_imgs/P001417.png  \n",
            "  inflating: data/train_imgs/P001418.png  \n",
            "  inflating: data/train_imgs/P001419.png  \n",
            "  inflating: data/train_imgs/P001420.png  \n",
            "  inflating: data/train_imgs/P001421.png  \n",
            "  inflating: data/train_imgs/P001422.png  \n",
            "  inflating: data/train_imgs/P001423.png  \n",
            "  inflating: data/train_imgs/P001424.png  \n",
            "  inflating: data/train_imgs/P001425.png  \n",
            "  inflating: data/train_imgs/P001426.png  \n",
            "  inflating: data/train_imgs/P001427.png  \n",
            "  inflating: data/train_imgs/P001428.png  \n",
            "  inflating: data/train_imgs/P001429.png  \n",
            "  inflating: data/train_imgs/P001430.png  \n",
            "  inflating: data/train_imgs/P001431.png  \n",
            "  inflating: data/train_imgs/P001432.png  \n",
            "  inflating: data/train_imgs/P001433.png  \n",
            "  inflating: data/train_imgs/P001434.png  \n",
            "  inflating: data/train_imgs/P001435.png  \n",
            "  inflating: data/train_imgs/P001436.png  \n",
            "  inflating: data/train_imgs/P001437.png  \n",
            "  inflating: data/train_imgs/P001438.png  \n",
            "  inflating: data/train_imgs/P001439.png  \n",
            "  inflating: data/train_imgs/P001440.png  \n",
            "  inflating: data/train_imgs/P001441.png  \n",
            "  inflating: data/train_imgs/P001442.png  \n",
            "  inflating: data/train_imgs/P001443.png  \n",
            "  inflating: data/train_imgs/P001444.png  \n",
            "  inflating: data/train_imgs/P001445.png  \n",
            "  inflating: data/train_imgs/P001446.png  \n",
            "  inflating: data/train_imgs/P001447.png  \n",
            "  inflating: data/train_imgs/P001448.png  \n",
            "  inflating: data/train_imgs/P001449.png  \n",
            "  inflating: data/train_imgs/P001450.png  \n",
            "  inflating: data/train_imgs/P001451.png  \n",
            "  inflating: data/train_imgs/P001452.png  \n",
            "  inflating: data/train_imgs/P001453.png  \n",
            "  inflating: data/train_imgs/P001454.png  \n",
            "  inflating: data/train_imgs/P001455.png  \n",
            "  inflating: data/train_imgs/P001456.png  \n",
            "  inflating: data/train_imgs/P001457.png  \n",
            "  inflating: data/train_imgs/P001458.png  \n",
            "  inflating: data/train_imgs/P001459.png  \n",
            "  inflating: data/train_imgs/P001460.png  \n",
            "  inflating: data/train_imgs/P001461.png  \n",
            "  inflating: data/train_imgs/P001462.png  \n",
            "  inflating: data/train_imgs/P001463.png  \n",
            "  inflating: data/train_imgs/P001464.png  \n",
            "  inflating: data/train_imgs/P001465.png  \n",
            "  inflating: data/train_imgs/P001466.png  \n",
            "  inflating: data/train_imgs/P001467.png  \n",
            "  inflating: data/train_imgs/P001468.png  \n",
            "  inflating: data/train_imgs/P001469.png  \n",
            "  inflating: data/train_imgs/P001470.png  \n",
            "  inflating: data/train_imgs/P001471.png  \n",
            "  inflating: data/train_imgs/P001472.png  \n",
            "  inflating: data/train_imgs/P001473.png  \n",
            "  inflating: data/train_imgs/P001474.png  \n",
            "  inflating: data/train_imgs/P001475.png  \n",
            "  inflating: data/train_imgs/P001476.png  \n",
            "  inflating: data/train_imgs/P001477.png  \n",
            "  inflating: data/train_imgs/P001478.png  \n",
            "  inflating: data/train_imgs/P001479.png  \n",
            "  inflating: data/train_imgs/P001480.png  \n",
            "  inflating: data/train_imgs/P001481.png  \n",
            "  inflating: data/train_imgs/P001482.png  \n",
            "  inflating: data/train_imgs/P001483.png  \n",
            "  inflating: data/train_imgs/P001484.png  \n",
            "  inflating: data/train_imgs/P001485.png  \n",
            "  inflating: data/train_imgs/P001486.png  \n",
            "  inflating: data/train_imgs/P001487.png  \n",
            "  inflating: data/train_imgs/P001488.png  \n",
            "  inflating: data/train_imgs/P001489.png  \n",
            "  inflating: data/train_imgs/P001490.png  \n",
            "  inflating: data/train_imgs/P001491.png  \n",
            "  inflating: data/train_imgs/P001492.png  \n",
            "  inflating: data/train_imgs/P001493.png  \n",
            "  inflating: data/train_imgs/P001494.png  \n",
            "  inflating: data/train_imgs/P001495.png  \n",
            "  inflating: data/train_imgs/P001496.png  \n",
            "  inflating: data/train_imgs/P001497.png  \n",
            "  inflating: data/train_imgs/P001498.png  \n",
            "  inflating: data/train_imgs/P001499.png  \n",
            "  inflating: data/train_imgs/P001500.png  \n",
            "  inflating: data/train_imgs/P001501.png  \n",
            "  inflating: data/train_imgs/P001502.png  \n",
            "  inflating: data/train_imgs/P001503.png  \n",
            "  inflating: data/train_imgs/P001504.png  \n",
            "  inflating: data/train_imgs/P001505.png  \n",
            "  inflating: data/train_imgs/P001506.png  \n",
            "  inflating: data/train_imgs/P001507.png  \n",
            "  inflating: data/train_imgs/P001508.png  \n",
            "  inflating: data/train_imgs/P001509.png  \n",
            "  inflating: data/train_imgs/P001510.png  \n",
            "  inflating: data/train_imgs/P001511.png  \n",
            "  inflating: data/train_imgs/P001512.png  \n",
            "  inflating: data/train_imgs/P001513.png  \n",
            "  inflating: data/train_imgs/P001514.png  \n",
            "  inflating: data/train_imgs/P001515.png  \n",
            "  inflating: data/train_imgs/P001516.png  \n",
            "  inflating: data/train_imgs/P001517.png  \n",
            "  inflating: data/train_imgs/P001518.png  \n",
            "  inflating: data/train_imgs/P001519.png  \n",
            "  inflating: data/train_imgs/P001520.png  \n",
            "  inflating: data/train_imgs/P001521.png  \n",
            "  inflating: data/train_imgs/P001522.png  \n",
            "  inflating: data/train_imgs/P001523.png  \n",
            "  inflating: data/train_imgs/P001524.png  \n",
            "  inflating: data/train_imgs/P001525.png  \n",
            "  inflating: data/train_imgs/P001526.png  \n",
            "  inflating: data/train_imgs/P001527.png  \n",
            "  inflating: data/train_imgs/P001528.png  \n",
            "  inflating: data/train_imgs/P001529.png  \n",
            "  inflating: data/train_imgs/P001530.png  \n",
            "  inflating: data/train_imgs/P001531.png  \n",
            "  inflating: data/train_imgs/P001532.png  \n",
            "  inflating: data/train_imgs/P001533.png  \n",
            "  inflating: data/train_imgs/P001534.png  \n",
            "  inflating: data/train_imgs/P001535.png  \n",
            "  inflating: data/train_imgs/P001536.png  \n",
            "  inflating: data/train_imgs/P001537.png  \n",
            "  inflating: data/train_imgs/P001538.png  \n",
            "  inflating: data/train_imgs/P001539.png  \n",
            "  inflating: data/train_imgs/P001540.png  \n",
            "  inflating: data/train_imgs/P001541.png  \n",
            "  inflating: data/train_imgs/P001542.png  \n",
            "  inflating: data/train_imgs/P001543.png  \n",
            "  inflating: data/train_imgs/P001544.png  \n",
            "  inflating: data/train_imgs/P001545.png  \n",
            "  inflating: data/train_imgs/P001546.png  \n",
            "  inflating: data/train_imgs/P001547.png  \n",
            "  inflating: data/train_imgs/P001548.png  \n",
            "  inflating: data/train_imgs/P001549.png  \n",
            "  inflating: data/train_imgs/P001550.png  \n",
            "  inflating: data/train_imgs/P001551.png  \n",
            "  inflating: data/train_imgs/P001552.png  \n",
            "  inflating: data/train_imgs/P001553.png  \n",
            "  inflating: data/train_imgs/P001554.png  \n",
            "  inflating: data/train_imgs/P001555.png  \n",
            "  inflating: data/train_imgs/P001556.png  \n",
            "  inflating: data/train_imgs/P001557.png  \n",
            "  inflating: data/train_imgs/P001558.png  \n",
            "  inflating: data/train_imgs/P001559.png  \n",
            "  inflating: data/train_imgs/P001560.png  \n",
            "  inflating: data/train_imgs/P001561.png  \n",
            "  inflating: data/train_imgs/P001562.png  \n",
            "  inflating: data/train_imgs/P001563.png  \n",
            "  inflating: data/train_imgs/P001564.png  \n",
            "  inflating: data/train_imgs/P001565.png  \n",
            "  inflating: data/train_imgs/P001566.png  \n",
            "  inflating: data/train_imgs/P001567.png  \n",
            "  inflating: data/train_imgs/P001568.png  \n",
            "  inflating: data/train_imgs/P001569.png  \n",
            "  inflating: data/train_imgs/P001570.png  \n",
            "  inflating: data/train_imgs/P001571.png  \n",
            "  inflating: data/train_imgs/P001572.png  \n",
            "  inflating: data/train_imgs/P001573.png  \n",
            "  inflating: data/train_imgs/P001574.png  \n",
            "  inflating: data/train_imgs/P001575.png  \n",
            "  inflating: data/train_imgs/P001576.png  \n",
            "  inflating: data/train_imgs/P001577.png  \n",
            "  inflating: data/train_imgs/P001578.png  \n",
            "  inflating: data/train_imgs/P001579.png  \n",
            "  inflating: data/train_imgs/P001580.png  \n",
            "  inflating: data/train_imgs/P001581.png  \n",
            "  inflating: data/train_imgs/P001582.png  \n",
            "  inflating: data/train_imgs/P001583.png  \n",
            "  inflating: data/train_imgs/P001584.png  \n",
            "  inflating: data/train_imgs/P001585.png  \n",
            "  inflating: data/train_imgs/P001586.png  \n",
            "  inflating: data/train_imgs/P001587.png  \n",
            "  inflating: data/train_imgs/P001588.png  \n",
            "  inflating: data/train_imgs/P001589.png  \n",
            "  inflating: data/train_imgs/P001590.png  \n",
            "  inflating: data/train_imgs/P001591.png  \n",
            "  inflating: data/train_imgs/P001592.png  \n",
            "  inflating: data/train_imgs/P001593.png  \n",
            "  inflating: data/train_imgs/P001594.png  \n",
            "  inflating: data/train_imgs/P001595.png  \n",
            "  inflating: data/train_imgs/P001596.png  \n",
            "  inflating: data/train_imgs/P001597.png  \n",
            "  inflating: data/train_imgs/P001598.png  \n",
            "  inflating: data/train_imgs/P001599.png  \n",
            "  inflating: data/train_imgs/P001600.png  \n",
            "  inflating: data/train_imgs/P001601.png  \n",
            "  inflating: data/train_imgs/P001602.png  \n",
            "  inflating: data/train_imgs/P001603.png  \n",
            "  inflating: data/train_imgs/P001604.png  \n",
            "  inflating: data/train_imgs/P001605.png  \n",
            "  inflating: data/train_imgs/P001606.png  \n",
            "  inflating: data/train_imgs/P001607.png  \n",
            "  inflating: data/train_imgs/P001608.png  \n",
            "  inflating: data/train_imgs/P001609.png  \n",
            "  inflating: data/train_imgs/P001610.png  \n",
            "  inflating: data/train_imgs/P001611.png  \n",
            "  inflating: data/train_imgs/P001612.png  \n",
            "  inflating: data/train_imgs/P001613.png  \n",
            "  inflating: data/train_imgs/P001614.png  \n",
            "  inflating: data/train_imgs/P001615.png  \n",
            "  inflating: data/train_imgs/P001616.png  \n",
            "  inflating: data/train_imgs/P001617.png  \n",
            "  inflating: data/train_imgs/P001618.png  \n",
            "  inflating: data/train_imgs/P001619.png  \n",
            "  inflating: data/train_imgs/P001620.png  \n",
            "  inflating: data/train_imgs/P001621.png  \n",
            "  inflating: data/train_imgs/P001622.png  \n",
            "  inflating: data/train_imgs/P001623.png  \n",
            "  inflating: data/train_imgs/P001624.png  \n",
            "  inflating: data/train_imgs/P001625.png  \n",
            "  inflating: data/train_imgs/P001626.png  \n",
            "  inflating: data/train_imgs/P001627.png  \n",
            "  inflating: data/train_imgs/P001628.png  \n",
            "  inflating: data/train_imgs/P001629.png  \n",
            "  inflating: data/train_imgs/P001630.png  \n",
            "  inflating: data/train_imgs/P001631.png  \n",
            "  inflating: data/train_imgs/P001632.png  \n",
            "  inflating: data/train_imgs/P001633.png  \n",
            "  inflating: data/train_imgs/P001634.png  \n",
            "  inflating: data/train_imgs/P001635.png  \n",
            "  inflating: data/train_imgs/P001636.png  \n",
            "  inflating: data/train_imgs/P001637.png  \n",
            "  inflating: data/train_imgs/P001638.png  \n",
            "  inflating: data/train_imgs/P001639.png  \n",
            "  inflating: data/train_imgs/P001640.png  \n",
            "  inflating: data/train_imgs/P001641.png  \n",
            "  inflating: data/train_imgs/P001642.png  \n",
            "  inflating: data/train_imgs/P001643.png  \n",
            "  inflating: data/train_imgs/P001644.png  \n",
            "  inflating: data/train_imgs/P001645.png  \n",
            "  inflating: data/train_imgs/P001646.png  \n",
            "  inflating: data/train_imgs/P001647.png  \n",
            "  inflating: data/train_imgs/P001648.png  \n",
            "  inflating: data/train_imgs/P001649.png  \n",
            "  inflating: data/train_imgs/P001650.png  \n",
            "  inflating: data/train_imgs/P001651.png  \n",
            "  inflating: data/train_imgs/P001652.png  \n",
            "  inflating: data/train_imgs/P001653.png  \n",
            "  inflating: data/train_imgs/P001654.png  \n",
            "  inflating: data/train_imgs/P001655.png  \n",
            "  inflating: data/train_imgs/P001656.png  \n",
            "  inflating: data/train_imgs/P001657.png  \n",
            "  inflating: data/train_imgs/P001658.png  \n",
            "  inflating: data/train_imgs/P001659.png  \n",
            "  inflating: data/train_imgs/P001660.png  \n",
            "  inflating: data/train_imgs/P001661.png  \n",
            "  inflating: data/train_imgs/P001662.png  \n",
            "  inflating: data/train_imgs/P001663.png  \n",
            "  inflating: data/train_imgs/P001664.png  \n",
            "  inflating: data/train_imgs/P001665.png  \n",
            "  inflating: data/train_imgs/P001666.png  \n",
            "  inflating: data/train_imgs/P001667.png  \n",
            "  inflating: data/train_imgs/P001668.png  \n",
            "  inflating: data/train_imgs/P001669.png  \n",
            "  inflating: data/train_imgs/P001670.png  \n",
            "  inflating: data/train_imgs/P001671.png  \n",
            "  inflating: data/train_imgs/P001672.png  \n",
            "  inflating: data/train_imgs/P001673.png  \n",
            "  inflating: data/train_imgs/P001674.png  \n",
            "  inflating: data/train_imgs/P001675.png  \n",
            "  inflating: data/train_imgs/P001676.png  \n",
            "  inflating: data/train_imgs/P001677.png  \n",
            "  inflating: data/train_imgs/P001678.png  \n",
            "  inflating: data/train_imgs/P001679.png  \n",
            "  inflating: data/train_imgs/P001680.png  \n",
            "  inflating: data/train_imgs/P001681.png  \n",
            "  inflating: data/train_imgs/P001682.png  \n",
            "  inflating: data/train_imgs/P001683.png  \n",
            "  inflating: data/train_imgs/P001684.png  \n",
            "  inflating: data/train_imgs/P001685.png  \n",
            "  inflating: data/train_imgs/P001686.png  \n",
            "  inflating: data/train_imgs/P001687.png  \n",
            "  inflating: data/train_imgs/P001688.png  \n",
            "  inflating: data/train_imgs/P001689.png  \n",
            "  inflating: data/train_imgs/P001690.png  \n",
            "  inflating: data/train_imgs/P001691.png  \n",
            "  inflating: data/train_imgs/P001692.png  \n",
            "  inflating: data/train_imgs/P001693.png  \n",
            "  inflating: data/train_imgs/P001694.png  \n",
            "  inflating: data/train_imgs/P001695.png  \n",
            "  inflating: data/train_imgs/P001696.png  \n",
            "  inflating: data/train_imgs/P001697.png  \n",
            "  inflating: data/train_imgs/P001698.png  \n",
            "  inflating: data/train_imgs/P001699.png  \n",
            "  inflating: data/train_imgs/P001700.png  \n",
            "  inflating: data/train_imgs/P001701.png  \n",
            "  inflating: data/train_imgs/P001702.png  \n",
            "  inflating: data/train_imgs/P001703.png  \n",
            "  inflating: data/train_imgs/P001704.png  \n",
            "  inflating: data/train_imgs/P001705.png  \n",
            "  inflating: data/train_imgs/P001706.png  \n",
            "  inflating: data/train_imgs/P001707.png  \n",
            "  inflating: data/train_imgs/P001708.png  \n",
            "  inflating: data/train_imgs/P001709.png  \n",
            "  inflating: data/train_imgs/P001710.png  \n",
            "  inflating: data/train_imgs/P001711.png  \n",
            "  inflating: data/train_imgs/P001712.png  \n",
            "  inflating: data/train_imgs/P001713.png  \n",
            "  inflating: data/train_imgs/P001714.png  \n",
            "  inflating: data/train_imgs/P001715.png  \n",
            "  inflating: data/train_imgs/P001716.png  \n",
            "  inflating: data/train_imgs/P001717.png  \n",
            "  inflating: data/train_imgs/P001718.png  \n",
            "  inflating: data/train_imgs/P001719.png  \n",
            "  inflating: data/train_imgs/P001720.png  \n",
            "  inflating: data/train_imgs/P001721.png  \n",
            "  inflating: data/train_imgs/P001722.png  \n",
            "  inflating: data/train_imgs/P001723.png  \n",
            "  inflating: data/train_imgs/P001724.png  \n",
            "  inflating: data/train_imgs/P001725.png  \n",
            "  inflating: data/train_imgs/P001726.png  \n",
            "  inflating: data/train_imgs/P001727.png  \n",
            "  inflating: data/train_imgs/P001728.png  \n",
            "  inflating: data/train_imgs/P001729.png  \n",
            "  inflating: data/train_imgs/P001730.png  \n",
            "  inflating: data/train_imgs/P001731.png  \n",
            "  inflating: data/train_imgs/P001732.png  \n",
            "  inflating: data/train_imgs/P001733.png  \n",
            "  inflating: data/train_imgs/P001734.png  \n",
            "  inflating: data/train_imgs/P001735.png  \n",
            "  inflating: data/train_imgs/P001736.png  \n",
            "  inflating: data/train_imgs/P001737.png  \n",
            "  inflating: data/train_imgs/P001738.png  \n",
            "  inflating: data/train_imgs/P001739.png  \n",
            "  inflating: data/train_imgs/P001740.png  \n",
            "  inflating: data/train_imgs/P001741.png  \n",
            "  inflating: data/train_imgs/P001742.png  \n",
            "  inflating: data/train_imgs/P001743.png  \n",
            "  inflating: data/train_imgs/P001744.png  \n",
            "  inflating: data/train_imgs/P001745.png  \n",
            "  inflating: data/train_imgs/P001746.png  \n",
            "  inflating: data/train_imgs/P001747.png  \n",
            "  inflating: data/train_imgs/P001748.png  \n",
            "  inflating: data/train_imgs/P001749.png  \n",
            "  inflating: data/train_imgs/P001750.png  \n",
            "  inflating: data/train_imgs/P001751.png  \n",
            "  inflating: data/train_imgs/P001752.png  \n",
            "  inflating: data/train_imgs/P001753.png  \n",
            "  inflating: data/train_imgs/P001754.png  \n",
            "  inflating: data/train_imgs/P001755.png  \n",
            "  inflating: data/train_imgs/P001756.png  \n",
            "  inflating: data/train_imgs/P001757.png  \n",
            "  inflating: data/train_imgs/P001758.png  \n",
            "  inflating: data/train_imgs/P001759.png  \n",
            "  inflating: data/train_imgs/P001760.png  \n",
            "  inflating: data/train_imgs/P001761.png  \n",
            "  inflating: data/train_imgs/P001762.png  \n",
            "  inflating: data/train_imgs/P001763.png  \n",
            "  inflating: data/train_imgs/P001764.png  \n",
            "  inflating: data/train_imgs/P001765.png  \n",
            "  inflating: data/train_imgs/P001766.png  \n",
            "  inflating: data/train_imgs/P001767.png  \n",
            "  inflating: data/train_imgs/P001768.png  \n",
            "  inflating: data/train_imgs/P001769.png  \n",
            "  inflating: data/train_imgs/P001770.png  \n",
            "  inflating: data/train_imgs/P001771.png  \n",
            "  inflating: data/train_imgs/P001772.png  \n",
            "  inflating: data/train_imgs/P001773.png  \n",
            "  inflating: data/train_imgs/P001774.png  \n",
            "  inflating: data/train_imgs/P001775.png  \n",
            "  inflating: data/train_imgs/P001776.png  \n",
            "  inflating: data/train_imgs/P001777.png  \n",
            "  inflating: data/train_imgs/P001778.png  \n",
            "  inflating: data/train_imgs/P001779.png  \n",
            "  inflating: data/train_imgs/P001780.png  \n",
            "  inflating: data/train_imgs/P001781.png  \n",
            "  inflating: data/train_imgs/P001782.png  \n",
            "  inflating: data/train_imgs/P001783.png  \n",
            "  inflating: data/train_imgs/P001784.png  \n",
            "  inflating: data/train_imgs/P001785.png  \n",
            "  inflating: data/train_imgs/P001786.png  \n",
            "  inflating: data/train_imgs/P001787.png  \n",
            "  inflating: data/train_imgs/P001788.png  \n",
            "  inflating: data/train_imgs/P001789.png  \n",
            "  inflating: data/train_imgs/P001790.png  \n",
            "  inflating: data/train_imgs/P001791.png  \n",
            "  inflating: data/train_imgs/P001792.png  \n",
            "  inflating: data/train_imgs/P001793.png  \n",
            "  inflating: data/train_imgs/P001794.png  \n",
            "  inflating: data/train_imgs/P001795.png  \n",
            "  inflating: data/train_imgs/P001796.png  \n",
            "  inflating: data/train_imgs/P001797.png  \n",
            "  inflating: data/train_imgs/P001798.png  \n",
            "  inflating: data/train_imgs/P001799.png  \n",
            "  inflating: data/train_imgs/P001800.png  \n",
            "  inflating: data/train_imgs/P001801.png  \n",
            "  inflating: data/train_imgs/P001802.png  \n",
            "  inflating: data/train_imgs/P001803.png  \n",
            "  inflating: data/train_imgs/P001804.png  \n",
            "  inflating: data/train_imgs/P001805.png  \n",
            "  inflating: data/train_imgs/P001806.png  \n",
            "  inflating: data/train_imgs/P001807.png  \n",
            "  inflating: data/train_imgs/P001808.png  \n",
            "  inflating: data/train_imgs/P001809.png  \n",
            "  inflating: data/train_imgs/P001810.png  \n",
            "  inflating: data/train_imgs/P001811.png  \n",
            "  inflating: data/train_imgs/P001812.png  \n",
            "  inflating: data/train_imgs/P001813.png  \n",
            "  inflating: data/train_imgs/P001814.png  \n",
            "  inflating: data/train_imgs/P001815.png  \n",
            "  inflating: data/train_imgs/P001816.png  \n",
            "  inflating: data/train_imgs/P001817.png  \n",
            "  inflating: data/train_imgs/P001818.png  \n",
            "  inflating: data/train_imgs/P001819.png  \n",
            "  inflating: data/train_imgs/P001820.png  \n",
            "  inflating: data/train_imgs/P001821.png  \n",
            "  inflating: data/train_imgs/P001822.png  \n",
            "  inflating: data/train_imgs/P001823.png  \n",
            "  inflating: data/train_imgs/P001824.png  \n",
            "  inflating: data/train_imgs/P001825.png  \n",
            "  inflating: data/train_imgs/P001826.png  \n",
            "  inflating: data/train_imgs/P001827.png  \n",
            "  inflating: data/train_imgs/P001828.png  \n",
            "  inflating: data/train_imgs/P001829.png  \n",
            "  inflating: data/train_imgs/P001830.png  \n",
            "  inflating: data/train_imgs/P001831.png  \n",
            "  inflating: data/train_imgs/P001832.png  \n",
            "  inflating: data/train_imgs/P001833.png  \n",
            "  inflating: data/train_imgs/P001834.png  \n",
            "  inflating: data/train_imgs/P001835.png  \n",
            "  inflating: data/train_imgs/P001836.png  \n",
            "  inflating: data/train_imgs/P001837.png  \n",
            "  inflating: data/train_imgs/P001838.png  \n",
            "  inflating: data/train_imgs/P001839.png  \n",
            "  inflating: data/train_imgs/P001840.png  \n",
            "  inflating: data/train_imgs/P001841.png  \n",
            "  inflating: data/train_imgs/P001842.png  \n",
            "  inflating: data/train_imgs/P001843.png  \n",
            "  inflating: data/train_imgs/P001844.png  \n",
            "  inflating: data/train_imgs/P001845.png  \n",
            "  inflating: data/train_imgs/P001846.png  \n",
            "  inflating: data/train_imgs/P001847.png  \n",
            "  inflating: data/train_imgs/P001848.png  \n",
            "  inflating: data/train_imgs/P001849.png  \n",
            "  inflating: data/train_imgs/P001850.png  \n",
            "  inflating: data/train_imgs/P001851.png  \n",
            "  inflating: data/train_imgs/P001852.png  \n",
            "  inflating: data/train_imgs/P001853.png  \n",
            "  inflating: data/train_imgs/P001854.png  \n",
            "  inflating: data/train_imgs/P001855.png  \n",
            "  inflating: data/train_imgs/P001856.png  \n",
            "  inflating: data/train_imgs/P001857.png  \n",
            "  inflating: data/train_imgs/P001858.png  \n",
            "  inflating: data/train_imgs/P001859.png  \n",
            "  inflating: data/train_imgs/P001860.png  \n",
            "  inflating: data/train_imgs/P001861.png  \n",
            "  inflating: data/train_imgs/P001862.png  \n",
            "  inflating: data/train_imgs/P001863.png  \n",
            "  inflating: data/train_imgs/P001864.png  \n",
            "  inflating: data/train_imgs/P001865.png  \n",
            "  inflating: data/train_imgs/P001866.png  \n",
            "  inflating: data/train_imgs/P001867.png  \n",
            "  inflating: data/train_imgs/P001868.png  \n",
            "  inflating: data/train_imgs/P001869.png  \n",
            "  inflating: data/train_imgs/P001870.png  \n",
            "  inflating: data/train_imgs/P001871.png  \n",
            "  inflating: data/train_imgs/P001872.png  \n",
            "  inflating: data/train_imgs/P001873.png  \n",
            "  inflating: data/train_imgs/P001874.png  \n",
            "  inflating: data/train_imgs/P001875.png  \n",
            "  inflating: data/train_imgs/P001876.png  \n",
            "  inflating: data/train_imgs/P001877.png  \n",
            "  inflating: data/train_imgs/P001878.png  \n",
            "  inflating: data/train_imgs/P001879.png  \n",
            "  inflating: data/train_imgs/P001880.png  \n",
            "  inflating: data/train_imgs/P001881.png  \n",
            "  inflating: data/train_imgs/P001882.png  \n",
            "  inflating: data/train_imgs/P001883.png  \n",
            "  inflating: data/train_imgs/P001884.png  \n",
            "  inflating: data/train_imgs/P001885.png  \n",
            "  inflating: data/train_imgs/P001886.png  \n",
            "  inflating: data/train_imgs/P001887.png  \n",
            "  inflating: data/train_imgs/P001888.png  \n",
            "  inflating: data/train_imgs/P001889.png  \n",
            "  inflating: data/train_imgs/P001890.png  \n",
            "  inflating: data/train_imgs/P001891.png  \n",
            "  inflating: data/train_imgs/P001892.png  \n",
            "  inflating: data/train_imgs/P001893.png  \n",
            "  inflating: data/train_imgs/P001894.png  \n",
            "  inflating: data/train_imgs/P001895.png  \n",
            "  inflating: data/train_imgs/P001896.png  \n",
            "  inflating: data/train_imgs/P001897.png  \n",
            "  inflating: data/train_imgs/P001898.png  \n",
            "  inflating: data/train_imgs/P001899.png  \n",
            "  inflating: data/train_imgs/P001900.png  \n",
            "  inflating: data/train_imgs/P001901.png  \n",
            "  inflating: data/train_imgs/P001902.png  \n",
            "  inflating: data/train_imgs/P001903.png  \n",
            "  inflating: data/train_imgs/P001904.png  \n",
            "  inflating: data/train_imgs/P001905.png  \n",
            "  inflating: data/train_imgs/P001906.png  \n",
            "  inflating: data/train_imgs/P001907.png  \n",
            "  inflating: data/train_imgs/P001908.png  \n",
            "  inflating: data/train_imgs/P001909.png  \n",
            "  inflating: data/train_imgs/P001910.png  \n",
            "  inflating: data/train_imgs/P001911.png  \n",
            "  inflating: data/train_imgs/P001912.png  \n",
            "  inflating: data/train_imgs/P001913.png  \n",
            "  inflating: data/train_imgs/P001914.png  \n",
            "  inflating: data/train_imgs/P001915.png  \n",
            "  inflating: data/train_imgs/P001916.png  \n",
            "  inflating: data/train_imgs/P001917.png  \n",
            "  inflating: data/train_imgs/P001918.png  \n",
            "  inflating: data/train_imgs/P001919.png  \n",
            "  inflating: data/train_imgs/P001920.png  \n",
            "  inflating: data/train_imgs/P001921.png  \n",
            "  inflating: data/train_imgs/P001922.png  \n",
            "  inflating: data/train_imgs/P001923.png  \n",
            "  inflating: data/train_imgs/P001924.png  \n",
            "  inflating: data/train_imgs/P001925.png  \n",
            "  inflating: data/train_imgs/P001926.png  \n",
            "  inflating: data/train_imgs/P001927.png  \n",
            "  inflating: data/train_imgs/P001928.png  \n",
            "  inflating: data/train_imgs/P001929.png  \n",
            "  inflating: data/train_imgs/P001930.png  \n",
            "  inflating: data/train_imgs/P001931.png  \n",
            "  inflating: data/train_imgs/P001932.png  \n",
            "  inflating: data/train_imgs/P001933.png  \n",
            "  inflating: data/train_imgs/P001934.png  \n",
            "  inflating: data/train_imgs/P001935.png  \n",
            "  inflating: data/train_imgs/P001936.png  \n",
            "  inflating: data/train_imgs/P001937.png  \n",
            "  inflating: data/train_imgs/P001938.png  \n",
            "  inflating: data/train_imgs/P001939.png  \n",
            "  inflating: data/train_imgs/P001940.png  \n",
            "  inflating: data/train_imgs/P001941.png  \n",
            "  inflating: data/train_imgs/P001942.png  \n",
            "  inflating: data/train_imgs/P001943.png  \n",
            "  inflating: data/train_imgs/P001944.png  \n",
            "  inflating: data/train_imgs/P001945.png  \n",
            "  inflating: data/train_imgs/P001946.png  \n",
            "  inflating: data/train_imgs/P001947.png  \n",
            "  inflating: data/train_imgs/P001948.png  \n",
            "  inflating: data/train_imgs/P001949.png  \n",
            "  inflating: data/train_imgs/P001950.png  \n",
            "  inflating: data/train_imgs/P001951.png  \n",
            "  inflating: data/train_imgs/P001952.png  \n",
            "  inflating: data/train_imgs/P001953.png  \n",
            "  inflating: data/train_imgs/P001954.png  \n",
            "  inflating: data/train_imgs/P001955.png  \n",
            "  inflating: data/train_imgs/P001956.png  \n",
            "  inflating: data/train_imgs/P001957.png  \n",
            "  inflating: data/train_imgs/P001958.png  \n",
            "  inflating: data/train_imgs/P001959.png  \n",
            "  inflating: data/train_imgs/P001960.png  \n",
            "  inflating: data/train_imgs/P001961.png  \n",
            "  inflating: data/train_imgs/P001962.png  \n",
            "  inflating: data/train_imgs/P001963.png  \n",
            "  inflating: data/train_imgs/P001964.png  \n",
            "  inflating: data/train_imgs/P001965.png  \n",
            "  inflating: data/train_imgs/P001966.png  \n",
            "  inflating: data/train_imgs/P001967.png  \n",
            "  inflating: data/train_imgs/P001968.png  \n",
            "  inflating: data/train_imgs/P001969.png  \n",
            "  inflating: data/train_imgs/P001970.png  \n",
            "  inflating: data/train_imgs/P001971.png  \n",
            "  inflating: data/train_imgs/P001972.png  \n",
            "  inflating: data/train_imgs/P001973.png  \n",
            "  inflating: data/train_imgs/P001974.png  \n",
            "  inflating: data/train_imgs/P001975.png  \n",
            "  inflating: data/train_imgs/P001976.png  \n",
            "  inflating: data/train_imgs/P001977.png  \n",
            "  inflating: data/train_imgs/P001978.png  \n",
            "  inflating: data/train_imgs/P001979.png  \n",
            "  inflating: data/train_imgs/P001980.png  \n",
            "  inflating: data/train_imgs/P001981.png  \n",
            "  inflating: data/train_imgs/P001982.png  \n",
            "  inflating: data/train_imgs/P001983.png  \n",
            "  inflating: data/train_imgs/P001984.png  \n",
            "  inflating: data/train_imgs/P001985.png  \n",
            "  inflating: data/train_imgs/P001986.png  \n",
            "  inflating: data/train_imgs/P001987.png  \n",
            "  inflating: data/train_imgs/P001988.png  \n",
            "  inflating: data/train_imgs/P001989.png  \n",
            "  inflating: data/train_imgs/P001990.png  \n",
            "  inflating: data/train_imgs/P001991.png  \n",
            "  inflating: data/train_imgs/P001992.png  \n",
            "  inflating: data/train_imgs/P001993.png  \n",
            "  inflating: data/train_imgs/P001994.png  \n",
            "  inflating: data/train_imgs/P001995.png  \n",
            "  inflating: data/train_imgs/P001996.png  \n",
            "  inflating: data/train_imgs/P001997.png  \n",
            "  inflating: data/train_imgs/P001998.png  \n",
            "  inflating: data/train_imgs/P001999.png  \n",
            "  inflating: data/train_imgs/P002000.png  \n",
            "  inflating: data/train_imgs/P002001.png  \n",
            "  inflating: data/train_imgs/P002002.png  \n",
            "  inflating: data/train_imgs/P002003.png  \n",
            "  inflating: data/train_imgs/P002004.png  \n",
            "  inflating: data/train_imgs/P002005.png  \n",
            "  inflating: data/train_imgs/P002006.png  \n",
            "  inflating: data/train_imgs/P002007.png  \n",
            "  inflating: data/train_imgs/P002008.png  \n",
            "  inflating: data/train_imgs/P002009.png  \n",
            "  inflating: data/train_imgs/P002010.png  \n",
            "  inflating: data/train_imgs/P002011.png  \n",
            "  inflating: data/train_imgs/P002012.png  \n",
            "  inflating: data/train_imgs/P002013.png  \n",
            "  inflating: data/train_imgs/P002014.png  \n",
            "  inflating: data/train_imgs/P002015.png  \n",
            "  inflating: data/train_imgs/P002016.png  \n",
            "  inflating: data/train_imgs/P002017.png  \n",
            "  inflating: data/train_imgs/P002018.png  \n",
            "  inflating: data/train_imgs/P002019.png  \n",
            "  inflating: data/train_imgs/P002020.png  \n",
            "  inflating: data/train_imgs/P002021.png  \n",
            "  inflating: data/train_imgs/P002022.png  \n",
            "  inflating: data/train_imgs/P002023.png  \n",
            "  inflating: data/train_imgs/P002024.png  \n",
            "  inflating: data/train_imgs/P002025.png  \n",
            "  inflating: data/train_imgs/P002026.png  \n",
            "  inflating: data/train_imgs/P002027.png  \n",
            "  inflating: data/train_imgs/P002028.png  \n",
            "  inflating: data/train_imgs/P002029.png  \n",
            "  inflating: data/train_imgs/P002030.png  \n",
            "  inflating: data/train_imgs/P002031.png  \n",
            "  inflating: data/train_imgs/P002032.png  \n",
            "  inflating: data/train_imgs/P002033.png  \n",
            "  inflating: data/train_imgs/P002034.png  \n",
            "  inflating: data/train_imgs/P002035.png  \n",
            "  inflating: data/train_imgs/P002036.png  \n",
            "  inflating: data/train_imgs/P002037.png  \n",
            "  inflating: data/train_imgs/P002038.png  \n",
            "  inflating: data/train_imgs/P002039.png  \n",
            "  inflating: data/train_imgs/P002040.png  \n",
            "  inflating: data/train_imgs/P002041.png  \n",
            "  inflating: data/train_imgs/P002042.png  \n",
            "  inflating: data/train_imgs/P002043.png  \n",
            "  inflating: data/train_imgs/P002044.png  \n",
            "  inflating: data/train_imgs/P002045.png  \n",
            "  inflating: data/train_imgs/P002046.png  \n",
            "  inflating: data/train_imgs/P002047.png  \n",
            "  inflating: data/train_imgs/P002048.png  \n",
            "  inflating: data/train_imgs/P002049.png  \n",
            "  inflating: data/train_imgs/P002050.png  \n",
            "  inflating: data/train_imgs/P002051.png  \n",
            "  inflating: data/train_imgs/P002052.png  \n",
            "  inflating: data/train_imgs/P002053.png  \n",
            "  inflating: data/train_imgs/P002054.png  \n",
            "  inflating: data/train_imgs/P002055.png  \n",
            "  inflating: data/train_imgs/P002056.png  \n",
            "  inflating: data/train_imgs/P002057.png  \n",
            "  inflating: data/train_imgs/P002058.png  \n",
            "  inflating: data/train_imgs/P002059.png  \n",
            "  inflating: data/train_imgs/P002060.png  \n",
            "  inflating: data/train_imgs/P002061.png  \n",
            "  inflating: data/train_imgs/P002062.png  \n",
            "  inflating: data/train_imgs/P002063.png  \n",
            "  inflating: data/train_imgs/P002064.png  \n",
            "  inflating: data/train_imgs/P002065.png  \n",
            "  inflating: data/train_imgs/P002066.png  \n",
            "  inflating: data/train_imgs/P002067.png  \n",
            "  inflating: data/train_imgs/P002068.png  \n",
            "  inflating: data/train_imgs/P002069.png  \n",
            "  inflating: data/train_imgs/P002070.png  \n",
            "  inflating: data/train_imgs/P002071.png  \n",
            "  inflating: data/train_imgs/P002072.png  \n",
            "  inflating: data/train_imgs/P002073.png  \n",
            "  inflating: data/train_imgs/P002074.png  \n",
            "  inflating: data/train_imgs/P002075.png  \n",
            "  inflating: data/train_imgs/P002076.png  \n",
            "  inflating: data/train_imgs/P002077.png  \n",
            "  inflating: data/train_imgs/P002078.png  \n",
            "  inflating: data/train_imgs/P002079.png  \n",
            "  inflating: data/train_imgs/P002080.png  \n",
            "  inflating: data/train_imgs/P002081.png  \n",
            "  inflating: data/train_imgs/P002082.png  \n",
            "  inflating: data/train_imgs/P002083.png  \n",
            "  inflating: data/train_imgs/P002084.png  \n",
            "  inflating: data/train_imgs/P002085.png  \n",
            "  inflating: data/train_imgs/P002086.png  \n",
            "  inflating: data/train_imgs/P002087.png  \n",
            "  inflating: data/train_imgs/P002088.png  \n",
            "  inflating: data/train_imgs/P002089.png  \n",
            "  inflating: data/train_imgs/P002090.png  \n",
            "  inflating: data/train_imgs/P002091.png  \n",
            "  inflating: data/train_imgs/P002092.png  \n",
            "  inflating: data/train_imgs/P002093.png  \n",
            "  inflating: data/train_imgs/P002094.png  \n",
            "  inflating: data/train_imgs/P002095.png  \n",
            "  inflating: data/train_imgs/P002096.png  \n",
            "  inflating: data/train_imgs/P002097.png  \n",
            "  inflating: data/train_imgs/P002098.png  \n",
            "  inflating: data/train_imgs/P002099.png  \n",
            "  inflating: data/train_imgs/P002100.png  \n",
            "  inflating: data/train_imgs/P002101.png  \n",
            "  inflating: data/train_imgs/P002102.png  \n",
            "  inflating: data/train_imgs/P002103.png  \n",
            "  inflating: data/train_imgs/P002104.png  \n",
            "  inflating: data/train_imgs/P002105.png  \n",
            "  inflating: data/train_imgs/P002106.png  \n",
            "  inflating: data/train_imgs/P002107.png  \n",
            "  inflating: data/train_imgs/P002108.png  \n",
            "  inflating: data/train_imgs/P002109.png  \n",
            "  inflating: data/train_imgs/P002110.png  \n",
            "  inflating: data/train_imgs/P002111.png  \n",
            "  inflating: data/train_imgs/P002112.png  \n",
            "  inflating: data/train_imgs/P002113.png  \n",
            "  inflating: data/train_imgs/P002114.png  \n",
            "  inflating: data/train_imgs/P002115.png  \n",
            "  inflating: data/train_imgs/P002116.png  \n",
            "  inflating: data/train_imgs/P002117.png  \n",
            "  inflating: data/train_imgs/P002118.png  \n",
            "  inflating: data/train_imgs/P002119.png  \n",
            "  inflating: data/train_imgs/P002120.png  \n",
            "  inflating: data/train_imgs/P002121.png  \n",
            "  inflating: data/train_imgs/P002122.png  \n",
            "  inflating: data/train_imgs/P002123.png  \n",
            "  inflating: data/train_imgs/P002124.png  \n",
            "  inflating: data/train_imgs/P002125.png  \n",
            "  inflating: data/train_imgs/P002126.png  \n",
            "  inflating: data/train_imgs/P002127.png  \n",
            "  inflating: data/train_imgs/P002128.png  \n",
            "  inflating: data/train_imgs/P002129.png  \n",
            "  inflating: data/train_imgs/P002130.png  \n",
            "  inflating: data/train_imgs/P002131.png  \n",
            "  inflating: data/train_imgs/P002132.png  \n",
            "  inflating: data/train_imgs/P002133.png  \n",
            "  inflating: data/train_imgs/P002134.png  \n",
            "  inflating: data/train_imgs/P002135.png  \n",
            "  inflating: data/train_imgs/P002136.png  \n",
            "  inflating: data/train_imgs/P002137.png  \n",
            "  inflating: data/train_imgs/P002138.png  \n",
            "  inflating: data/train_imgs/P002139.png  \n",
            "  inflating: data/train_imgs/P002140.png  \n",
            "  inflating: data/train_imgs/P002141.png  \n",
            "  inflating: data/train_imgs/P002142.png  \n",
            "  inflating: data/train_imgs/P002143.png  \n",
            "  inflating: data/train_imgs/P002144.png  \n",
            "  inflating: data/train_imgs/P002145.png  \n",
            "  inflating: data/train_imgs/P002146.png  \n",
            "  inflating: data/train_imgs/P002147.png  \n",
            "  inflating: data/train_imgs/P002148.png  \n",
            "  inflating: data/train_imgs/P002149.png  \n",
            "  inflating: data/train_imgs/P002150.png  \n",
            "  inflating: data/train_imgs/P002151.png  \n",
            "  inflating: data/train_imgs/P002152.png  \n",
            "  inflating: data/train_imgs/P002153.png  \n",
            "  inflating: data/train_imgs/P002154.png  \n",
            "  inflating: data/train_imgs/P002155.png  \n",
            "  inflating: data/train_imgs/P002156.png  \n",
            "  inflating: data/train_imgs/P002157.png  \n",
            "  inflating: data/train_imgs/P002158.png  \n",
            "  inflating: data/train_imgs/P002159.png  \n",
            "  inflating: data/train_imgs/P002160.png  \n",
            "  inflating: data/train_imgs/P002161.png  \n",
            "  inflating: data/train_imgs/P002162.png  \n",
            "  inflating: data/train_imgs/P002163.png  \n",
            "  inflating: data/train_imgs/P002164.png  \n",
            "  inflating: data/train_imgs/P002165.png  \n",
            "  inflating: data/train_imgs/P002166.png  \n",
            "  inflating: data/train_imgs/P002167.png  \n",
            "  inflating: data/train_imgs/P002168.png  \n",
            "  inflating: data/train_imgs/P002169.png  \n",
            "  inflating: data/train_imgs/P002170.png  \n",
            "  inflating: data/train_imgs/P002171.png  \n",
            "  inflating: data/train_imgs/P002172.png  \n",
            "  inflating: data/train_imgs/P002173.png  \n",
            "  inflating: data/train_imgs/P002174.png  \n",
            "  inflating: data/train_imgs/P002175.png  \n",
            "  inflating: data/train_imgs/P002176.png  \n",
            "  inflating: data/train_imgs/P002177.png  \n",
            "  inflating: data/train_imgs/P002178.png  \n",
            "  inflating: data/train_imgs/P002179.png  \n",
            "  inflating: data/train_imgs/P002180.png  \n",
            "  inflating: data/train_imgs/P002181.png  \n",
            "  inflating: data/train_imgs/P002182.png  \n",
            "  inflating: data/train_imgs/P002183.png  \n",
            "  inflating: data/train_imgs/P002184.png  \n",
            "  inflating: data/train_imgs/P002185.png  \n",
            "  inflating: data/train_imgs/P002186.png  \n",
            "  inflating: data/train_imgs/P002187.png  \n",
            "  inflating: data/train_imgs/P002188.png  \n",
            "  inflating: data/train_imgs/P002189.png  \n",
            "  inflating: data/train_imgs/P002190.png  \n",
            "  inflating: data/train_imgs/P002191.png  \n",
            "  inflating: data/train_imgs/P002192.png  \n",
            "  inflating: data/train_imgs/P002193.png  \n",
            "  inflating: data/train_imgs/P002194.png  \n",
            "  inflating: data/train_imgs/P002195.png  \n",
            "  inflating: data/train_imgs/P002196.png  \n",
            "  inflating: data/train_imgs/P002197.png  \n",
            "  inflating: data/train_imgs/P002198.png  \n",
            "  inflating: data/train_imgs/P002199.png  \n",
            "  inflating: data/train_imgs/P002200.png  \n",
            "  inflating: data/train_imgs/P002201.png  \n",
            "  inflating: data/train_imgs/P002202.png  \n",
            "  inflating: data/train_imgs/P002203.png  \n",
            "  inflating: data/train_imgs/P002204.png  \n",
            "  inflating: data/train_imgs/P002205.png  \n",
            "  inflating: data/train_imgs/P002206.png  \n",
            "  inflating: data/train_imgs/P002207.png  \n",
            "  inflating: data/train_imgs/P002208.png  \n",
            "  inflating: data/train_imgs/P002209.png  \n",
            "  inflating: data/train_imgs/P002210.png  \n",
            "  inflating: data/train_imgs/P002211.png  \n",
            "  inflating: data/train_imgs/P002212.png  \n",
            "  inflating: data/train_imgs/P002213.png  \n",
            "  inflating: data/train_imgs/P002214.png  \n",
            "  inflating: data/train_imgs/P002215.png  \n",
            "  inflating: data/train_imgs/P002216.png  \n",
            "  inflating: data/train_imgs/P002217.png  \n",
            "  inflating: data/train_imgs/P002218.png  \n",
            "  inflating: data/train_imgs/P002219.png  \n",
            "  inflating: data/train_imgs/P002220.png  \n",
            "  inflating: data/train_imgs/P002221.png  \n",
            "  inflating: data/train_imgs/P002222.png  \n",
            "  inflating: data/train_imgs/P002223.png  \n",
            "  inflating: data/train_imgs/P002224.png  \n",
            "  inflating: data/train_imgs/P002225.png  \n",
            "  inflating: data/train_imgs/P002226.png  \n",
            "  inflating: data/train_imgs/P002227.png  \n",
            "  inflating: data/train_imgs/P002228.png  \n",
            "  inflating: data/train_imgs/P002229.png  \n",
            "  inflating: data/train_imgs/P002230.png  \n",
            "  inflating: data/train_imgs/P002231.png  \n",
            "  inflating: data/train_imgs/P002232.png  \n",
            "  inflating: data/train_imgs/P002233.png  \n",
            "  inflating: data/train_imgs/P002234.png  \n",
            "  inflating: data/train_imgs/P002235.png  \n",
            "  inflating: data/train_imgs/P002236.png  \n",
            "  inflating: data/train_imgs/P002237.png  \n",
            "  inflating: data/train_imgs/P002238.png  \n",
            "  inflating: data/train_imgs/P002239.png  \n",
            "  inflating: data/train_imgs/P002240.png  \n",
            "  inflating: data/train_imgs/P002241.png  \n",
            "  inflating: data/train_imgs/P002242.png  \n",
            "  inflating: data/train_imgs/P002243.png  \n",
            "  inflating: data/train_imgs/P002244.png  \n",
            "  inflating: data/train_imgs/P002245.png  \n",
            "  inflating: data/train_imgs/P002246.png  \n",
            "  inflating: data/train_imgs/P002247.png  \n",
            "  inflating: data/train_imgs/P002248.png  \n",
            "  inflating: data/train_imgs/P002249.png  \n",
            "  inflating: data/train_imgs/P002250.png  \n",
            "  inflating: data/train_imgs/P002251.png  \n",
            "  inflating: data/train_imgs/P002252.png  \n",
            "  inflating: data/train_imgs/P002253.png  \n",
            "  inflating: data/train_imgs/P002254.png  \n",
            "  inflating: data/train_imgs/P002255.png  \n",
            "  inflating: data/train_imgs/P002256.png  \n",
            "  inflating: data/train_imgs/P002257.png  \n",
            "  inflating: data/train_imgs/P002258.png  \n",
            "  inflating: data/train_imgs/P002259.png  \n",
            "  inflating: data/train_imgs/P002260.png  \n",
            "  inflating: data/train_imgs/P002261.png  \n",
            "  inflating: data/train_imgs/P002262.png  \n",
            "  inflating: data/train_imgs/P002263.png  \n",
            "  inflating: data/train_imgs/P002264.png  \n",
            "  inflating: data/train_imgs/P002265.png  \n",
            "  inflating: data/train_imgs/P002266.png  \n",
            "  inflating: data/train_imgs/P002267.png  \n",
            "  inflating: data/train_imgs/P002268.png  \n",
            "  inflating: data/train_imgs/P002269.png  \n",
            "  inflating: data/train_imgs/P002270.png  \n",
            "  inflating: data/train_imgs/P002271.png  \n",
            "  inflating: data/train_imgs/P002272.png  \n",
            "  inflating: data/train_imgs/P002273.png  \n",
            "  inflating: data/train_imgs/P002274.png  \n",
            "  inflating: data/train_imgs/P002275.png  \n",
            "  inflating: data/train_imgs/P002276.png  \n",
            "  inflating: data/train_imgs/P002277.png  \n",
            "  inflating: data/train_imgs/P002278.png  \n",
            "  inflating: data/train_imgs/P002279.png  \n",
            "  inflating: data/train_imgs/P002280.png  \n",
            "  inflating: data/train_imgs/P002281.png  \n",
            "  inflating: data/train_imgs/P002282.png  \n",
            "  inflating: data/train_imgs/P002283.png  \n",
            "  inflating: data/train_imgs/P002284.png  \n",
            "  inflating: data/train_imgs/P002285.png  \n",
            "  inflating: data/train_imgs/P002286.png  \n",
            "  inflating: data/train_imgs/P002287.png  \n",
            "  inflating: data/train_imgs/P002288.png  \n",
            "  inflating: data/train_imgs/P002289.png  \n",
            "  inflating: data/train_imgs/P002290.png  \n",
            "  inflating: data/train_imgs/P002291.png  \n",
            "  inflating: data/train_imgs/P002292.png  \n",
            "  inflating: data/train_imgs/P002293.png  \n",
            "  inflating: data/train_imgs/P002294.png  \n",
            "  inflating: data/train_imgs/P002295.png  \n",
            "  inflating: data/train_imgs/P002296.png  \n",
            "  inflating: data/train_imgs/P002297.png  \n",
            "  inflating: data/train_imgs/P002298.png  \n",
            "  inflating: data/train_imgs/P002299.png  \n",
            "  inflating: data/train_imgs/P002300.png  \n",
            "  inflating: data/train_imgs/P002301.png  \n",
            "  inflating: data/train_imgs/P002302.png  \n",
            "  inflating: data/train_imgs/P002303.png  \n",
            "  inflating: data/train_imgs/P002304.png  \n",
            "  inflating: data/train_imgs/P002305.png  \n",
            "  inflating: data/train_imgs/P002306.png  \n",
            "  inflating: data/train_imgs/P002307.png  \n",
            "  inflating: data/train_imgs/P002308.png  \n",
            "  inflating: data/train_imgs/P002309.png  \n",
            "  inflating: data/train_imgs/P002310.png  \n",
            "  inflating: data/train_imgs/P002311.png  \n",
            "  inflating: data/train_imgs/P002312.png  \n",
            "  inflating: data/train_imgs/P002313.png  \n",
            "  inflating: data/train_imgs/P002314.png  \n",
            "  inflating: data/train_imgs/P002315.png  \n",
            "  inflating: data/train_imgs/P002316.png  \n",
            "  inflating: data/train_imgs/P002317.png  \n",
            "  inflating: data/train_imgs/P002318.png  \n",
            "  inflating: data/train_imgs/P002319.png  \n",
            "  inflating: data/train_imgs/P002320.png  \n",
            "  inflating: data/train_imgs/P002321.png  \n",
            "  inflating: data/train_imgs/P002322.png  \n",
            "  inflating: data/train_imgs/P002323.png  \n",
            "  inflating: data/train_imgs/P002324.png  \n",
            "  inflating: data/train_imgs/P002325.png  \n",
            "  inflating: data/train_imgs/P002326.png  \n",
            "  inflating: data/train_imgs/P002327.png  \n",
            "  inflating: data/train_imgs/P002328.png  \n",
            "  inflating: data/train_imgs/P002329.png  \n",
            "  inflating: data/train_imgs/P002330.png  \n",
            "  inflating: data/train_imgs/P002331.png  \n",
            "  inflating: data/train_imgs/P002332.png  \n",
            "  inflating: data/train_imgs/P002333.png  \n",
            "  inflating: data/train_imgs/P002334.png  \n",
            "  inflating: data/train_imgs/P002335.png  \n",
            "  inflating: data/train_imgs/P002336.png  \n",
            "  inflating: data/train_imgs/P002337.png  \n",
            "  inflating: data/train_imgs/P002338.png  \n",
            "  inflating: data/train_imgs/P002339.png  \n",
            "  inflating: data/train_imgs/P002340.png  \n",
            "  inflating: data/train_imgs/P002341.png  \n",
            "  inflating: data/train_imgs/P002342.png  \n",
            "  inflating: data/train_imgs/P002343.png  \n",
            "  inflating: data/train_imgs/P002344.png  \n",
            "  inflating: data/train_imgs/P002345.png  \n",
            "  inflating: data/train_imgs/P002346.png  \n",
            "  inflating: data/train_imgs/P002347.png  \n",
            "  inflating: data/train_imgs/P002348.png  \n",
            "  inflating: data/train_imgs/P002349.png  \n",
            "  inflating: data/train_imgs/P002350.png  \n",
            "  inflating: data/train_imgs/P002351.png  \n",
            "  inflating: data/train_imgs/P002352.png  \n",
            "  inflating: data/train_imgs/P002353.png  \n",
            "  inflating: data/train_imgs/P002354.png  \n",
            "  inflating: data/train_imgs/P002355.png  \n",
            "  inflating: data/train_imgs/P002356.png  \n",
            "  inflating: data/train_imgs/P002357.png  \n",
            "  inflating: data/train_imgs/P002358.png  \n",
            "  inflating: data/train_imgs/P002359.png  \n",
            "  inflating: data/train_imgs/P002360.png  \n",
            "  inflating: data/train_imgs/P002361.png  \n",
            "  inflating: data/train_imgs/P002362.png  \n",
            "  inflating: data/train_imgs/P002363.png  \n",
            "  inflating: data/train_imgs/P002364.png  \n",
            "  inflating: data/train_imgs/P002365.png  \n",
            "  inflating: data/train_imgs/P002366.png  \n",
            "  inflating: data/train_imgs/P002367.png  \n",
            "  inflating: data/train_imgs/P002368.png  \n",
            "  inflating: data/train_imgs/P002369.png  \n",
            "  inflating: data/train_imgs/P002370.png  \n",
            "  inflating: data/train_imgs/P002371.png  \n",
            "  inflating: data/train_imgs/P002372.png  \n",
            "  inflating: data/train_imgs/P002373.png  \n",
            "  inflating: data/train_imgs/P002374.png  \n",
            "  inflating: data/train_imgs/P002375.png  \n",
            "  inflating: data/train_imgs/P002376.png  \n",
            "  inflating: data/train_imgs/P002377.png  \n",
            "  inflating: data/train_imgs/P002378.png  \n",
            "  inflating: data/train_imgs/P002379.png  \n",
            "  inflating: data/train_imgs/P002380.png  \n",
            "  inflating: data/train_imgs/P002381.png  \n",
            "  inflating: data/train_imgs/P002382.png  \n",
            "  inflating: data/train_imgs/P002383.png  \n",
            "  inflating: data/train_imgs/P002384.png  \n",
            "  inflating: data/train_imgs/P002385.png  \n",
            "  inflating: data/train_imgs/P002386.png  \n",
            "  inflating: data/train_imgs/P002387.png  \n",
            "  inflating: data/train_imgs/P002388.png  \n",
            "  inflating: data/train_imgs/P002389.png  \n",
            "  inflating: data/train_imgs/P002390.png  \n",
            "  inflating: data/train_imgs/P002391.png  \n",
            "  inflating: data/train_imgs/P002392.png  \n",
            "  inflating: data/train_imgs/P002393.png  \n",
            "  inflating: data/train_imgs/P002394.png  \n",
            "  inflating: data/train_imgs/P002395.png  \n",
            "  inflating: data/train_imgs/P002396.png  \n",
            "  inflating: data/train_imgs/P002397.png  \n",
            "  inflating: data/train_imgs/P002398.png  \n",
            "  inflating: data/train_imgs/P002399.png  \n",
            "  inflating: data/train_imgs/P002400.png  \n",
            "  inflating: data/train_imgs/P002401.png  \n",
            "  inflating: data/train_imgs/P002402.png  \n",
            "  inflating: data/train_imgs/P002403.png  \n",
            "  inflating: data/train_imgs/P002404.png  \n",
            "  inflating: data/train_imgs/P002405.png  \n",
            "  inflating: data/train_imgs/P002406.png  \n",
            "  inflating: data/train_imgs/P002407.png  \n",
            "  inflating: data/train_imgs/P002408.png  \n",
            "  inflating: data/train_imgs/P002409.png  \n",
            "  inflating: data/train_imgs/P002410.png  \n",
            "  inflating: data/train_imgs/P002411.png  \n",
            "  inflating: data/train_imgs/P002412.png  \n",
            "  inflating: data/train_imgs/P002413.png  \n",
            "  inflating: data/train_imgs/P002414.png  \n",
            "  inflating: data/train_imgs/P002415.png  \n",
            "  inflating: data/train_imgs/P002416.png  \n",
            "  inflating: data/train_imgs/P002417.png  \n",
            "  inflating: data/train_imgs/P002418.png  \n",
            "  inflating: data/train_imgs/P002419.png  \n",
            "  inflating: data/train_imgs/P002420.png  \n",
            "  inflating: data/train_imgs/P002421.png  \n",
            "  inflating: data/train_imgs/P002422.png  \n",
            "  inflating: data/train_imgs/P002423.png  \n",
            "  inflating: data/train_imgs/P002424.png  \n",
            "  inflating: data/train_imgs/P002425.png  \n",
            "  inflating: data/train_imgs/P002426.png  \n",
            "  inflating: data/train_imgs/P002427.png  \n",
            "  inflating: data/train_imgs/P002428.png  \n",
            "  inflating: data/train_imgs/P002429.png  \n",
            "  inflating: data/train_imgs/P002430.png  \n",
            "  inflating: data/train_imgs/P002431.png  \n",
            "  inflating: data/train_imgs/P002432.png  \n",
            "  inflating: data/train_imgs/P002433.png  \n",
            "  inflating: data/train_imgs/P002434.png  \n",
            "  inflating: data/train_imgs/P002435.png  \n",
            "  inflating: data/train_imgs/P002436.png  \n",
            "  inflating: data/train_imgs/P002437.png  \n",
            "  inflating: data/train_imgs/P002438.png  \n",
            "  inflating: data/train_imgs/P002439.png  \n",
            "  inflating: data/train_imgs/P002440.png  \n",
            "  inflating: data/train_imgs/P002441.png  \n",
            "  inflating: data/train_imgs/P002442.png  \n",
            "  inflating: data/train_imgs/P002443.png  \n",
            "  inflating: data/train_imgs/P002444.png  \n",
            "  inflating: data/train_imgs/P002445.png  \n",
            "  inflating: data/train_imgs/P002446.png  \n",
            "  inflating: data/train_imgs/P002447.png  \n",
            "  inflating: data/train_imgs/P002448.png  \n",
            "  inflating: data/train_imgs/P002449.png  \n",
            "  inflating: data/train_imgs/P002450.png  \n",
            "  inflating: data/train_imgs/P002451.png  \n",
            "  inflating: data/train_imgs/P002452.png  \n",
            "  inflating: data/train_imgs/P002453.png  \n",
            "  inflating: data/train_imgs/P002454.png  \n",
            "  inflating: data/train_imgs/P002455.png  \n",
            "  inflating: data/train_imgs/P002456.png  \n",
            "  inflating: data/train_imgs/P002457.png  \n",
            "  inflating: data/train_imgs/P002458.png  \n",
            "  inflating: data/train_imgs/P002459.png  \n",
            "  inflating: data/train_imgs/P002460.png  \n",
            "  inflating: data/train_imgs/P002461.png  \n",
            "  inflating: data/train_imgs/P002462.png  \n",
            "  inflating: data/train_imgs/P002463.png  \n",
            "  inflating: data/train_imgs/P002464.png  \n",
            "  inflating: data/train_imgs/P002465.png  \n",
            "  inflating: data/train_imgs/P002466.png  \n",
            "  inflating: data/train_imgs/P002467.png  \n",
            "  inflating: data/train_imgs/P002468.png  \n",
            "  inflating: data/train_imgs/P002469.png  \n",
            "  inflating: data/train_imgs/P002470.png  \n",
            "  inflating: data/train_imgs/P002471.png  \n",
            "  inflating: data/train_imgs/P002472.png  \n",
            "  inflating: data/train_imgs/P002473.png  \n",
            "  inflating: data/train_imgs/P002474.png  \n",
            "  inflating: data/train_imgs/P002475.png  \n",
            "  inflating: data/train_imgs/P002476.png  \n",
            "  inflating: data/train_imgs/P002477.png  \n",
            "  inflating: data/train_imgs/P002478.png  \n",
            "  inflating: data/train_imgs/P002479.png  \n",
            "  inflating: data/train_imgs/P002480.png  \n",
            "  inflating: data/train_imgs/P002481.png  \n",
            "  inflating: data/train_imgs/P002482.png  \n",
            "  inflating: data/train_imgs/P002483.png  \n",
            "  inflating: data/train_imgs/P002484.png  \n",
            "  inflating: data/train_imgs/P002485.png  \n",
            "  inflating: data/train_imgs/P002486.png  \n",
            "  inflating: data/train_imgs/P002487.png  \n",
            "  inflating: data/train_imgs/P002488.png  \n",
            "  inflating: data/train_imgs/P002489.png  \n",
            "  inflating: data/train_imgs/P002490.png  \n",
            "  inflating: data/train_imgs/P002491.png  \n",
            "  inflating: data/train_imgs/P002492.png  \n",
            "  inflating: data/train_imgs/P002493.png  \n",
            "  inflating: data/train_imgs/P002494.png  \n",
            "  inflating: data/train_imgs/P002495.png  \n",
            "  inflating: data/train_imgs/P002496.png  \n",
            "  inflating: data/train_imgs/P002497.png  \n",
            "  inflating: data/train_imgs/P002498.png  \n",
            "  inflating: data/train_imgs/P002499.png  \n",
            "  inflating: data/train_imgs/P002500.png  \n",
            "  inflating: data/train_imgs/P002501.png  \n",
            "  inflating: data/train_imgs/P002502.png  \n",
            "  inflating: data/train_imgs/P002503.png  \n",
            "  inflating: data/train_imgs/P002504.png  \n",
            "  inflating: data/train_imgs/P002505.png  \n",
            "  inflating: data/train_imgs/P002506.png  \n",
            "  inflating: data/train_imgs/P002507.png  \n",
            "  inflating: data/train_imgs/P002508.png  \n",
            "  inflating: data/train_imgs/P002509.png  \n",
            "  inflating: data/train_imgs/P002510.png  \n",
            "  inflating: data/train_imgs/P002511.png  \n",
            "  inflating: data/train_imgs/P002512.png  \n",
            "  inflating: data/train_imgs/P002513.png  \n",
            "  inflating: data/train_imgs/P002514.png  \n",
            "  inflating: data/train_imgs/P002515.png  \n",
            "  inflating: data/train_imgs/P002516.png  \n",
            "  inflating: data/train_imgs/P002517.png  \n",
            "  inflating: data/train_imgs/P002518.png  \n",
            "  inflating: data/train_imgs/P002519.png  \n",
            "  inflating: data/train_imgs/P002520.png  \n",
            "  inflating: data/train_imgs/P002521.png  \n",
            "  inflating: data/train_imgs/P002522.png  \n",
            "  inflating: data/train_imgs/P002523.png  \n",
            "  inflating: data/train_imgs/P002524.png  \n",
            "  inflating: data/train_imgs/P002525.png  \n",
            "  inflating: data/train_imgs/P002526.png  \n",
            "  inflating: data/train_imgs/P002527.png  \n",
            "  inflating: data/train_imgs/P002528.png  \n",
            "  inflating: data/train_imgs/P002529.png  \n",
            "  inflating: data/train_imgs/P002530.png  \n",
            "  inflating: data/train_imgs/P002531.png  \n",
            "  inflating: data/train_imgs/P002532.png  \n",
            "  inflating: data/train_imgs/P002533.png  \n",
            "  inflating: data/train_imgs/P002534.png  \n",
            "  inflating: data/train_imgs/P002535.png  \n",
            "  inflating: data/train_imgs/P002536.png  \n",
            "  inflating: data/train_imgs/P002537.png  \n",
            "  inflating: data/train_imgs/P002538.png  \n",
            "  inflating: data/train_imgs/P002539.png  \n",
            "  inflating: data/train_imgs/P002540.png  \n",
            "  inflating: data/train_imgs/P002541.png  \n",
            "  inflating: data/train_imgs/P002542.png  \n",
            "  inflating: data/train_imgs/P002543.png  \n",
            "  inflating: data/train_imgs/P002544.png  \n",
            "  inflating: data/train_imgs/P002545.png  \n",
            "  inflating: data/train_imgs/P002546.png  \n",
            "  inflating: data/train_imgs/P002547.png  \n",
            "  inflating: data/train_imgs/P002548.png  \n",
            "  inflating: data/train_imgs/P002549.png  \n",
            "  inflating: data/train_imgs/P002550.png  \n",
            "  inflating: data/train_imgs/P002551.png  \n",
            "  inflating: data/train_imgs/P002552.png  \n",
            "  inflating: data/train_imgs/P002553.png  \n",
            "  inflating: data/train_imgs/P002554.png  \n",
            "  inflating: data/train_imgs/P002555.png  \n",
            "  inflating: data/train_imgs/P002556.png  \n",
            "  inflating: data/train_imgs/P002557.png  \n",
            "  inflating: data/train_imgs/P002558.png  \n",
            "  inflating: data/train_imgs/P002559.png  \n",
            "  inflating: data/train_imgs/P002560.png  \n",
            "  inflating: data/train_imgs/P002561.png  \n",
            "  inflating: data/train_imgs/P002562.png  \n",
            "  inflating: data/train_imgs/P002563.png  \n",
            "  inflating: data/train_imgs/P002564.png  \n",
            "  inflating: data/train_imgs/P002565.png  \n",
            "  inflating: data/train_imgs/P002566.png  \n",
            "  inflating: data/train_imgs/P002567.png  \n",
            "  inflating: data/train_imgs/P002568.png  \n",
            "  inflating: data/train_imgs/P002569.png  \n",
            "  inflating: data/train_imgs/P002570.png  \n",
            "  inflating: data/train_imgs/P002571.png  \n",
            "  inflating: data/train_imgs/P002572.png  \n",
            "  inflating: data/train_imgs/P002573.png  \n",
            "  inflating: data/train_imgs/P002574.png  \n",
            "  inflating: data/train_imgs/P002575.png  \n",
            "  inflating: data/train_imgs/P002576.png  \n",
            "  inflating: data/train_imgs/P002577.png  \n",
            "  inflating: data/train_imgs/P002578.png  \n",
            "  inflating: data/train_imgs/P002579.png  \n",
            "  inflating: data/train_imgs/P002580.png  \n",
            "  inflating: data/train_imgs/P002581.png  \n",
            "  inflating: data/train_imgs/P002582.png  \n",
            "  inflating: data/train_imgs/P002583.png  \n",
            "  inflating: data/train_imgs/P002584.png  \n",
            "  inflating: data/train_imgs/P002585.png  \n",
            "  inflating: data/train_imgs/P002586.png  \n",
            "  inflating: data/train_imgs/P002587.png  \n",
            "  inflating: data/train_imgs/P002588.png  \n",
            "  inflating: data/train_imgs/P002589.png  \n",
            "  inflating: data/train_imgs/P002590.png  \n",
            "  inflating: data/train_imgs/P002591.png  \n",
            "  inflating: data/train_imgs/P002592.png  \n",
            "  inflating: data/train_imgs/P002593.png  \n",
            "  inflating: data/train_imgs/P002594.png  \n",
            "  inflating: data/train_imgs/P002595.png  \n",
            "  inflating: data/train_imgs/P002596.png  \n",
            "  inflating: data/train_imgs/P002597.png  \n",
            "  inflating: data/train_imgs/P002598.png  \n",
            "  inflating: data/train_imgs/P002599.png  \n",
            "  inflating: data/train_imgs/P002600.png  \n",
            "  inflating: data/train_imgs/P002601.png  \n",
            "  inflating: data/train_imgs/P002602.png  \n",
            "  inflating: data/train_imgs/P002603.png  \n",
            "  inflating: data/train_imgs/P002604.png  \n",
            "  inflating: data/train_imgs/P002605.png  \n",
            "  inflating: data/train_imgs/P002606.png  \n",
            "  inflating: data/train_imgs/P002607.png  \n",
            "  inflating: data/train_imgs/P002608.png  \n",
            "  inflating: data/train_imgs/P002609.png  \n",
            "  inflating: data/train_imgs/P002610.png  \n",
            "  inflating: data/train_imgs/P002611.png  \n",
            "  inflating: data/train_imgs/P002612.png  \n",
            "  inflating: data/train_imgs/P002613.png  \n",
            "  inflating: data/train_imgs/P002614.png  \n",
            "  inflating: data/train_imgs/P002615.png  \n",
            "  inflating: data/train_imgs/P002616.png  \n",
            "  inflating: data/train_imgs/P002617.png  \n",
            "  inflating: data/train_imgs/P002618.png  \n",
            "  inflating: data/train_imgs/P002619.png  \n",
            "  inflating: data/train_imgs/P002620.png  \n",
            "  inflating: data/train_imgs/P002621.png  \n",
            "  inflating: data/train_imgs/P002622.png  \n",
            "  inflating: data/train_imgs/P002623.png  \n",
            "  inflating: data/train_imgs/P002624.png  \n",
            "  inflating: data/train_imgs/P002625.png  \n",
            "  inflating: data/train_imgs/P002626.png  \n",
            "  inflating: data/train_imgs/P002627.png  \n",
            "  inflating: data/train_imgs/P002628.png  \n",
            "  inflating: data/train_imgs/P002629.png  \n",
            "  inflating: data/train_imgs/P002630.png  \n",
            "  inflating: data/train_imgs/P002631.png  \n",
            "  inflating: data/train_imgs/P002632.png  \n",
            "  inflating: data/train_imgs/P002633.png  \n",
            "  inflating: data/train_imgs/P002634.png  \n",
            "  inflating: data/train_imgs/P002635.png  \n",
            "  inflating: data/train_imgs/P002636.png  \n",
            "  inflating: data/train_imgs/P002637.png  \n",
            "  inflating: data/train_imgs/P002638.png  \n",
            "  inflating: data/train_imgs/P002639.png  \n",
            "  inflating: data/train_imgs/P002640.png  \n",
            "  inflating: data/train_imgs/P002641.png  \n",
            "  inflating: data/train_imgs/P002642.png  \n",
            "  inflating: data/train_imgs/P002643.png  \n",
            "  inflating: data/train_imgs/P002644.png  \n",
            "  inflating: data/train_imgs/P002645.png  \n",
            "  inflating: data/train_imgs/P002646.png  \n",
            "  inflating: data/train_imgs/P002647.png  \n",
            "  inflating: data/train_imgs/P002648.png  \n",
            "  inflating: data/train_imgs/P002649.png  \n",
            "  inflating: data/train_imgs/P002650.png  \n",
            "  inflating: data/train_imgs/P002651.png  \n",
            "  inflating: data/train_imgs/P002652.png  \n",
            "  inflating: data/train_imgs/P002653.png  \n",
            "  inflating: data/train_imgs/P002654.png  \n",
            "  inflating: data/train_imgs/P002655.png  \n",
            "  inflating: data/train_imgs/P002656.png  \n",
            "  inflating: data/train_imgs/P002657.png  \n",
            "  inflating: data/train_imgs/P002658.png  \n",
            "  inflating: data/train_imgs/P002659.png  \n",
            "  inflating: data/train_imgs/P002660.png  \n",
            "  inflating: data/train_imgs/P002661.png  \n",
            "  inflating: data/train_imgs/P002662.png  \n",
            "  inflating: data/train_imgs/P002663.png  \n",
            "  inflating: data/train_imgs/P002664.png  \n",
            "  inflating: data/train_imgs/P002665.png  \n",
            "  inflating: data/train_imgs/P002666.png  \n",
            "  inflating: data/train_imgs/P002667.png  \n",
            "  inflating: data/train_imgs/P002668.png  \n",
            "  inflating: data/train_imgs/P002669.png  \n",
            "  inflating: data/train_imgs/P002670.png  \n",
            "  inflating: data/train_imgs/P002671.png  \n",
            "  inflating: data/train_imgs/P002672.png  \n",
            "  inflating: data/train_imgs/P002673.png  \n",
            "  inflating: data/train_imgs/P002674.png  \n",
            "  inflating: data/train_imgs/P002675.png  \n",
            "  inflating: data/train_imgs/P002676.png  \n",
            "  inflating: data/train_imgs/P002677.png  \n",
            "  inflating: data/train_imgs/P002678.png  \n",
            "  inflating: data/train_imgs/P002679.png  \n",
            "  inflating: data/train_imgs/P002680.png  \n",
            "  inflating: data/train_imgs/P002681.png  \n",
            "  inflating: data/train_imgs/P002682.png  \n",
            "  inflating: data/train_imgs/P002683.png  \n",
            "  inflating: data/train_imgs/P002684.png  \n",
            "  inflating: data/train_imgs/P002685.png  \n",
            "  inflating: data/train_imgs/P002686.png  \n",
            "  inflating: data/train_imgs/P002687.png  \n",
            "  inflating: data/train_imgs/P002688.png  \n",
            "  inflating: data/train_imgs/P002689.png  \n",
            "  inflating: data/train_imgs/P002690.png  \n",
            "  inflating: data/train_imgs/P002691.png  \n",
            "  inflating: data/train_imgs/P002692.png  \n",
            "  inflating: data/train_imgs/P002693.png  \n",
            "  inflating: data/train_imgs/P002694.png  \n",
            "  inflating: data/train_imgs/P002695.png  \n",
            "  inflating: data/train_imgs/P002696.png  \n",
            "  inflating: data/train_imgs/P002697.png  \n",
            "  inflating: data/train_imgs/P002698.png  \n",
            "  inflating: data/train_imgs/P002699.png  \n",
            "  inflating: data/train_imgs/P002700.png  \n",
            "  inflating: data/train_imgs/P002701.png  \n",
            "  inflating: data/train_imgs/P002702.png  \n",
            "  inflating: data/train_imgs/P002703.png  \n",
            "  inflating: data/train_imgs/P002704.png  \n",
            "  inflating: data/train_imgs/P002705.png  \n",
            "  inflating: data/train_imgs/P002706.png  \n",
            "  inflating: data/train_imgs/P002707.png  \n",
            "  inflating: data/train_imgs/P002708.png  \n",
            "  inflating: data/train_imgs/P002709.png  \n",
            "  inflating: data/train_imgs/P002710.png  \n",
            "  inflating: data/train_imgs/P002711.png  \n",
            "  inflating: data/train_imgs/P002712.png  \n",
            "  inflating: data/train_imgs/P002713.png  \n",
            "  inflating: data/train_imgs/P002714.png  \n",
            "  inflating: data/train_imgs/P002715.png  \n",
            "  inflating: data/train_imgs/P002716.png  \n",
            "  inflating: data/train_imgs/P002717.png  \n",
            "  inflating: data/train_imgs/P002718.png  \n",
            "  inflating: data/train_imgs/P002719.png  \n",
            "  inflating: data/train_imgs/P002720.png  \n",
            "  inflating: data/train_imgs/P002721.png  \n",
            "  inflating: data/train_imgs/P002722.png  \n",
            "  inflating: data/train_imgs/P002723.png  \n",
            "  inflating: data/train_imgs/P002724.png  \n",
            "  inflating: data/train_imgs/P002725.png  \n",
            "  inflating: data/train_imgs/P002726.png  \n",
            "  inflating: data/train_imgs/P002727.png  \n",
            "  inflating: data/train_imgs/P002728.png  \n",
            "  inflating: data/train_imgs/P002729.png  \n",
            "  inflating: data/train_imgs/P002730.png  \n",
            "  inflating: data/train_imgs/P002731.png  \n",
            "  inflating: data/train_imgs/P002732.png  \n",
            "  inflating: data/train_imgs/P002733.png  \n",
            "  inflating: data/train_imgs/P002734.png  \n",
            "  inflating: data/train_imgs/P002735.png  \n",
            "  inflating: data/train_imgs/P002736.png  \n",
            "  inflating: data/train_imgs/P002737.png  \n",
            "  inflating: data/train_imgs/P002738.png  \n",
            "  inflating: data/train_imgs/P002739.png  \n",
            "  inflating: data/train_imgs/P002740.png  \n",
            "  inflating: data/train_imgs/P002741.png  \n",
            "  inflating: data/train_imgs/P002742.png  \n",
            "  inflating: data/train_imgs/P002743.png  \n",
            "  inflating: data/train_imgs/P002744.png  \n",
            "  inflating: data/train_imgs/P002745.png  \n",
            "  inflating: data/train_imgs/P002746.png  \n",
            "  inflating: data/train_imgs/P002747.png  \n",
            "  inflating: data/train_imgs/P002748.png  \n",
            "  inflating: data/train_imgs/P002749.png  \n",
            "  inflating: data/train_imgs/P002750.png  \n",
            "  inflating: data/train_imgs/P002751.png  \n",
            "  inflating: data/train_imgs/P002752.png  \n",
            "  inflating: data/train_imgs/P002753.png  \n",
            "  inflating: data/train_imgs/P002754.png  \n",
            "  inflating: data/train_imgs/P002755.png  \n",
            "  inflating: data/train_imgs/P002756.png  \n",
            "  inflating: data/train_imgs/P002757.png  \n",
            "  inflating: data/train_imgs/P002758.png  \n",
            "  inflating: data/train_imgs/P002759.png  \n",
            "  inflating: data/train_imgs/P002760.png  \n",
            "  inflating: data/train_imgs/P002761.png  \n",
            "  inflating: data/train_imgs/P002762.png  \n",
            "  inflating: data/train_imgs/P002763.png  \n",
            "  inflating: data/train_imgs/P002764.png  \n",
            "  inflating: data/train_imgs/P002765.png  \n",
            "  inflating: data/train_imgs/P002766.png  \n",
            "  inflating: data/train_imgs/P002767.png  \n",
            "  inflating: data/train_imgs/P002768.png  \n",
            "  inflating: data/train_imgs/P002769.png  \n",
            "  inflating: data/train_imgs/P002770.png  \n",
            "  inflating: data/train_imgs/P002771.png  \n",
            "  inflating: data/train_imgs/P002772.png  \n",
            "  inflating: data/train_imgs/P002773.png  \n",
            "  inflating: data/train_imgs/P002774.png  \n",
            "  inflating: data/train_imgs/P002775.png  \n",
            "  inflating: data/train_imgs/P002776.png  \n",
            "  inflating: data/train_imgs/P002777.png  \n",
            "  inflating: data/train_imgs/P002778.png  \n",
            "  inflating: data/train_imgs/P002779.png  \n",
            "  inflating: data/train_imgs/P002780.png  \n",
            "  inflating: data/train_imgs/P002781.png  \n",
            "  inflating: data/train_imgs/P002782.png  \n",
            "  inflating: data/train_imgs/P002783.png  \n",
            "  inflating: data/train_imgs/P002784.png  \n",
            "  inflating: data/train_imgs/P002785.png  \n",
            "  inflating: data/train_imgs/P002786.png  \n",
            "  inflating: data/train_imgs/P002787.png  \n",
            "  inflating: data/train_imgs/P002788.png  \n",
            "  inflating: data/train_imgs/P002789.png  \n",
            "  inflating: data/train_imgs/P002790.png  \n",
            "  inflating: data/train_imgs/P002791.png  \n",
            "  inflating: data/train_imgs/P002792.png  \n",
            "  inflating: data/train_imgs/P002793.png  \n",
            "  inflating: data/train_imgs/P002794.png  \n",
            "  inflating: data/train_imgs/P002795.png  \n",
            "  inflating: data/train_imgs/P002796.png  \n",
            "  inflating: data/train_imgs/P002797.png  \n",
            "  inflating: data/train_imgs/P002798.png  \n",
            "  inflating: data/train_imgs/P002799.png  \n",
            "  inflating: data/train_imgs/P002800.png  \n",
            "  inflating: data/train_imgs/P002801.png  \n",
            "  inflating: data/train_imgs/P002802.png  \n",
            "  inflating: data/train_imgs/P002803.png  \n",
            "  inflating: data/train_imgs/P002804.png  \n",
            "  inflating: data/train_imgs/P002805.png  \n",
            "  inflating: data/train_imgs/P002806.png  \n",
            "  inflating: data/train_imgs/P002807.png  \n",
            "  inflating: data/train_imgs/P002808.png  \n",
            "  inflating: data/train_imgs/P002809.png  \n",
            "  inflating: data/train_imgs/P002810.png  \n",
            "  inflating: data/train_imgs/P002811.png  \n",
            "  inflating: data/train_imgs/P002812.png  \n",
            "  inflating: data/train_imgs/P002813.png  \n",
            "  inflating: data/train_imgs/P002814.png  \n",
            "  inflating: data/train_imgs/P002815.png  \n",
            "  inflating: data/train_imgs/P002816.png  \n",
            "  inflating: data/train_imgs/P002817.png  \n",
            "  inflating: data/train_imgs/P002818.png  \n",
            "  inflating: data/train_imgs/P002819.png  \n",
            "  inflating: data/train_imgs/P002820.png  \n",
            "  inflating: data/train_imgs/P002821.png  \n",
            "  inflating: data/train_imgs/P002822.png  \n",
            "  inflating: data/train_imgs/P002823.png  \n",
            "  inflating: data/train_imgs/P002824.png  \n",
            "  inflating: data/train_imgs/P002825.png  \n",
            "  inflating: data/train_imgs/P002826.png  \n",
            "  inflating: data/train_imgs/P002827.png  \n",
            "  inflating: data/train_imgs/P002828.png  \n",
            "  inflating: data/train_imgs/P002829.png  \n",
            "  inflating: data/train_imgs/P002830.png  \n",
            "  inflating: data/train_imgs/P002831.png  \n",
            "  inflating: data/train_imgs/P002832.png  \n",
            "  inflating: data/train_imgs/P002833.png  \n",
            "  inflating: data/train_imgs/P002834.png  \n",
            "  inflating: data/train_imgs/P002835.png  \n",
            "  inflating: data/train_imgs/P002836.png  \n",
            "  inflating: data/train_imgs/P002837.png  \n",
            "  inflating: data/train_imgs/P002838.png  \n",
            "  inflating: data/train_imgs/P002839.png  \n",
            "  inflating: data/train_imgs/P002840.png  \n",
            "  inflating: data/train_imgs/P002841.png  \n",
            "  inflating: data/train_imgs/P002842.png  \n",
            "  inflating: data/train_imgs/P002843.png  \n",
            "  inflating: data/train_imgs/P002844.png  \n",
            "  inflating: data/train_imgs/P002845.png  \n",
            "  inflating: data/train_imgs/P002846.png  \n",
            "  inflating: data/train_imgs/P002847.png  \n",
            "  inflating: data/train_imgs/P002848.png  \n",
            "  inflating: data/train_imgs/P002849.png  \n",
            "  inflating: data/train_imgs/P002850.png  \n",
            "  inflating: data/train_imgs/P002851.png  \n",
            "  inflating: data/train_imgs/P002852.png  \n",
            "  inflating: data/train_imgs/P002853.png  \n",
            "  inflating: data/train_imgs/P002854.png  \n",
            "  inflating: data/train_imgs/P002855.png  \n",
            "  inflating: data/train_imgs/P002856.png  \n",
            "  inflating: data/train_imgs/P002857.png  \n",
            "  inflating: data/train_imgs/P002858.png  \n",
            "  inflating: data/train_imgs/P002859.png  \n",
            "  inflating: data/train_imgs/P002860.png  \n",
            "  inflating: data/train_imgs/P002861.png  \n",
            "  inflating: data/train_imgs/P002862.png  \n",
            "  inflating: data/train_imgs/P002863.png  \n",
            "  inflating: data/train_imgs/P002864.png  \n",
            "  inflating: data/train_imgs/P002865.png  \n",
            "  inflating: data/train_imgs/P002866.png  \n",
            "  inflating: data/train_imgs/P002867.png  \n",
            "  inflating: data/train_imgs/P002868.png  \n",
            "  inflating: data/train_imgs/P002869.png  \n",
            "  inflating: data/train_imgs/P002870.png  \n",
            "  inflating: data/train_imgs/P002871.png  \n",
            "  inflating: data/train_imgs/P002872.png  \n",
            "  inflating: data/train_imgs/P002873.png  \n",
            "  inflating: data/train_imgs/P002874.png  \n",
            "  inflating: data/train_imgs/P002875.png  \n",
            "  inflating: data/train_imgs/P002876.png  \n",
            "  inflating: data/train_imgs/P002877.png  \n",
            "  inflating: data/train_imgs/P002878.png  \n",
            "  inflating: data/train_imgs/P002879.png  \n",
            "  inflating: data/train_imgs/P002880.png  \n",
            "  inflating: data/train_imgs/P002881.png  \n",
            "  inflating: data/train_imgs/P002882.png  \n",
            "  inflating: data/train_imgs/P002883.png  \n",
            "  inflating: data/train_imgs/P002884.png  \n",
            "  inflating: data/train_imgs/P002885.png  \n",
            "  inflating: data/train_imgs/P002886.png  \n",
            "  inflating: data/train_imgs/P002887.png  \n",
            "  inflating: data/train_imgs/P002888.png  \n",
            "  inflating: data/train_imgs/P002889.png  \n",
            "  inflating: data/train_imgs/P002890.png  \n",
            "  inflating: data/train_imgs/P002891.png  \n",
            "  inflating: data/train_imgs/P002892.png  \n",
            "  inflating: data/train_imgs/P002893.png  \n",
            "  inflating: data/train_imgs/P002894.png  \n",
            "  inflating: data/train_imgs/P002895.png  \n",
            "  inflating: data/train_imgs/P002896.png  \n",
            "  inflating: data/train_imgs/P002897.png  \n",
            "  inflating: data/train_imgs/P002898.png  \n",
            "  inflating: data/train_imgs/P002899.png  \n",
            "  inflating: data/train_imgs/P002900.png  \n",
            "  inflating: data/train_imgs/P002901.png  \n",
            "  inflating: data/train_imgs/P002902.png  \n",
            "  inflating: data/train_imgs/P002903.png  \n",
            "  inflating: data/train_imgs/P002904.png  \n",
            "  inflating: data/train_imgs/P002905.png  \n",
            "  inflating: data/train_imgs/P002906.png  \n",
            "  inflating: data/train_imgs/P002907.png  \n",
            "  inflating: data/train_imgs/P002908.png  \n",
            "  inflating: data/train_imgs/P002909.png  \n",
            "  inflating: data/train_imgs/P002910.png  \n",
            "  inflating: data/train_imgs/P002911.png  \n",
            "  inflating: data/train_imgs/P002912.png  \n",
            "  inflating: data/train_imgs/P002913.png  \n",
            "  inflating: data/train_imgs/P002914.png  \n",
            "  inflating: data/train_imgs/P002915.png  \n",
            "  inflating: data/train_imgs/P002916.png  \n",
            "  inflating: data/train_imgs/P002917.png  \n",
            "  inflating: data/train_imgs/P002918.png  \n",
            "  inflating: data/train_imgs/P002919.png  \n",
            "  inflating: data/train_imgs/P002920.png  \n",
            "  inflating: data/train_imgs/P002921.png  \n",
            "  inflating: data/train_imgs/P002922.png  \n",
            "  inflating: data/train_imgs/P002923.png  \n",
            "  inflating: data/train_imgs/P002924.png  \n",
            "  inflating: data/train_imgs/P002925.png  \n",
            "  inflating: data/train_imgs/P002926.png  \n",
            "  inflating: data/train_imgs/P002927.png  \n",
            "  inflating: data/train_imgs/P002928.png  \n",
            "  inflating: data/train_imgs/P002929.png  \n",
            "  inflating: data/train_imgs/P002930.png  \n",
            "  inflating: data/train_imgs/P002931.png  \n",
            "  inflating: data/train_imgs/P002932.png  \n",
            "  inflating: data/train_imgs/P002933.png  \n",
            "  inflating: data/train_imgs/P002934.png  \n",
            "  inflating: data/train_imgs/P002935.png  \n",
            "  inflating: data/train_imgs/P002936.png  \n",
            "  inflating: data/train_imgs/P002937.png  \n",
            "  inflating: data/train_imgs/P002938.png  \n",
            "  inflating: data/train_imgs/P002939.png  \n",
            "  inflating: data/train_imgs/P002940.png  \n",
            "  inflating: data/train_imgs/P002941.png  \n",
            "  inflating: data/train_imgs/P002942.png  \n",
            "  inflating: data/train_imgs/P002943.png  \n",
            "  inflating: data/train_imgs/P002944.png  \n",
            "  inflating: data/train_imgs/P002945.png  \n",
            "  inflating: data/train_imgs/P002946.png  \n",
            "  inflating: data/train_imgs/P002947.png  \n",
            "  inflating: data/train_imgs/P002948.png  \n",
            "  inflating: data/train_imgs/P002949.png  \n",
            "  inflating: data/train_imgs/P002950.png  \n",
            "  inflating: data/train_imgs/P002951.png  \n",
            "  inflating: data/train_imgs/P002952.png  \n",
            "  inflating: data/train_imgs/P002953.png  \n",
            "  inflating: data/train_imgs/P002954.png  \n",
            "  inflating: data/train_imgs/P002955.png  \n",
            "  inflating: data/train_imgs/P002956.png  \n",
            "  inflating: data/train_imgs/P002957.png  \n",
            "  inflating: data/train_imgs/P002958.png  \n",
            "  inflating: data/train_imgs/P002959.png  \n",
            "  inflating: data/train_imgs/P002960.png  \n",
            "  inflating: data/train_imgs/P002961.png  \n",
            "  inflating: data/train_imgs/P002962.png  \n",
            "  inflating: data/train_imgs/P002963.png  \n",
            "  inflating: data/train_imgs/P002964.png  \n",
            "  inflating: data/train_imgs/P002965.png  \n",
            "  inflating: data/train_imgs/P002966.png  \n",
            "  inflating: data/train_imgs/P002967.png  \n",
            "  inflating: data/train_imgs/P002968.png  \n",
            "  inflating: data/train_imgs/P002969.png  \n",
            "  inflating: data/train_imgs/P002970.png  \n",
            "  inflating: data/train_imgs/P002971.png  \n",
            "  inflating: data/train_imgs/P002972.png  \n",
            "  inflating: data/train_imgs/P002973.png  \n",
            "  inflating: data/train_imgs/P002974.png  \n",
            "  inflating: data/train_imgs/P002975.png  \n",
            "  inflating: data/train_imgs/P002976.png  \n",
            "  inflating: data/train_imgs/P002977.png  \n",
            "  inflating: data/train_imgs/P002978.png  \n",
            "  inflating: data/train_imgs/P002979.png  \n",
            "  inflating: data/train_imgs/P002980.png  \n",
            "  inflating: data/train_imgs/P002981.png  \n",
            "  inflating: data/train_imgs/P002982.png  \n",
            "  inflating: data/train_imgs/P002983.png  \n",
            "  inflating: data/train_imgs/P002984.png  \n",
            "  inflating: data/train_imgs/P002985.png  \n",
            "  inflating: data/train_imgs/P002986.png  \n",
            "  inflating: data/train_imgs/P002987.png  \n",
            "  inflating: data/train_imgs/P002988.png  \n",
            "  inflating: data/train_imgs/P002989.png  \n",
            "  inflating: data/train_imgs/P002990.png  \n",
            "  inflating: data/train_imgs/P002991.png  \n",
            "  inflating: data/train_imgs/P002992.png  \n",
            "  inflating: data/train_imgs/P002993.png  \n",
            "  inflating: data/train_imgs/P002994.png  \n",
            "  inflating: data/train_imgs/P002995.png  \n",
            "  inflating: data/train_imgs/P002996.png  \n",
            "  inflating: data/train_imgs/P002997.png  \n",
            "  inflating: data/train_imgs/P002998.png  \n",
            "  inflating: data/train_imgs/P002999.png  \n",
            "  inflating: data/train_imgs/P003000.png  \n",
            "  inflating: data/train_imgs/P003001.png  \n",
            "  inflating: data/train_imgs/P003002.png  \n",
            "  inflating: data/train_imgs/P003003.png  \n",
            "  inflating: data/train_imgs/P003004.png  \n",
            "  inflating: data/train_imgs/P003005.png  \n",
            "  inflating: data/train_imgs/P003006.png  \n",
            "  inflating: data/train_imgs/P003007.png  \n",
            "  inflating: data/train_imgs/P003008.png  \n",
            "  inflating: data/train_imgs/P003009.png  \n",
            "  inflating: data/train_imgs/P003010.png  \n",
            "  inflating: data/train_imgs/P003011.png  \n",
            "  inflating: data/train_imgs/P003012.png  \n",
            "  inflating: data/train_imgs/P003013.png  \n",
            "  inflating: data/train_imgs/P003014.png  \n",
            "  inflating: data/train_imgs/P003015.png  \n",
            "  inflating: data/train_imgs/P003016.png  \n",
            "  inflating: data/train_imgs/P003017.png  \n",
            "  inflating: data/train_imgs/P003018.png  \n",
            "  inflating: data/train_imgs/P003019.png  \n",
            "  inflating: data/train_imgs/P003020.png  \n",
            "  inflating: data/train_imgs/P003021.png  \n",
            "  inflating: data/train_imgs/P003022.png  \n",
            "  inflating: data/train_imgs/P003023.png  \n",
            "  inflating: data/train_imgs/P003024.png  \n",
            "  inflating: data/train_imgs/P003025.png  \n",
            "  inflating: data/train_imgs/P003026.png  \n",
            "  inflating: data/train_imgs/P003027.png  \n",
            "  inflating: data/train_imgs/P003028.png  \n",
            "  inflating: data/train_imgs/P003029.png  \n",
            "  inflating: data/train_imgs/P003030.png  \n",
            "  inflating: data/train_imgs/P003031.png  \n",
            "  inflating: data/train_imgs/P003032.png  \n",
            "  inflating: data/train_imgs/P003033.png  \n",
            "  inflating: data/train_imgs/P003034.png  \n",
            "  inflating: data/train_imgs/P003035.png  \n",
            "  inflating: data/train_imgs/P003036.png  \n",
            "  inflating: data/train_imgs/P003037.png  \n",
            "  inflating: data/train_imgs/P003038.png  \n",
            "  inflating: data/train_imgs/P003039.png  \n",
            "  inflating: data/train_imgs/P003040.png  \n",
            "  inflating: data/train_imgs/P003041.png  \n",
            "  inflating: data/train_imgs/P003042.png  \n",
            "  inflating: data/train_imgs/P003043.png  \n",
            "  inflating: data/train_imgs/P003044.png  \n",
            "  inflating: data/train_imgs/P003045.png  \n",
            "  inflating: data/train_imgs/P003046.png  \n",
            "  inflating: data/train_imgs/P003047.png  \n",
            "  inflating: data/train_imgs/P003048.png  \n",
            "  inflating: data/train_imgs/P003049.png  \n",
            "  inflating: data/train_imgs/P003050.png  \n",
            "  inflating: data/train_imgs/P003051.png  \n",
            "  inflating: data/train_imgs/P003052.png  \n",
            "  inflating: data/train_imgs/P003053.png  \n",
            "  inflating: data/train_imgs/P003054.png  \n",
            "  inflating: data/train_imgs/P003055.png  \n",
            "  inflating: data/train_imgs/P003056.png  \n",
            "  inflating: data/train_imgs/P003057.png  \n",
            "  inflating: data/train_imgs/P003058.png  \n",
            "  inflating: data/train_imgs/P003059.png  \n",
            "  inflating: data/train_imgs/P003060.png  \n",
            "  inflating: data/train_imgs/P003061.png  \n",
            "  inflating: data/train_imgs/P003062.png  \n",
            "  inflating: data/train_imgs/P003063.png  \n",
            "  inflating: data/train_imgs/P003064.png  \n",
            "  inflating: data/train_imgs/P003065.png  \n",
            "  inflating: data/train_imgs/P003066.png  \n",
            "  inflating: data/train_imgs/P003067.png  \n",
            "  inflating: data/train_imgs/P003068.png  \n",
            "  inflating: data/train_imgs/P003069.png  \n",
            "  inflating: data/train_imgs/P003070.png  \n",
            "  inflating: data/train_imgs/P003071.png  \n",
            "  inflating: data/train_imgs/P003072.png  \n",
            "  inflating: data/train_imgs/P003073.png  \n",
            "  inflating: data/train_imgs/P003074.png  \n",
            "  inflating: data/train_imgs/P003075.png  \n",
            "  inflating: data/train_imgs/P003076.png  \n",
            "  inflating: data/train_imgs/P003077.png  \n",
            "  inflating: data/train_imgs/P003078.png  \n",
            "  inflating: data/train_imgs/P003079.png  \n",
            "  inflating: data/train_imgs/P003080.png  \n",
            "  inflating: data/train_imgs/P003081.png  \n",
            "  inflating: data/train_imgs/P003082.png  \n",
            "  inflating: data/train_imgs/P003083.png  \n",
            "  inflating: data/train_imgs/P003084.png  \n",
            "  inflating: data/train_imgs/P003085.png  \n",
            "  inflating: data/train_imgs/P003086.png  \n",
            "  inflating: data/train_imgs/P003087.png  \n",
            "  inflating: data/train_imgs/P003088.png  \n",
            "  inflating: data/train_imgs/P003089.png  \n",
            "  inflating: data/train_imgs/P003090.png  \n",
            "  inflating: data/train_imgs/P003091.png  \n",
            "  inflating: data/train_imgs/P003092.png  \n",
            "  inflating: data/train_imgs/P003093.png  \n",
            "  inflating: data/train_imgs/P003094.png  \n",
            "  inflating: data/train_imgs/P003095.png  \n",
            "  inflating: data/train_imgs/P003096.png  \n",
            "  inflating: data/train_imgs/P003097.png  \n",
            "  inflating: data/train_imgs/P003098.png  \n",
            "  inflating: data/train_imgs/P003099.png  \n",
            "  inflating: data/train_imgs/P003100.png  \n",
            "  inflating: data/train_imgs/P003101.png  \n",
            "  inflating: data/train_imgs/P003102.png  \n",
            "  inflating: data/train_imgs/P003103.png  \n",
            "  inflating: data/train_imgs/P003104.png  \n",
            "  inflating: data/train_imgs/P003105.png  \n",
            "  inflating: data/train_imgs/P003106.png  \n",
            "  inflating: data/train_imgs/P003107.png  \n",
            "  inflating: data/train_imgs/P003108.png  \n",
            "  inflating: data/train_imgs/P003109.png  \n",
            "  inflating: data/train_imgs/P003110.png  \n",
            "  inflating: data/train_imgs/P003111.png  \n",
            "  inflating: data/train_imgs/P003112.png  \n",
            "  inflating: data/train_imgs/P003113.png  \n",
            "  inflating: data/train_imgs/P003114.png  \n",
            "  inflating: data/train_imgs/P003115.png  \n",
            "  inflating: data/train_imgs/P003116.png  \n",
            "  inflating: data/train_imgs/P003117.png  \n",
            "  inflating: data/train_imgs/P003118.png  \n",
            "  inflating: data/train_imgs/P003119.png  \n",
            "  inflating: data/train_imgs/P003120.png  \n",
            "  inflating: data/train_imgs/P003121.png  \n",
            "  inflating: data/train_imgs/P003122.png  \n",
            "  inflating: data/train_imgs/P003123.png  \n",
            "  inflating: data/train_imgs/P003124.png  \n",
            "  inflating: data/train_imgs/P003125.png  \n",
            "  inflating: data/train_imgs/P003126.png  \n",
            "  inflating: data/train_imgs/P003127.png  \n",
            "  inflating: data/train_imgs/P003128.png  \n",
            "  inflating: data/train_imgs/P003129.png  \n",
            "  inflating: data/train_imgs/P003130.png  \n",
            "  inflating: data/train_imgs/P003131.png  \n",
            "  inflating: data/train_imgs/P003132.png  \n",
            "  inflating: data/train_imgs/P003133.png  \n",
            "  inflating: data/train_imgs/P003134.png  \n",
            "  inflating: data/train_imgs/P003135.png  \n",
            "  inflating: data/train_imgs/P003136.png  \n",
            "  inflating: data/train_imgs/P003137.png  \n",
            "  inflating: data/train_imgs/P003138.png  \n",
            "  inflating: data/train_imgs/P003139.png  \n",
            "  inflating: data/train_imgs/P003140.png  \n",
            "  inflating: data/train_imgs/P003141.png  \n",
            "  inflating: data/train_imgs/P003142.png  \n",
            "  inflating: data/train_imgs/P003143.png  \n",
            "  inflating: data/train_imgs/P003144.png  \n",
            "  inflating: data/train_imgs/P003145.png  \n",
            "  inflating: data/train_imgs/P003146.png  \n",
            "  inflating: data/train_imgs/P003147.png  \n",
            "  inflating: data/train_imgs/P003148.png  \n",
            "  inflating: data/train_imgs/P003149.png  \n",
            "  inflating: data/train_imgs/P003150.png  \n",
            "  inflating: data/train_imgs/P003151.png  \n",
            "  inflating: data/train_imgs/P003152.png  \n",
            "  inflating: data/train_imgs/P003153.png  \n",
            "  inflating: data/train_imgs/P003154.png  \n",
            "  inflating: data/train_imgs/P003155.png  \n",
            "  inflating: data/train_imgs/P003156.png  \n",
            "  inflating: data/train_imgs/P003157.png  \n",
            "  inflating: data/train_imgs/P003158.png  \n",
            "  inflating: data/train_imgs/P003159.png  \n",
            "  inflating: data/train_imgs/P003160.png  \n",
            "  inflating: data/train_imgs/P003161.png  \n",
            "  inflating: data/train_imgs/P003162.png  \n",
            "  inflating: data/train_imgs/P003163.png  \n",
            "  inflating: data/train_imgs/P003164.png  \n",
            "  inflating: data/train_imgs/P003165.png  \n",
            "  inflating: data/train_imgs/P003166.png  \n",
            "  inflating: data/train_imgs/P003167.png  \n",
            "  inflating: data/train_imgs/P003168.png  \n",
            "  inflating: data/train_imgs/P003169.png  \n",
            "  inflating: data/train_imgs/P003170.png  \n",
            "  inflating: data/train_imgs/P003171.png  \n",
            "  inflating: data/train_imgs/P003172.png  \n",
            "  inflating: data/train_imgs/P003173.png  \n",
            "  inflating: data/train_imgs/P003174.png  \n",
            "  inflating: data/train_imgs/P003175.png  \n",
            "  inflating: data/train_imgs/P003176.png  \n",
            "  inflating: data/train_imgs/P003177.png  \n",
            "  inflating: data/train_imgs/P003178.png  \n",
            "  inflating: data/train_imgs/P003179.png  \n",
            "  inflating: data/train_imgs/P003180.png  \n",
            "  inflating: data/train_imgs/P003181.png  \n",
            "  inflating: data/train_imgs/P003182.png  \n",
            "  inflating: data/train_imgs/P003183.png  \n",
            "  inflating: data/train_imgs/P003184.png  \n",
            "  inflating: data/train_imgs/P003185.png  \n",
            "  inflating: data/train_imgs/P003186.png  \n",
            "  inflating: data/train_imgs/P003187.png  \n",
            "  inflating: data/train_imgs/P003188.png  \n",
            "  inflating: data/train_imgs/P003189.png  \n",
            "  inflating: data/train_imgs/P003190.png  \n",
            "  inflating: data/train_imgs/P003191.png  \n",
            "  inflating: data/train_imgs/P003192.png  \n",
            "  inflating: data/train_imgs/P003193.png  \n",
            "  inflating: data/train_imgs/P003194.png  \n",
            "  inflating: data/train_imgs/P003195.png  \n",
            "  inflating: data/train_imgs/P003196.png  \n",
            "  inflating: data/train_imgs/P003197.png  \n",
            "  inflating: data/train_imgs/P003198.png  \n",
            "  inflating: data/train_imgs/P003199.png  \n",
            "  inflating: data/train_imgs/P003200.png  \n",
            "  inflating: data/train_imgs/P003201.png  \n",
            "  inflating: data/train_imgs/P003202.png  \n",
            "  inflating: data/train_imgs/P003203.png  \n",
            "  inflating: data/train_imgs/P003204.png  \n",
            "  inflating: data/train_imgs/P003205.png  \n",
            "  inflating: data/train_imgs/P003206.png  \n",
            "  inflating: data/train_imgs/P003207.png  \n",
            "  inflating: data/train_imgs/P003208.png  \n",
            "  inflating: data/train_imgs/P003209.png  \n",
            "  inflating: data/train_imgs/P003210.png  \n",
            "  inflating: data/train_imgs/P003211.png  \n",
            "  inflating: data/train_imgs/P003212.png  \n",
            "  inflating: data/train_imgs/P003213.png  \n",
            "  inflating: data/train_imgs/P003214.png  \n",
            "  inflating: data/train_imgs/P003215.png  \n",
            "  inflating: data/train_imgs/P003216.png  \n",
            "  inflating: data/train_imgs/P003217.png  \n",
            "  inflating: data/train_imgs/P003218.png  \n",
            "  inflating: data/train_imgs/P003219.png  \n",
            "  inflating: data/train_imgs/P003220.png  \n",
            "  inflating: data/train_imgs/P003221.png  \n",
            "  inflating: data/train_imgs/P003222.png  \n",
            "  inflating: data/train_imgs/P003223.png  \n",
            "  inflating: data/train_imgs/P003224.png  \n",
            "  inflating: data/train_imgs/P003225.png  \n",
            "  inflating: data/train_imgs/P003226.png  \n",
            "  inflating: data/train_imgs/P003227.png  \n",
            "  inflating: data/train_imgs/P003228.png  \n",
            "  inflating: data/train_imgs/P003229.png  \n",
            "  inflating: data/train_imgs/P003230.png  \n",
            "  inflating: data/train_imgs/P003231.png  \n",
            "  inflating: data/train_imgs/P003232.png  \n",
            "  inflating: data/train_imgs/P003233.png  \n",
            "  inflating: data/train_imgs/P003234.png  \n",
            "  inflating: data/train_imgs/P003235.png  \n",
            "  inflating: data/train_imgs/P003236.png  \n",
            "  inflating: data/train_imgs/P003237.png  \n",
            "  inflating: data/train_imgs/P003238.png  \n",
            "  inflating: data/train_imgs/P003239.png  \n",
            "  inflating: data/train_imgs/P003240.png  \n",
            "  inflating: data/train_imgs/P003241.png  \n",
            "  inflating: data/train_imgs/P003242.png  \n",
            "  inflating: data/train_imgs/P003243.png  \n",
            "  inflating: data/train_imgs/P003244.png  \n",
            "  inflating: data/train_imgs/P003245.png  \n",
            "  inflating: data/train_imgs/P003246.png  \n",
            "  inflating: data/train_imgs/P003247.png  \n",
            "  inflating: data/train_imgs/P003248.png  \n",
            "  inflating: data/train_imgs/P003249.png  \n",
            "  inflating: data/train_imgs/P003250.png  \n",
            "  inflating: data/train_imgs/P003251.png  \n",
            "  inflating: data/train_imgs/P003252.png  \n",
            "  inflating: data/train_imgs/P003253.png  \n",
            "  inflating: data/train_imgs/P003254.png  \n",
            "  inflating: data/train_imgs/P003255.png  \n",
            "  inflating: data/train_imgs/P003256.png  \n",
            "  inflating: data/train_imgs/P003257.png  \n",
            "  inflating: data/train_imgs/P003258.png  \n",
            "  inflating: data/train_imgs/P003259.png  \n",
            "  inflating: data/train_imgs/P003260.png  \n",
            "  inflating: data/train_imgs/P003261.png  \n",
            "  inflating: data/train_imgs/P003262.png  \n",
            "  inflating: data/train_imgs/P003263.png  \n",
            "  inflating: data/train_imgs/P003264.png  \n",
            "  inflating: data/train_imgs/P003265.png  \n",
            "  inflating: data/train_imgs/P003266.png  \n",
            "  inflating: data/train_imgs/P003267.png  \n",
            "  inflating: data/train_imgs/P003268.png  \n",
            "  inflating: data/train_imgs/P003269.png  \n",
            "  inflating: data/train_imgs/P003270.png  \n",
            "  inflating: data/train_imgs/P003271.png  \n",
            "  inflating: data/train_imgs/P003272.png  \n",
            "  inflating: data/train_imgs/P003273.png  \n",
            "  inflating: data/train_imgs/P003274.png  \n",
            "  inflating: data/train_imgs/P003275.png  \n",
            "  inflating: data/train_imgs/P003276.png  \n",
            "  inflating: data/train_imgs/P003277.png  \n",
            "  inflating: data/train_imgs/P003278.png  \n",
            "  inflating: data/train_imgs/P003279.png  \n",
            "  inflating: data/train_imgs/P003280.png  \n",
            "  inflating: data/train_imgs/P003281.png  \n",
            "  inflating: data/train_imgs/P003282.png  \n",
            "  inflating: data/train_imgs/P003283.png  \n",
            "  inflating: data/train_imgs/P003284.png  \n",
            "  inflating: data/train_imgs/P003285.png  \n",
            "  inflating: data/train_imgs/P003286.png  \n",
            "  inflating: data/train_imgs/P003287.png  \n",
            "  inflating: data/train_imgs/P003288.png  \n",
            "  inflating: data/train_imgs/P003289.png  \n",
            "  inflating: data/train_imgs/P003290.png  \n",
            "  inflating: data/train_imgs/P003291.png  \n",
            "  inflating: data/train_imgs/P003292.png  \n",
            "  inflating: data/train_imgs/P003293.png  \n",
            "  inflating: data/train_imgs/P003294.png  \n",
            "  inflating: data/train_imgs/P003295.png  \n",
            "  inflating: data/train_imgs/P003296.png  \n",
            "  inflating: data/train_imgs/P003297.png  \n",
            "  inflating: data/train_imgs/P003298.png  \n",
            "  inflating: data/train_imgs/P003299.png  \n",
            "  inflating: data/train_imgs/P003300.png  \n",
            "  inflating: data/train_imgs/P003301.png  \n",
            "  inflating: data/train_imgs/P003302.png  \n",
            "  inflating: data/train_imgs/P003303.png  \n",
            "  inflating: data/train_imgs/P003304.png  \n",
            "  inflating: data/train_imgs/P003305.png  \n",
            "  inflating: data/train_imgs/P003306.png  \n",
            "  inflating: data/train_imgs/P003307.png  \n",
            "  inflating: data/train_imgs/P003308.png  \n",
            "  inflating: data/train_imgs/P003309.png  \n",
            "  inflating: data/train_imgs/P003310.png  \n",
            "  inflating: data/train_imgs/P003311.png  \n",
            "  inflating: data/train_imgs/P003312.png  \n",
            "  inflating: data/train_imgs/P003313.png  \n",
            "  inflating: data/train_imgs/P003314.png  \n",
            "  inflating: data/train_imgs/P003315.png  \n",
            "  inflating: data/train_imgs/P003316.png  \n",
            "  inflating: data/train_imgs/P003317.png  \n",
            "  inflating: data/train_imgs/P003318.png  \n",
            "  inflating: data/train_imgs/P003319.png  \n",
            "  inflating: data/train_imgs/P003320.png  \n",
            "  inflating: data/train_imgs/P003321.png  \n",
            "  inflating: data/train_imgs/P003322.png  \n",
            "  inflating: data/train_imgs/P003323.png  \n",
            "  inflating: data/train_imgs/P003324.png  \n",
            "  inflating: data/train_imgs/P003325.png  \n",
            "  inflating: data/train_imgs/P003326.png  \n",
            "  inflating: data/train_imgs/P003327.png  \n",
            "  inflating: data/train_imgs/P003328.png  \n",
            "  inflating: data/train_imgs/P003329.png  \n",
            "  inflating: data/train_imgs/P003330.png  \n",
            "  inflating: data/train_imgs/P003331.png  \n",
            "  inflating: data/train_imgs/P003332.png  \n",
            "  inflating: data/train_imgs/P003333.png  \n",
            "  inflating: data/train_imgs/P003334.png  \n",
            "  inflating: data/train_imgs/P003335.png  \n",
            "  inflating: data/train_imgs/P003336.png  \n",
            "  inflating: data/train_imgs/P003337.png  \n",
            "  inflating: data/train_imgs/P003338.png  \n",
            "  inflating: data/train_imgs/P003339.png  \n",
            "  inflating: data/train_imgs/P003340.png  \n",
            "  inflating: data/train_imgs/P003341.png  \n",
            "  inflating: data/train_imgs/P003342.png  \n",
            "  inflating: data/train_imgs/P003343.png  \n",
            "  inflating: data/train_imgs/P003344.png  \n",
            "  inflating: data/train_imgs/P003345.png  \n",
            "  inflating: data/train_imgs/P003346.png  \n",
            "  inflating: data/train_imgs/P003347.png  \n",
            "  inflating: data/train_imgs/P003348.png  \n",
            "  inflating: data/train_imgs/P003349.png  \n",
            "  inflating: data/train_imgs/P003350.png  \n",
            "  inflating: data/train_imgs/P003351.png  \n",
            "  inflating: data/train_imgs/P003352.png  \n",
            "  inflating: data/train_imgs/P003353.png  \n",
            "  inflating: data/train_imgs/P003354.png  \n",
            "  inflating: data/train_imgs/P003355.png  \n",
            "  inflating: data/train_imgs/P003356.png  \n",
            "  inflating: data/train_imgs/P003357.png  \n",
            "  inflating: data/train_imgs/P003358.png  \n",
            "  inflating: data/train_imgs/P003359.png  \n",
            "  inflating: data/train_imgs/P003360.png  \n",
            "  inflating: data/train_imgs/P003361.png  \n",
            "  inflating: data/train_imgs/P003362.png  \n",
            "  inflating: data/train_imgs/P003363.png  \n",
            "  inflating: data/train_imgs/P003364.png  \n",
            "  inflating: data/train_imgs/P003365.png  \n",
            "  inflating: data/train_imgs/P003366.png  \n",
            "  inflating: data/train_imgs/P003367.png  \n",
            "  inflating: data/train_imgs/P003368.png  \n",
            "  inflating: data/train_imgs/P003369.png  \n",
            "  inflating: data/train_imgs/P003370.png  \n",
            "  inflating: data/train_imgs/P003371.png  \n",
            "  inflating: data/train_imgs/P003372.png  \n",
            "  inflating: data/train_imgs/P003373.png  \n",
            "  inflating: data/train_imgs/P003374.png  \n",
            "  inflating: data/train_imgs/P003375.png  \n",
            "  inflating: data/train_imgs/P003376.png  \n",
            "  inflating: data/train_imgs/P003377.png  \n",
            "  inflating: data/train_imgs/P003378.png  \n",
            "  inflating: data/train_imgs/P003379.png  \n",
            "  inflating: data/train_imgs/P003380.png  \n",
            "  inflating: data/train_imgs/P003381.png  \n",
            "  inflating: data/train_imgs/P003382.png  \n",
            "  inflating: data/train_imgs/P003383.png  \n",
            "  inflating: data/train_imgs/P003384.png  \n",
            "  inflating: data/train_imgs/P003385.png  \n",
            "  inflating: data/train_imgs/P003386.png  \n",
            "  inflating: data/train_imgs/P003387.png  \n",
            "  inflating: data/train_imgs/P003388.png  \n",
            "  inflating: data/train_imgs/P003389.png  \n",
            "  inflating: data/train_imgs/P003390.png  \n",
            "  inflating: data/train_imgs/P003391.png  \n",
            "  inflating: data/train_imgs/P003392.png  \n",
            "  inflating: data/train_imgs/P003393.png  \n",
            "  inflating: data/train_imgs/P003394.png  \n",
            "  inflating: data/train_imgs/P003395.png  \n",
            "  inflating: data/train_imgs/P003396.png  \n",
            "  inflating: data/train_imgs/P003397.png  \n",
            "  inflating: data/train_imgs/P003398.png  \n",
            "  inflating: data/train_imgs/P003399.png  \n",
            "  inflating: data/train_imgs/P003400.png  \n",
            "  inflating: data/train_imgs/P003401.png  \n",
            "  inflating: data/train_imgs/P003402.png  \n",
            "  inflating: data/train_imgs/P003403.png  \n",
            "  inflating: data/train_imgs/P003404.png  \n",
            "  inflating: data/train_imgs/P003405.png  \n",
            "  inflating: data/train_imgs/P003406.png  \n",
            "  inflating: data/train_imgs/P003407.png  \n",
            "  inflating: data/train_imgs/P003408.png  \n",
            "  inflating: data/train_imgs/P003409.png  \n",
            "  inflating: data/train_imgs/P003410.png  \n",
            "  inflating: data/train_imgs/P003411.png  \n",
            "  inflating: data/train_imgs/P003412.png  \n",
            "  inflating: data/train_imgs/P003413.png  \n",
            "  inflating: data/train_imgs/P003414.png  \n",
            "  inflating: data/train_imgs/P003415.png  \n",
            "  inflating: data/train_imgs/P003416.png  \n",
            "  inflating: data/train_imgs/P003417.png  \n",
            "  inflating: data/train_imgs/P003418.png  \n",
            "  inflating: data/train_imgs/P003419.png  \n",
            "  inflating: data/train_imgs/P003420.png  \n",
            "  inflating: data/train_imgs/P003421.png  \n",
            "  inflating: data/train_imgs/P003422.png  \n",
            "  inflating: data/train_imgs/P003423.png  \n",
            "  inflating: data/train_imgs/P003424.png  \n",
            "  inflating: data/train_imgs/P003425.png  \n",
            "  inflating: data/train_imgs/P003426.png  \n",
            "  inflating: data/train_imgs/P003427.png  \n",
            "  inflating: data/train_imgs/P003428.png  \n",
            "  inflating: data/train_imgs/P003429.png  \n",
            "  inflating: data/train_imgs/P003430.png  \n",
            "  inflating: data/train_imgs/P003431.png  \n",
            "  inflating: data/train_imgs/P003432.png  \n",
            "  inflating: data/train_imgs/P003433.png  \n",
            "  inflating: data/train_imgs/P003434.png  \n",
            "  inflating: data/train_imgs/P003435.png  \n",
            "  inflating: data/train_imgs/P003436.png  \n",
            "  inflating: data/train_imgs/P003437.png  \n",
            "  inflating: data/train_imgs/P003438.png  \n",
            "  inflating: data/train_imgs/P003439.png  \n",
            "  inflating: data/train_imgs/P003440.png  \n",
            "  inflating: data/train_imgs/P003441.png  \n",
            "  inflating: data/train_imgs/P003442.png  \n",
            "  inflating: data/train_imgs/P003443.png  \n",
            "  inflating: data/train_imgs/P003444.png  \n",
            "  inflating: data/train_imgs/P003445.png  \n",
            "  inflating: data/train_imgs/P003446.png  \n",
            "  inflating: data/train_imgs/P003447.png  \n",
            "  inflating: data/train_imgs/P003448.png  \n",
            "  inflating: data/train_imgs/P003449.png  \n",
            "  inflating: data/train_imgs/P003450.png  \n",
            "  inflating: data/train_imgs/P003451.png  \n",
            "  inflating: data/train_imgs/P003452.png  \n",
            "  inflating: data/train_imgs/P003453.png  \n",
            "  inflating: data/train_imgs/P003454.png  \n",
            "  inflating: data/train_imgs/P003455.png  \n",
            "  inflating: data/train_imgs/P003456.png  \n",
            "  inflating: data/train_imgs/P003457.png  \n",
            "  inflating: data/train_imgs/P003458.png  \n",
            "  inflating: data/train_imgs/P003459.png  \n",
            "  inflating: data/train_imgs/P003460.png  \n",
            "  inflating: data/train_imgs/P003461.png  \n",
            "  inflating: data/train_imgs/P003462.png  \n",
            "  inflating: data/train_imgs/P003463.png  \n",
            "  inflating: data/train_imgs/P003464.png  \n",
            "  inflating: data/train_imgs/P003465.png  \n",
            "  inflating: data/train_imgs/P003466.png  \n",
            "  inflating: data/train_imgs/P003467.png  \n",
            "  inflating: data/train_imgs/P003468.png  \n",
            "  inflating: data/train_imgs/P003469.png  \n",
            "  inflating: data/train_imgs/P003470.png  \n",
            "  inflating: data/train_imgs/P003471.png  \n",
            "  inflating: data/train_imgs/P003472.png  \n",
            "  inflating: data/train_imgs/P003473.png  \n",
            "  inflating: data/train_imgs/P003474.png  \n",
            "  inflating: data/train_imgs/P003475.png  \n",
            "  inflating: data/train_imgs/P003476.png  \n",
            "  inflating: data/train_imgs/P003477.png  \n",
            "  inflating: data/train_imgs/P003478.png  \n",
            "  inflating: data/train_imgs/P003479.png  \n",
            "  inflating: data/train_imgs/P003480.png  \n",
            "  inflating: data/train_imgs/P003481.png  \n",
            "  inflating: data/train_imgs/P003482.png  \n",
            "  inflating: data/train_imgs/P003483.png  \n",
            "  inflating: data/train_imgs/P003484.png  \n",
            "  inflating: data/train_imgs/P003485.png  \n",
            "  inflating: data/train_imgs/P003486.png  \n",
            "  inflating: data/train_imgs/P003487.png  \n",
            "  inflating: data/train_imgs/P003488.png  \n",
            "  inflating: data/train_imgs/P003489.png  \n",
            "  inflating: data/train_imgs/P003490.png  \n",
            "  inflating: data/train_imgs/P003491.png  \n",
            "  inflating: data/train_imgs/P003492.png  \n",
            "  inflating: data/train_imgs/P003493.png  \n",
            "  inflating: data/train_imgs/P003494.png  \n",
            "  inflating: data/train_imgs/P003495.png  \n",
            "  inflating: data/train_imgs/P003496.png  \n",
            "  inflating: data/train_imgs/P003497.png  \n",
            "  inflating: data/train_imgs/P003498.png  \n",
            "  inflating: data/train_imgs/P003499.png  \n",
            "  inflating: data/train_imgs/P003500.png  \n",
            "  inflating: data/train_imgs/P003501.png  \n",
            "  inflating: data/train_imgs/P003502.png  \n",
            "  inflating: data/train_imgs/P003503.png  \n",
            "  inflating: data/train_imgs/P003504.png  \n",
            "  inflating: data/train_imgs/P003505.png  \n",
            "  inflating: data/train_imgs/P003506.png  \n",
            "  inflating: data/train_imgs/P003507.png  \n",
            "  inflating: data/train_imgs/P003508.png  \n",
            "  inflating: data/train_imgs/P003509.png  \n",
            "  inflating: data/train_imgs/P003510.png  \n",
            "  inflating: data/train_imgs/P003511.png  \n",
            "  inflating: data/train_imgs/P003512.png  \n",
            "  inflating: data/train_imgs/P003513.png  \n",
            "  inflating: data/train_imgs/P003514.png  \n",
            "  inflating: data/train_imgs/P003515.png  \n",
            "  inflating: data/train_imgs/P003516.png  \n",
            "  inflating: data/train_imgs/P003517.png  \n",
            "  inflating: data/train_imgs/P003518.png  \n",
            "  inflating: data/train_imgs/P003519.png  \n",
            "  inflating: data/train_imgs/P003520.png  \n",
            "  inflating: data/train_imgs/P003521.png  \n",
            "  inflating: data/train_imgs/P003522.png  \n",
            "  inflating: data/train_imgs/P003523.png  \n",
            "  inflating: data/train_imgs/P003524.png  \n",
            "  inflating: data/train_imgs/P003525.png  \n",
            "  inflating: data/train_imgs/P003526.png  \n",
            "  inflating: data/train_imgs/P003527.png  \n",
            "  inflating: data/train_imgs/P003528.png  \n",
            "  inflating: data/train_imgs/P003529.png  \n",
            "  inflating: data/train_imgs/P003530.png  \n",
            "  inflating: data/train_imgs/P003531.png  \n",
            "  inflating: data/train_imgs/P003532.png  \n",
            "  inflating: data/train_imgs/P003533.png  \n",
            "  inflating: data/train_imgs/P003534.png  \n",
            "  inflating: data/train_imgs/P003535.png  \n",
            "  inflating: data/train_imgs/P003536.png  \n",
            "  inflating: data/train_imgs/P003537.png  \n",
            "  inflating: data/train_imgs/P003538.png  \n",
            "  inflating: data/train_imgs/P003539.png  \n",
            "  inflating: data/train_imgs/P003540.png  \n",
            "  inflating: data/train_imgs/P003541.png  \n",
            "  inflating: data/train_imgs/P003542.png  \n",
            "  inflating: data/train_imgs/P003543.png  \n",
            "  inflating: data/train_imgs/P003544.png  \n",
            "  inflating: data/train_imgs/P003545.png  \n",
            "  inflating: data/train_imgs/P003546.png  \n",
            "  inflating: data/train_imgs/P003547.png  \n",
            "  inflating: data/train_imgs/P003548.png  \n",
            "  inflating: data/train_imgs/P003549.png  \n",
            "  inflating: data/train_imgs/P003550.png  \n",
            "  inflating: data/train_imgs/P003551.png  \n",
            "  inflating: data/train_imgs/P003552.png  \n",
            "  inflating: data/train_imgs/P003553.png  \n",
            "  inflating: data/train_imgs/P003554.png  \n",
            "  inflating: data/train_imgs/P003555.png  \n",
            "  inflating: data/train_imgs/P003556.png  \n",
            "  inflating: data/train_imgs/P003557.png  \n",
            "  inflating: data/train_imgs/P003558.png  \n",
            "  inflating: data/train_imgs/P003559.png  \n",
            "  inflating: data/train_imgs/P003560.png  \n",
            "  inflating: data/train_imgs/P003561.png  \n",
            "  inflating: data/train_imgs/P003562.png  \n",
            "  inflating: data/train_imgs/P003563.png  \n",
            "  inflating: data/train_imgs/P003564.png  \n",
            "  inflating: data/train_imgs/P003565.png  \n",
            "  inflating: data/train_imgs/P003566.png  \n",
            "  inflating: data/train_imgs/P003567.png  \n",
            "  inflating: data/train_imgs/P003568.png  \n",
            "  inflating: data/train_imgs/P003569.png  \n",
            "  inflating: data/train_imgs/P003570.png  \n",
            "  inflating: data/train_imgs/P003571.png  \n",
            "  inflating: data/train_imgs/P003572.png  \n",
            "  inflating: data/train_imgs/P003573.png  \n",
            "  inflating: data/train_imgs/P003574.png  \n",
            "  inflating: data/train_imgs/P003575.png  \n",
            "  inflating: data/train_imgs/P003576.png  \n",
            "  inflating: data/train_imgs/P003577.png  \n",
            "  inflating: data/train_imgs/P003578.png  \n",
            "  inflating: data/train_imgs/P003579.png  \n",
            "  inflating: data/train_imgs/P003580.png  \n",
            "  inflating: data/train_imgs/P003581.png  \n",
            "  inflating: data/train_imgs/P003582.png  \n",
            "  inflating: data/train_imgs/P003583.png  \n",
            "  inflating: data/train_imgs/P003584.png  \n",
            "  inflating: data/train_imgs/P003585.png  \n",
            "  inflating: data/train_imgs/P003586.png  \n",
            "  inflating: data/train_imgs/P003587.png  \n",
            "  inflating: data/train_imgs/P003588.png  \n",
            "  inflating: data/train_imgs/P003589.png  \n",
            "  inflating: data/train_imgs/P003590.png  \n",
            "  inflating: data/train_imgs/P003591.png  \n",
            "  inflating: data/train_imgs/P003592.png  \n",
            "  inflating: data/train_imgs/P003593.png  \n",
            "  inflating: data/train_imgs/P003594.png  \n",
            "  inflating: data/train_imgs/P003595.png  \n",
            "  inflating: data/train_imgs/P003596.png  \n",
            "  inflating: data/train_imgs/P003597.png  \n",
            "  inflating: data/train_imgs/P003598.png  \n",
            "  inflating: data/train_imgs/P003599.png  \n",
            "  inflating: data/train_imgs/P003600.png  \n",
            "  inflating: data/train_imgs/P003601.png  \n",
            "  inflating: data/train_imgs/P003602.png  \n",
            "  inflating: data/train_imgs/P003603.png  \n",
            "  inflating: data/train_imgs/P003604.png  \n",
            "  inflating: data/train_imgs/P003605.png  \n",
            "  inflating: data/train_imgs/P003606.png  \n",
            "  inflating: data/train_imgs/P003607.png  \n",
            "  inflating: data/train_imgs/P003608.png  \n",
            "  inflating: data/train_imgs/P003609.png  \n",
            "  inflating: data/train_imgs/P003610.png  \n",
            "  inflating: data/train_imgs/P003611.png  \n",
            "  inflating: data/train_imgs/P003612.png  \n",
            "  inflating: data/train_imgs/P003613.png  \n",
            "  inflating: data/train_imgs/P003614.png  \n",
            "  inflating: data/train_imgs/P003615.png  \n",
            "  inflating: data/train_imgs/P003616.png  \n",
            "  inflating: data/train_imgs/P003617.png  \n",
            "  inflating: data/train_imgs/P003618.png  \n",
            "  inflating: data/train_imgs/P003619.png  \n",
            "  inflating: data/train_imgs/P003620.png  \n",
            "  inflating: data/train_imgs/P003621.png  \n",
            "  inflating: data/train_imgs/P003622.png  \n",
            "  inflating: data/train_imgs/P003623.png  \n",
            "  inflating: data/train_imgs/P003624.png  \n",
            "  inflating: data/train_imgs/P003625.png  \n",
            "  inflating: data/train_imgs/P003626.png  \n",
            "  inflating: data/train_imgs/P003627.png  \n",
            "  inflating: data/train_imgs/P003628.png  \n",
            "  inflating: data/train_imgs/P003629.png  \n",
            "  inflating: data/train_imgs/P003630.png  \n",
            "  inflating: data/train_imgs/P003631.png  \n",
            "  inflating: data/train_imgs/P003632.png  \n",
            "  inflating: data/train_imgs/P003633.png  \n",
            "  inflating: data/train_imgs/P003634.png  \n",
            "  inflating: data/train_imgs/P003635.png  \n",
            "  inflating: data/train_imgs/P003636.png  \n",
            "  inflating: data/train_imgs/P003637.png  \n",
            "  inflating: data/train_imgs/P003638.png  \n",
            "  inflating: data/train_imgs/P003639.png  \n",
            "  inflating: data/train_imgs/P003640.png  \n",
            "  inflating: data/train_imgs/P003641.png  \n",
            "  inflating: data/train_imgs/P003642.png  \n",
            "  inflating: data/train_imgs/P003643.png  \n",
            "  inflating: data/train_imgs/P003644.png  \n",
            "  inflating: data/train_imgs/P003645.png  \n",
            "  inflating: data/train_imgs/P003646.png  \n",
            "  inflating: data/train_imgs/P003647.png  \n",
            "  inflating: data/train_imgs/P003648.png  \n",
            "  inflating: data/train_imgs/P003649.png  \n",
            "  inflating: data/train_imgs/P003650.png  \n",
            "  inflating: data/train_imgs/P003651.png  \n",
            "  inflating: data/train_imgs/P003652.png  \n",
            "  inflating: data/train_imgs/P003653.png  \n",
            "  inflating: data/train_imgs/P003654.png  \n",
            "  inflating: data/train_imgs/P003655.png  \n",
            "  inflating: data/train_imgs/P003656.png  \n",
            "  inflating: data/train_imgs/P003657.png  \n",
            "  inflating: data/train_imgs/P003658.png  \n",
            "  inflating: data/train_imgs/P003659.png  \n",
            "  inflating: data/train_imgs/P003660.png  \n",
            "  inflating: data/train_imgs/P003661.png  \n",
            "  inflating: data/train_imgs/P003662.png  \n",
            "  inflating: data/train_imgs/P003663.png  \n",
            "  inflating: data/train_imgs/P003664.png  \n",
            "  inflating: data/train_imgs/P003665.png  \n",
            "  inflating: data/train_imgs/P003666.png  \n",
            "  inflating: data/train_imgs/P003667.png  \n",
            "  inflating: data/train_imgs/P003668.png  \n",
            "  inflating: data/train_imgs/P003669.png  \n",
            "  inflating: data/train_imgs/P003670.png  \n",
            "  inflating: data/train_imgs/P003671.png  \n",
            "  inflating: data/train_imgs/P003672.png  \n",
            "  inflating: data/train_imgs/P003673.png  \n",
            "  inflating: data/train_imgs/P003674.png  \n",
            "  inflating: data/train_imgs/P003675.png  \n",
            "  inflating: data/train_imgs/P003676.png  \n",
            "  inflating: data/train_imgs/P003677.png  \n",
            "  inflating: data/train_imgs/P003678.png  \n",
            "  inflating: data/train_imgs/P003679.png  \n",
            "  inflating: data/train_imgs/P003680.png  \n",
            "  inflating: data/train_imgs/P003681.png  \n",
            "  inflating: data/train_imgs/P003682.png  \n",
            "  inflating: data/train_imgs/P003683.png  \n",
            "  inflating: data/train_imgs/P003684.png  \n",
            "  inflating: data/train_imgs/P003685.png  \n",
            "  inflating: data/train_imgs/P003686.png  \n",
            "  inflating: data/train_imgs/P003687.png  \n",
            "  inflating: data/train_imgs/P003688.png  \n",
            "  inflating: data/train_imgs/P003689.png  \n",
            "  inflating: data/train_imgs/P003690.png  \n",
            "  inflating: data/train_imgs/P003691.png  \n",
            "  inflating: data/train_imgs/P003692.png  \n",
            "  inflating: data/train_imgs/P003693.png  \n",
            "  inflating: data/train_imgs/P003694.png  \n",
            "  inflating: data/train_imgs/P003695.png  \n",
            "  inflating: data/train_imgs/P003696.png  \n",
            "  inflating: data/train_imgs/P003697.png  \n",
            "  inflating: data/train_imgs/P003698.png  \n",
            "  inflating: data/train_imgs/P003699.png  \n",
            "  inflating: data/train_imgs/P003700.png  \n",
            "  inflating: data/train_imgs/P003701.png  \n",
            "  inflating: data/train_imgs/P003702.png  \n",
            "  inflating: data/train_imgs/P003703.png  \n",
            "  inflating: data/train_imgs/P003704.png  \n",
            "  inflating: data/train_imgs/P003705.png  \n",
            "  inflating: data/train_imgs/P003706.png  \n",
            "  inflating: data/train_imgs/P003707.png  \n",
            "  inflating: data/train_imgs/P003708.png  \n",
            "  inflating: data/train_imgs/P003709.png  \n",
            "  inflating: data/train_imgs/P003710.png  \n",
            "  inflating: data/train_imgs/P003711.png  \n",
            "  inflating: data/train_imgs/P003712.png  \n",
            "  inflating: data/train_imgs/P003713.png  \n",
            "  inflating: data/train_imgs/P003714.png  \n",
            "  inflating: data/train_imgs/P003715.png  \n",
            "  inflating: data/train_imgs/P003716.png  \n",
            "  inflating: data/train_imgs/P003717.png  \n",
            "  inflating: data/train_imgs/P003718.png  \n",
            "  inflating: data/train_imgs/P003719.png  \n",
            "  inflating: data/train_imgs/P003720.png  \n",
            "  inflating: data/train_imgs/P003721.png  \n",
            "  inflating: data/train_imgs/P003722.png  \n",
            "  inflating: data/train_imgs/P003723.png  \n",
            "  inflating: data/train_imgs/P003724.png  \n",
            "  inflating: data/train_imgs/P003725.png  \n",
            "  inflating: data/train_imgs/P003726.png  \n",
            "  inflating: data/train_imgs/P003727.png  \n",
            "  inflating: data/train_imgs/P003728.png  \n",
            "  inflating: data/train_imgs/P003729.png  \n",
            "  inflating: data/train_imgs/P003730.png  \n",
            "  inflating: data/train_imgs/P003731.png  \n",
            "  inflating: data/train_imgs/P003732.png  \n",
            "  inflating: data/train_imgs/P003733.png  \n",
            "  inflating: data/train_imgs/P003734.png  \n",
            "  inflating: data/train_imgs/P003735.png  \n",
            "  inflating: data/train_imgs/P003736.png  \n",
            "  inflating: data/train_imgs/P003737.png  \n",
            "  inflating: data/train_imgs/P003738.png  \n",
            "  inflating: data/train_imgs/P003739.png  \n",
            "  inflating: data/train_imgs/P003740.png  \n",
            "  inflating: data/train_imgs/P003741.png  \n",
            "  inflating: data/train_imgs/P003742.png  \n",
            "  inflating: data/train_imgs/P003743.png  \n",
            "  inflating: data/train_imgs/P003744.png  \n",
            "  inflating: data/train_imgs/P003745.png  \n",
            "  inflating: data/train_imgs/P003746.png  \n",
            "  inflating: data/train_imgs/P003747.png  \n",
            "  inflating: data/train_imgs/P003748.png  \n",
            "  inflating: data/train_imgs/P003749.png  \n",
            "  inflating: data/train_imgs/P003750.png  \n",
            "  inflating: data/train_imgs/P003751.png  \n",
            "  inflating: data/train_imgs/P003752.png  \n",
            "  inflating: data/train_imgs/P003753.png  \n",
            "  inflating: data/train_imgs/P003754.png  \n",
            "  inflating: data/train_imgs/P003755.png  \n",
            "  inflating: data/train_imgs/P003756.png  \n",
            "  inflating: data/train_imgs/P003757.png  \n",
            "  inflating: data/train_imgs/P003758.png  \n",
            "  inflating: data/train_imgs/P003759.png  \n",
            "  inflating: data/train_imgs/P003760.png  \n",
            "  inflating: data/train_imgs/P003761.png  \n",
            "  inflating: data/train_imgs/P003762.png  \n",
            "  inflating: data/train_imgs/P003763.png  \n",
            "  inflating: data/train_imgs/P003764.png  \n",
            "  inflating: data/train_imgs/P003765.png  \n",
            "  inflating: data/train_imgs/P003766.png  \n",
            "  inflating: data/train_imgs/P003767.png  \n",
            "  inflating: data/train_imgs/P003768.png  \n",
            "  inflating: data/train_imgs/P003769.png  \n",
            "  inflating: data/train_imgs/P003770.png  \n",
            "  inflating: data/train_imgs/P003771.png  \n",
            "  inflating: data/train_imgs/P003772.png  \n",
            "  inflating: data/train_imgs/P003773.png  \n",
            "  inflating: data/train_imgs/P003774.png  \n",
            "  inflating: data/train_imgs/P003775.png  \n",
            "  inflating: data/train_imgs/P003776.png  \n",
            "  inflating: data/train_imgs/P003777.png  \n",
            "  inflating: data/train_imgs/P003778.png  \n",
            "  inflating: data/train_imgs/P003779.png  \n",
            "  inflating: data/train_imgs/P003780.png  \n",
            "  inflating: data/train_imgs/P003781.png  \n",
            "  inflating: data/train_imgs/P003782.png  \n",
            "  inflating: data/train_imgs/P003783.png  \n",
            "  inflating: data/train_imgs/P003784.png  \n",
            "  inflating: data/train_imgs/P003785.png  \n",
            "  inflating: data/train_imgs/P003786.png  \n",
            "  inflating: data/train_imgs/P003787.png  \n",
            "  inflating: data/train_imgs/P003788.png  \n",
            "  inflating: data/train_imgs/P003789.png  \n",
            "  inflating: data/train_imgs/P003790.png  \n",
            "  inflating: data/train_imgs/P003791.png  \n",
            "  inflating: data/train_imgs/P003792.png  \n",
            "  inflating: data/train_imgs/P003793.png  \n",
            "  inflating: data/train_imgs/P003794.png  \n",
            "  inflating: data/train_imgs/P003795.png  \n",
            "  inflating: data/train_imgs/P003796.png  \n",
            "  inflating: data/train_imgs/P003797.png  \n",
            "  inflating: data/train_imgs/P003798.png  \n",
            "  inflating: data/train_imgs/P003799.png  \n",
            "  inflating: data/train_imgs/P003800.png  \n",
            "  inflating: data/train_imgs/P003801.png  \n",
            "  inflating: data/train_imgs/P003802.png  \n",
            "  inflating: data/train_imgs/P003803.png  \n",
            "  inflating: data/train_imgs/P003804.png  \n",
            "  inflating: data/train_imgs/P003805.png  \n",
            "  inflating: data/train_imgs/P003806.png  \n",
            "  inflating: data/train_imgs/P003807.png  \n",
            "  inflating: data/train_imgs/P003808.png  \n",
            "  inflating: data/train_imgs/P003809.png  \n",
            "  inflating: data/train_imgs/P003810.png  \n",
            "  inflating: data/train_imgs/P003811.png  \n",
            "  inflating: data/train_imgs/P003812.png  \n",
            "  inflating: data/train_imgs/P003813.png  \n",
            "  inflating: data/train_imgs/P003814.png  \n",
            "  inflating: data/train_imgs/P003815.png  \n",
            "  inflating: data/train_imgs/P003816.png  \n",
            "  inflating: data/train_imgs/P003817.png  \n",
            "  inflating: data/train_imgs/P003818.png  \n",
            "  inflating: data/train_imgs/P003819.png  \n",
            "  inflating: data/train_imgs/P003820.png  \n",
            "  inflating: data/train_imgs/P003821.png  \n",
            "  inflating: data/train_imgs/P003822.png  \n",
            "  inflating: data/train_imgs/P003823.png  \n",
            "  inflating: data/train_imgs/P003824.png  \n",
            "  inflating: data/train_imgs/P003825.png  \n",
            "  inflating: data/train_imgs/P003826.png  \n",
            "  inflating: data/train_imgs/P003827.png  \n",
            "  inflating: data/train_imgs/P003828.png  \n",
            "  inflating: data/train_imgs/P003829.png  \n",
            "  inflating: data/train_imgs/P003830.png  \n",
            "  inflating: data/train_imgs/P003831.png  \n",
            "  inflating: data/train_imgs/P003832.png  \n",
            "  inflating: data/train_imgs/P003833.png  \n",
            "  inflating: data/train_imgs/P003834.png  \n",
            "  inflating: data/train_imgs/P003835.png  \n",
            "  inflating: data/train_imgs/P003836.png  \n",
            "  inflating: data/train_imgs/P003837.png  \n",
            "  inflating: data/train_imgs/P003838.png  \n",
            "  inflating: data/train_imgs/P003839.png  \n",
            "  inflating: data/train_imgs/P003840.png  \n",
            "  inflating: data/train_imgs/P003841.png  \n",
            "  inflating: data/train_imgs/P003842.png  \n",
            "  inflating: data/train_imgs/P003843.png  \n",
            "  inflating: data/train_imgs/P003844.png  \n",
            "  inflating: data/train_imgs/P003845.png  \n",
            "  inflating: data/train_imgs/P003846.png  \n",
            "  inflating: data/train_imgs/P003847.png  \n",
            "  inflating: data/train_imgs/P003848.png  \n",
            "  inflating: data/train_imgs/P003849.png  \n",
            "  inflating: data/train_imgs/P003850.png  \n",
            "  inflating: data/train_imgs/P003851.png  \n",
            "  inflating: data/train_imgs/P003852.png  \n",
            "  inflating: data/train_imgs/P003853.png  \n",
            "  inflating: data/train_imgs/P003854.png  \n",
            "  inflating: data/train_imgs/P003855.png  \n",
            "  inflating: data/train_imgs/P003856.png  \n",
            "  inflating: data/train_imgs/P003857.png  \n",
            "  inflating: data/train_imgs/P003858.png  \n",
            "  inflating: data/train_imgs/P003859.png  \n",
            "  inflating: data/train_imgs/P003860.png  \n",
            "  inflating: data/train_imgs/P003861.png  \n",
            "  inflating: data/train_imgs/P003862.png  \n",
            "  inflating: data/train_imgs/P003863.png  \n",
            "  inflating: data/train_imgs/P003864.png  \n",
            "  inflating: data/train_imgs/P003865.png  \n",
            "  inflating: data/train_imgs/P003866.png  \n",
            "  inflating: data/train_imgs/P003867.png  \n",
            "  inflating: data/train_imgs/P003868.png  \n",
            "  inflating: data/train_imgs/P003869.png  \n",
            "  inflating: data/train_imgs/P003870.png  \n",
            "  inflating: data/train_imgs/P003871.png  \n",
            "  inflating: data/train_imgs/P003872.png  \n",
            "  inflating: data/train_imgs/P003873.png  \n",
            "  inflating: data/train_imgs/P003874.png  \n",
            "  inflating: data/train_imgs/P003875.png  \n",
            "  inflating: data/train_imgs/P003876.png  \n",
            "  inflating: data/train_imgs/P003877.png  \n",
            "  inflating: data/train_imgs/P003878.png  \n",
            "  inflating: data/train_imgs/P003879.png  \n",
            "  inflating: data/train_imgs/P003880.png  \n",
            "  inflating: data/train_imgs/P003881.png  \n",
            "  inflating: data/train_imgs/P003882.png  \n",
            "  inflating: data/train_imgs/P003883.png  \n",
            "  inflating: data/train_imgs/P003884.png  \n",
            "  inflating: data/train_imgs/P003885.png  \n",
            "  inflating: data/train_imgs/P003886.png  \n",
            "  inflating: data/train_imgs/P003887.png  \n",
            "  inflating: data/train_imgs/P003888.png  \n",
            "  inflating: data/train_imgs/P003889.png  \n",
            "  inflating: data/train_imgs/P003890.png  \n",
            "  inflating: data/train_imgs/P003891.png  \n",
            "  inflating: data/train_imgs/P003892.png  \n",
            "  inflating: data/train_imgs/P003893.png  \n",
            "  inflating: data/train_imgs/P003894.png  \n",
            "  inflating: data/train_imgs/P003895.png  \n",
            "  inflating: data/train_imgs/P003896.png  \n",
            "  inflating: data/train_imgs/P003897.png  \n",
            "  inflating: data/train_imgs/P003898.png  \n",
            "  inflating: data/train_imgs/P003899.png  \n",
            "  inflating: data/train_imgs/P003900.png  \n",
            "  inflating: data/train_imgs/P003901.png  \n",
            "  inflating: data/train_imgs/P003902.png  \n",
            "  inflating: data/train_imgs/P003903.png  \n",
            "  inflating: data/train_imgs/P003904.png  \n",
            "  inflating: data/train_imgs/P003905.png  \n",
            "  inflating: data/train_imgs/P003906.png  \n",
            "  inflating: data/train_imgs/P003907.png  \n",
            "  inflating: data/train_imgs/P003908.png  \n",
            "  inflating: data/train_imgs/P003909.png  \n",
            "  inflating: data/train_imgs/P003910.png  \n",
            "  inflating: data/train_imgs/P003911.png  \n",
            "  inflating: data/train_imgs/P003912.png  \n",
            "  inflating: data/train_imgs/P003913.png  \n",
            "  inflating: data/train_imgs/P003914.png  \n",
            "  inflating: data/train_imgs/P003915.png  \n",
            "  inflating: data/train_imgs/P003916.png  \n",
            "  inflating: data/train_imgs/P003917.png  \n",
            "  inflating: data/train_imgs/P003918.png  \n",
            "  inflating: data/train_imgs/P003919.png  \n",
            "  inflating: data/train_imgs/P003920.png  \n",
            "  inflating: data/train_imgs/P003921.png  \n",
            "  inflating: data/train_imgs/P003922.png  \n",
            "  inflating: data/train_imgs/P003923.png  \n",
            "  inflating: data/train_imgs/P003924.png  \n",
            "  inflating: data/train_imgs/P003925.png  \n",
            "  inflating: data/train_imgs/P003926.png  \n",
            "  inflating: data/train_imgs/P003927.png  \n",
            "  inflating: data/train_imgs/P003928.png  \n",
            "  inflating: data/train_imgs/P003929.png  \n",
            "  inflating: data/train_imgs/P003930.png  \n",
            "  inflating: data/train_imgs/P003931.png  \n",
            "  inflating: data/train_imgs/P003932.png  \n",
            "  inflating: data/train_imgs/P003933.png  \n",
            "  inflating: data/train_imgs/P003934.png  \n",
            "  inflating: data/train_imgs/P003935.png  \n",
            "  inflating: data/train_imgs/P003936.png  \n",
            "  inflating: data/train_imgs/P003937.png  \n",
            "  inflating: data/train_imgs/P003938.png  \n",
            "  inflating: data/train_imgs/P003939.png  \n",
            "  inflating: data/train_imgs/P003940.png  \n",
            "  inflating: data/train_imgs/P003941.png  \n",
            "  inflating: data/train_imgs/P003942.png  \n",
            "  inflating: data/train_imgs/P003943.png  \n",
            "  inflating: data/train_imgs/P003944.png  \n",
            "  inflating: data/train_imgs/P003945.png  \n",
            "  inflating: data/train_imgs/P003946.png  \n",
            "  inflating: data/train_imgs/P003947.png  \n",
            "  inflating: data/train_imgs/P003948.png  \n",
            "  inflating: data/train_imgs/P003949.png  \n",
            "  inflating: data/train_imgs/P003950.png  \n",
            "  inflating: data/train_imgs/P003951.png  \n",
            "  inflating: data/train_imgs/P003952.png  \n",
            "  inflating: data/train_imgs/P003953.png  \n",
            "  inflating: data/train_imgs/P003954.png  \n",
            "  inflating: data/train_imgs/P003955.png  \n",
            "  inflating: data/train_imgs/P003956.png  \n",
            "  inflating: data/train_imgs/P003957.png  \n",
            "  inflating: data/train_imgs/P003958.png  \n",
            "  inflating: data/train_imgs/P003959.png  \n",
            "  inflating: data/train_imgs/P003960.png  \n",
            "  inflating: data/train_imgs/P003961.png  \n",
            "  inflating: data/train_imgs/P003962.png  \n",
            "  inflating: data/train_imgs/P003963.png  \n",
            "  inflating: data/train_imgs/P003964.png  \n",
            "  inflating: data/train_imgs/P003965.png  \n",
            "  inflating: data/train_imgs/P003966.png  \n",
            "  inflating: data/train_imgs/P003967.png  \n",
            "  inflating: data/train_imgs/P003968.png  \n",
            "  inflating: data/train_imgs/P003969.png  \n",
            "  inflating: data/train_imgs/P003970.png  \n",
            "  inflating: data/train_imgs/P003971.png  \n",
            "  inflating: data/train_imgs/P003972.png  \n",
            "  inflating: data/train_imgs/P003973.png  \n",
            "  inflating: data/train_imgs/P003974.png  \n",
            "  inflating: data/train_imgs/P003975.png  \n",
            "  inflating: data/train_imgs/P003976.png  \n",
            "  inflating: data/train_imgs/P003977.png  \n",
            "  inflating: data/train_imgs/P003978.png  \n",
            "  inflating: data/train_imgs/P003979.png  \n",
            "  inflating: data/train_imgs/P003980.png  \n",
            "  inflating: data/train_imgs/P003981.png  \n",
            "  inflating: data/train_imgs/P003982.png  \n",
            "  inflating: data/train_imgs/P003983.png  \n",
            "  inflating: data/train_imgs/P003984.png  \n",
            "  inflating: data/train_imgs/P003985.png  \n",
            "  inflating: data/train_imgs/P003986.png  \n",
            "  inflating: data/train_imgs/P003987.png  \n",
            "  inflating: data/train_imgs/P003988.png  \n",
            "  inflating: data/train_imgs/P003989.png  \n",
            "  inflating: data/train_imgs/P003990.png  \n",
            "  inflating: data/train_imgs/P003991.png  \n",
            "  inflating: data/train_imgs/P003992.png  \n",
            "  inflating: data/train_imgs/P003993.png  \n",
            "  inflating: data/train_imgs/P003994.png  \n",
            "  inflating: data/train_imgs/P003995.png  \n",
            "  inflating: data/train_imgs/P003996.png  \n",
            "  inflating: data/train_imgs/P003997.png  \n",
            "  inflating: data/train_imgs/P003998.png  \n",
            "  inflating: data/train_imgs/P003999.png  \n",
            "  inflating: data/train_imgs/P004000.png  \n",
            "  inflating: data/train_imgs/P004001.png  \n",
            "  inflating: data/train_imgs/P004002.png  \n",
            "  inflating: data/train_imgs/P004003.png  \n",
            "  inflating: data/train_imgs/P004004.png  \n",
            "  inflating: data/train_imgs/P004005.png  \n",
            "  inflating: data/train_imgs/P004006.png  \n",
            "  inflating: data/train_imgs/P004007.png  \n",
            "  inflating: data/train_imgs/P004008.png  \n",
            "  inflating: data/train_imgs/P004009.png  \n",
            "  inflating: data/train_imgs/P004010.png  \n",
            "  inflating: data/train_imgs/P004011.png  \n",
            "  inflating: data/train_imgs/P004012.png  \n",
            "  inflating: data/train_imgs/P004013.png  \n",
            "  inflating: data/train_imgs/P004014.png  \n",
            "  inflating: data/train_imgs/P004015.png  \n",
            "  inflating: data/train_imgs/P004016.png  \n",
            "  inflating: data/train_imgs/P004017.png  \n",
            "  inflating: data/train_imgs/P004018.png  \n",
            "  inflating: data/train_imgs/P004019.png  \n",
            "  inflating: data/train_imgs/P004020.png  \n",
            "  inflating: data/train_imgs/P004021.png  \n",
            "  inflating: data/train_imgs/P004022.png  \n",
            "  inflating: data/train_imgs/P004023.png  \n",
            "  inflating: data/train_imgs/P004024.png  \n",
            "  inflating: data/train_imgs/P004025.png  \n",
            "  inflating: data/train_imgs/P004026.png  \n",
            "  inflating: data/train_imgs/P004027.png  \n",
            "  inflating: data/train_imgs/P004028.png  \n",
            "  inflating: data/train_imgs/P004029.png  \n",
            "  inflating: data/train_imgs/P004030.png  \n",
            "  inflating: data/train_imgs/P004031.png  \n",
            "  inflating: data/train_imgs/P004032.png  \n",
            "  inflating: data/train_imgs/P004033.png  \n",
            "  inflating: data/train_imgs/P004034.png  \n",
            "  inflating: data/train_imgs/P004035.png  \n",
            "  inflating: data/train_imgs/P004036.png  \n",
            "  inflating: data/train_imgs/P004037.png  \n",
            "  inflating: data/train_imgs/P004038.png  \n",
            "  inflating: data/train_imgs/P004039.png  \n",
            "  inflating: data/train_imgs/P004040.png  \n",
            "  inflating: data/train_imgs/P004041.png  \n",
            "  inflating: data/train_imgs/P004042.png  \n",
            "  inflating: data/train_imgs/P004043.png  \n",
            "  inflating: data/train_imgs/P004044.png  \n",
            "  inflating: data/train_imgs/P004045.png  \n",
            "  inflating: data/train_imgs/P004046.png  \n",
            "  inflating: data/train_imgs/P004047.png  \n",
            "  inflating: data/train_imgs/P004048.png  \n",
            "  inflating: data/train_imgs/P004049.png  \n",
            "  inflating: data/train_imgs/P004050.png  \n",
            "  inflating: data/train_imgs/P004051.png  \n",
            "  inflating: data/train_imgs/P004052.png  \n",
            "  inflating: data/train_imgs/P004053.png  \n",
            "  inflating: data/train_imgs/P004054.png  \n",
            "  inflating: data/train_imgs/P004055.png  \n",
            "  inflating: data/train_imgs/P004056.png  \n",
            "  inflating: data/train_imgs/P004057.png  \n",
            "  inflating: data/train_imgs/P004058.png  \n",
            "  inflating: data/train_imgs/P004059.png  \n",
            "  inflating: data/train_imgs/P004060.png  \n",
            "  inflating: data/train_imgs/P004061.png  \n",
            "  inflating: data/train_imgs/P004062.png  \n",
            "  inflating: data/train_imgs/P004063.png  \n",
            "  inflating: data/train_imgs/P004064.png  \n",
            "  inflating: data/train_imgs/P004065.png  \n",
            "  inflating: data/train_imgs/P004066.png  \n",
            "  inflating: data/train_imgs/P004067.png  \n",
            "  inflating: data/train_imgs/P004068.png  \n",
            "  inflating: data/train_imgs/P004069.png  \n",
            "  inflating: data/train_imgs/P004070.png  \n",
            "  inflating: data/train_imgs/P004071.png  \n",
            "  inflating: data/train_imgs/P004072.png  \n",
            "  inflating: data/train_imgs/P004073.png  \n",
            "  inflating: data/train_imgs/P004074.png  \n",
            "  inflating: data/train_imgs/P004075.png  \n",
            "  inflating: data/train_imgs/P004076.png  \n",
            "  inflating: data/train_imgs/P004077.png  \n",
            "  inflating: data/train_imgs/P004078.png  \n",
            "  inflating: data/train_imgs/P004079.png  \n",
            "  inflating: data/train_imgs/P004080.png  \n",
            "  inflating: data/train_imgs/P004081.png  \n",
            "  inflating: data/train_imgs/P004082.png  \n",
            "  inflating: data/train_imgs/P004083.png  \n",
            "  inflating: data/train_imgs/P004084.png  \n",
            "  inflating: data/train_imgs/P004085.png  \n",
            "  inflating: data/train_imgs/P004086.png  \n",
            "  inflating: data/train_imgs/P004087.png  \n",
            "  inflating: data/train_imgs/P004088.png  \n",
            "  inflating: data/train_imgs/P004089.png  \n",
            "  inflating: data/train_imgs/P004090.png  \n",
            "  inflating: data/train_imgs/P004091.png  \n",
            "  inflating: data/train_imgs/P004092.png  \n",
            "  inflating: data/train_imgs/P004093.png  \n",
            "  inflating: data/train_imgs/P004094.png  \n",
            "  inflating: data/train_imgs/P004095.png  \n",
            "  inflating: data/train_imgs/P004096.png  \n",
            "  inflating: data/train_imgs/P004097.png  \n",
            "  inflating: data/train_imgs/P004098.png  \n",
            "  inflating: data/train_imgs/P004099.png  \n",
            "  inflating: data/train_imgs/P004100.png  \n",
            "  inflating: data/train_imgs/P004101.png  \n",
            "  inflating: data/train_imgs/P004102.png  \n",
            "  inflating: data/train_imgs/P004103.png  \n",
            "  inflating: data/train_imgs/P004104.png  \n",
            "  inflating: data/train_imgs/P004105.png  \n",
            "  inflating: data/train_imgs/P004106.png  \n",
            "  inflating: data/train_imgs/P004107.png  \n",
            "  inflating: data/train_imgs/P004108.png  \n",
            "  inflating: data/train_imgs/P004109.png  \n",
            "  inflating: data/train_imgs/P004110.png  \n",
            "  inflating: data/train_imgs/P004111.png  \n",
            "  inflating: data/train_imgs/P004112.png  \n",
            "  inflating: data/train_imgs/P004113.png  \n",
            "  inflating: data/train_imgs/P004114.png  \n",
            "  inflating: data/train_imgs/P004115.png  \n",
            "  inflating: data/train_imgs/P004116.png  \n",
            "  inflating: data/train_imgs/P004117.png  \n",
            "  inflating: data/train_imgs/P004118.png  \n",
            "  inflating: data/train_imgs/P004119.png  \n",
            "  inflating: data/train_imgs/P004120.png  \n",
            "  inflating: data/train_imgs/P004121.png  \n",
            "  inflating: data/train_imgs/P004122.png  \n",
            "  inflating: data/train_imgs/P004123.png  \n",
            "  inflating: data/train_imgs/P004124.png  \n",
            "  inflating: data/train_imgs/P004125.png  \n",
            "  inflating: data/train_imgs/P004126.png  \n",
            "  inflating: data/train_imgs/P004127.png  \n",
            "  inflating: data/train_imgs/P004128.png  \n",
            "  inflating: data/train_imgs/P004129.png  \n",
            "  inflating: data/train_imgs/P004130.png  \n",
            "  inflating: data/train_imgs/P004131.png  \n",
            "  inflating: data/train_imgs/P004132.png  \n",
            "  inflating: data/train_imgs/P004133.png  \n",
            "  inflating: data/train_imgs/P004134.png  \n",
            "  inflating: data/train_imgs/P004135.png  \n",
            "  inflating: data/train_imgs/P004136.png  \n",
            "  inflating: data/train_imgs/P004137.png  \n",
            "  inflating: data/train_imgs/P004138.png  \n",
            "  inflating: data/train_imgs/P004139.png  \n",
            "  inflating: data/train_imgs/P004140.png  \n",
            "  inflating: data/train_imgs/P004141.png  \n",
            "  inflating: data/train_imgs/P004142.png  \n",
            "  inflating: data/train_imgs/P004143.png  \n",
            "  inflating: data/train_imgs/P004144.png  \n",
            "  inflating: data/train_imgs/P004145.png  \n",
            "  inflating: data/train_imgs/P004146.png  \n",
            "  inflating: data/train_imgs/P004147.png  \n",
            "  inflating: data/train_imgs/P004148.png  \n",
            "  inflating: data/train_imgs/P004149.png  \n",
            "  inflating: data/train_imgs/P004150.png  \n",
            "  inflating: data/train_imgs/P004151.png  \n",
            "  inflating: data/train_imgs/P004152.png  \n",
            "  inflating: data/train_imgs/P004153.png  \n",
            "  inflating: data/train_imgs/P004154.png  \n",
            "  inflating: data/train_imgs/P004155.png  \n",
            "  inflating: data/train_imgs/P004156.png  \n",
            "  inflating: data/train_imgs/P004157.png  \n",
            "  inflating: data/train_imgs/P004158.png  \n",
            "  inflating: data/train_imgs/P004159.png  \n",
            "  inflating: data/train_imgs/P004160.png  \n",
            "  inflating: data/train_imgs/P004161.png  \n",
            "  inflating: data/train_imgs/P004162.png  \n",
            "  inflating: data/train_imgs/P004163.png  \n",
            "  inflating: data/train_imgs/P004164.png  \n",
            "  inflating: data/train_imgs/P004165.png  \n",
            "  inflating: data/train_imgs/P004166.png  \n",
            "  inflating: data/train_imgs/P004167.png  \n",
            "  inflating: data/train_imgs/P004168.png  \n",
            "  inflating: data/train_imgs/P004169.png  \n",
            "  inflating: data/train_imgs/P004170.png  \n",
            "  inflating: data/train_imgs/P004171.png  \n",
            "  inflating: data/train_imgs/P004172.png  \n",
            "  inflating: data/train_imgs/P004173.png  \n",
            "  inflating: data/train_imgs/P004174.png  \n",
            "  inflating: data/train_imgs/P004175.png  \n",
            "  inflating: data/train_imgs/P004176.png  \n",
            "  inflating: data/train_imgs/P004177.png  \n",
            "  inflating: data/train_imgs/P004178.png  \n",
            "  inflating: data/train_imgs/P004179.png  \n",
            "  inflating: data/train_imgs/P004180.png  \n",
            "  inflating: data/train_imgs/P004181.png  \n",
            "  inflating: data/train_imgs/P004182.png  \n",
            "  inflating: data/train_imgs/P004183.png  \n",
            "  inflating: data/train_imgs/P004184.png  \n",
            "  inflating: data/train_imgs/P004185.png  \n",
            "  inflating: data/train_imgs/P004186.png  \n",
            "  inflating: data/train_imgs/P004187.png  \n",
            "  inflating: data/train_imgs/P004188.png  \n",
            "  inflating: data/train_imgs/P004189.png  \n",
            "  inflating: data/train_imgs/P004190.png  \n",
            "  inflating: data/train_imgs/P004191.png  \n",
            "  inflating: data/train_imgs/P004192.png  \n",
            "  inflating: data/train_imgs/P004193.png  \n",
            "  inflating: data/train_imgs/P004194.png  \n",
            "  inflating: data/train_imgs/P004195.png  \n",
            "  inflating: data/train_imgs/P004196.png  \n",
            "  inflating: data/train_imgs/P004197.png  \n",
            "  inflating: data/train_imgs/P004198.png  \n",
            "  inflating: data/train_imgs/P004199.png  \n",
            "  inflating: data/train_imgs/P004200.png  \n",
            "  inflating: data/train_imgs/P004201.png  \n",
            "  inflating: data/train_imgs/P004202.png  \n",
            "  inflating: data/train_imgs/P004203.png  \n",
            "  inflating: data/train_imgs/P004204.png  \n",
            "  inflating: data/train_imgs/P004205.png  \n",
            "  inflating: data/train_imgs/P004206.png  \n",
            "  inflating: data/train_imgs/P004207.png  \n",
            "  inflating: data/train_imgs/P004208.png  \n",
            "  inflating: data/train_imgs/P004209.png  \n",
            "  inflating: data/train_imgs/P004210.png  \n",
            "  inflating: data/train_imgs/P004211.png  \n",
            "  inflating: data/train_imgs/P004212.png  \n",
            "  inflating: data/train_imgs/P004213.png  \n",
            "  inflating: data/train_imgs/P004214.png  \n",
            "  inflating: data/train_imgs/P004215.png  \n",
            "  inflating: data/train_imgs/P004216.png  \n",
            "  inflating: data/train_imgs/P004217.png  \n",
            "  inflating: data/train_imgs/P004218.png  \n",
            "  inflating: data/train_imgs/P004219.png  \n",
            "  inflating: data/train_imgs/P004220.png  \n",
            "  inflating: data/train_imgs/P004221.png  \n",
            "  inflating: data/train_imgs/P004222.png  \n",
            "  inflating: data/train_imgs/P004223.png  \n",
            "  inflating: data/train_imgs/P004224.png  \n",
            "  inflating: data/train_imgs/P004225.png  \n",
            "  inflating: data/train_imgs/P004226.png  \n",
            "  inflating: data/train_imgs/P004227.png  \n",
            "  inflating: data/train_imgs/P004228.png  \n",
            "  inflating: data/train_imgs/P004229.png  \n",
            "  inflating: data/train_imgs/P004230.png  \n",
            "  inflating: data/train_imgs/P004231.png  \n",
            "  inflating: data/train_imgs/P004232.png  \n",
            "  inflating: data/train_imgs/P004233.png  \n",
            "  inflating: data/train_imgs/P004234.png  \n",
            "  inflating: data/train_imgs/P004235.png  \n",
            "  inflating: data/train_imgs/P004236.png  \n",
            "  inflating: data/train_imgs/P004237.png  \n",
            "  inflating: data/train_imgs/P004238.png  \n",
            "  inflating: data/train_imgs/P004239.png  \n",
            "  inflating: data/train_imgs/P004240.png  \n",
            "  inflating: data/train_imgs/P004241.png  \n",
            "  inflating: data/train_imgs/P004242.png  \n",
            "  inflating: data/train_imgs/P004243.png  \n",
            "  inflating: data/train_imgs/P004244.png  \n",
            "  inflating: data/train_imgs/P004245.png  \n",
            "  inflating: data/train_imgs/P004246.png  \n",
            "  inflating: data/train_imgs/P004247.png  \n",
            "  inflating: data/train_imgs/P004248.png  \n",
            "  inflating: data/train_imgs/P004249.png  \n",
            "  inflating: data/train_imgs/P004250.png  \n",
            "  inflating: data/train_imgs/P004251.png  \n",
            "  inflating: data/train_imgs/P004252.png  \n",
            "  inflating: data/train_imgs/P004253.png  \n",
            "  inflating: data/train_imgs/P004254.png  \n",
            "  inflating: data/train_imgs/P004255.png  \n",
            "  inflating: data/train_imgs/P004256.png  \n",
            "  inflating: data/train_imgs/P004257.png  \n",
            "  inflating: data/train_imgs/P004258.png  \n",
            "  inflating: data/train_imgs/P004259.png  \n",
            "  inflating: data/train_imgs/P004260.png  \n",
            "  inflating: data/train_imgs/P004261.png  \n",
            "  inflating: data/train_imgs/P004262.png  \n",
            "  inflating: data/train_imgs/P004263.png  \n",
            "  inflating: data/train_imgs/P004264.png  \n",
            "  inflating: data/train_imgs/P004265.png  \n",
            "  inflating: data/train_imgs/P004266.png  \n",
            "  inflating: data/train_imgs/P004267.png  \n",
            "  inflating: data/train_imgs/P004268.png  \n",
            "  inflating: data/train_imgs/P004269.png  \n",
            "  inflating: data/train_imgs/P004270.png  \n",
            "  inflating: data/train_imgs/P004271.png  \n",
            "  inflating: data/train_imgs/P004272.png  \n",
            "  inflating: data/train_imgs/P004273.png  \n",
            "  inflating: data/train_imgs/P004274.png  \n",
            "  inflating: data/train_imgs/P004275.png  \n",
            "  inflating: data/train_imgs/P004276.png  \n",
            "  inflating: data/train_imgs/P004277.png  \n",
            "  inflating: data/train_imgs/P004278.png  \n",
            "  inflating: data/train_imgs/P004279.png  \n",
            "  inflating: data/train_imgs/P004280.png  \n",
            "  inflating: data/train_imgs/P004281.png  \n",
            "  inflating: data/train_imgs/P004282.png  \n",
            "  inflating: data/train_imgs/P004283.png  \n",
            "  inflating: data/train_imgs/P004284.png  \n",
            "  inflating: data/train_imgs/P004285.png  \n",
            "  inflating: data/train_imgs/P004286.png  \n",
            "  inflating: data/train_imgs/P004287.png  \n",
            "  inflating: data/train_imgs/P004288.png  \n",
            "  inflating: data/train_imgs/P004289.png  \n",
            "  inflating: data/train_imgs/P004290.png  \n",
            "  inflating: data/train_imgs/P004291.png  \n",
            "  inflating: data/train_imgs/P004292.png  \n",
            "  inflating: data/train_imgs/P004293.png  \n",
            "  inflating: data/train_imgs/P004294.png  \n",
            "  inflating: data/train_imgs/P004295.png  \n",
            "  inflating: data/train_imgs/P004296.png  \n",
            "  inflating: data/train_imgs/P004297.png  \n",
            "  inflating: data/train_imgs/P004298.png  \n",
            "  inflating: data/train_imgs/P004299.png  \n",
            "  inflating: data/train_imgs/P004300.png  \n",
            "  inflating: data/train_imgs/P004301.png  \n",
            "  inflating: data/train_imgs/P004302.png  \n",
            "  inflating: data/train_imgs/P004303.png  \n",
            "  inflating: data/train_imgs/P004304.png  \n",
            "  inflating: data/train_imgs/P004305.png  \n",
            "  inflating: data/train_imgs/P004306.png  \n",
            "  inflating: data/train_imgs/P004307.png  \n",
            "  inflating: data/train_imgs/P004308.png  \n",
            "  inflating: data/train_imgs/P004309.png  \n",
            "  inflating: data/train_imgs/P004310.png  \n",
            "  inflating: data/train_imgs/P004311.png  \n",
            "  inflating: data/train_imgs/P004312.png  \n",
            "  inflating: data/train_imgs/P004313.png  \n",
            "  inflating: data/train_imgs/P004314.png  \n",
            "  inflating: data/train_imgs/P004315.png  \n",
            "  inflating: data/train_imgs/P004316.png  \n",
            "  inflating: data/train_imgs/P004317.png  \n",
            "  inflating: data/train_imgs/P004318.png  \n",
            "  inflating: data/train_imgs/P004319.png  \n",
            "  inflating: data/train_imgs/P004320.png  \n",
            "  inflating: data/train_imgs/P004321.png  \n",
            "  inflating: data/train_imgs/P004322.png  \n",
            "  inflating: data/train_imgs/P004323.png  \n",
            "  inflating: data/train_imgs/P004324.png  \n",
            "  inflating: data/train_imgs/P004325.png  \n",
            "  inflating: data/train_imgs/P004326.png  \n",
            "  inflating: data/train_imgs/P004327.png  \n",
            "  inflating: data/train_imgs/P004328.png  \n",
            "  inflating: data/train_imgs/P004329.png  \n",
            "  inflating: data/train_imgs/P004330.png  \n",
            "  inflating: data/train_imgs/P004331.png  \n",
            "  inflating: data/train_imgs/P004332.png  \n",
            "  inflating: data/train_imgs/P004333.png  \n",
            "  inflating: data/train_imgs/P004334.png  \n",
            "  inflating: data/train_imgs/P004335.png  \n",
            "  inflating: data/train_imgs/P004336.png  \n",
            "  inflating: data/train_imgs/P004337.png  \n",
            "  inflating: data/train_imgs/P004338.png  \n",
            "  inflating: data/train_imgs/P004339.png  \n",
            "  inflating: data/train_imgs/P004340.png  \n",
            "  inflating: data/train_imgs/P004341.png  \n",
            "  inflating: data/train_imgs/P004342.png  \n",
            "  inflating: data/train_imgs/P004343.png  \n",
            "  inflating: data/train_imgs/P004344.png  \n",
            "  inflating: data/train_imgs/P004345.png  \n",
            "  inflating: data/train_imgs/P004346.png  \n",
            "  inflating: data/train_imgs/P004347.png  \n",
            "  inflating: data/train_imgs/P004348.png  \n",
            "  inflating: data/train_imgs/P004349.png  \n",
            "  inflating: data/train_imgs/P004350.png  \n",
            "  inflating: data/train_imgs/P004351.png  \n",
            "  inflating: data/train_imgs/P004352.png  \n",
            "  inflating: data/train_imgs/P004353.png  \n",
            "  inflating: data/train_imgs/P004354.png  \n",
            "  inflating: data/train_imgs/P004355.png  \n",
            "  inflating: data/train_imgs/P004356.png  \n",
            "  inflating: data/train_imgs/P004357.png  \n",
            "  inflating: data/train_imgs/P004358.png  \n",
            "  inflating: data/train_imgs/P004359.png  \n",
            "  inflating: data/train_imgs/P004360.png  \n",
            "  inflating: data/train_imgs/P004361.png  \n",
            "  inflating: data/train_imgs/P004362.png  \n",
            "  inflating: data/train_imgs/P004363.png  \n",
            "  inflating: data/train_imgs/P004364.png  \n",
            "  inflating: data/train_imgs/P004365.png  \n",
            "  inflating: data/train_imgs/P004366.png  \n",
            "  inflating: data/train_imgs/P004367.png  \n",
            "  inflating: data/train_imgs/P004368.png  \n",
            "  inflating: data/train_imgs/P004369.png  \n",
            "  inflating: data/train_imgs/P004370.png  \n",
            "  inflating: data/train_imgs/P004371.png  \n",
            "  inflating: data/train_imgs/P004372.png  \n",
            "  inflating: data/train_imgs/P004373.png  \n",
            "  inflating: data/train_imgs/P004374.png  \n",
            "  inflating: data/train_imgs/P004375.png  \n",
            "  inflating: data/train_imgs/P004376.png  \n",
            "  inflating: data/train_imgs/P004377.png  \n",
            "  inflating: data/train_imgs/P004378.png  \n",
            "  inflating: data/train_imgs/P004379.png  \n",
            "  inflating: data/train_imgs/P004380.png  \n",
            "  inflating: data/train_imgs/P004381.png  \n",
            "  inflating: data/train_imgs/P004382.png  \n",
            "  inflating: data/train_imgs/P004383.png  \n",
            "  inflating: data/train_imgs/P004384.png  \n",
            "  inflating: data/train_imgs/P004385.png  \n",
            "  inflating: data/train_imgs/P004386.png  \n",
            "  inflating: data/train_imgs/P004387.png  \n",
            "  inflating: data/train_imgs/P004388.png  \n",
            "  inflating: data/train_imgs/P004389.png  \n",
            "  inflating: data/train_imgs/P004390.png  \n",
            "  inflating: data/train_imgs/P004391.png  \n",
            "  inflating: data/train_imgs/P004392.png  \n",
            "  inflating: data/train_imgs/P004393.png  \n",
            "  inflating: data/train_imgs/P004394.png  \n",
            "  inflating: data/train_imgs/P004395.png  \n",
            "  inflating: data/train_imgs/P004396.png  \n",
            "  inflating: data/train_imgs/P004397.png  \n",
            "  inflating: data/train_imgs/P004398.png  \n",
            "  inflating: data/train_imgs/P004399.png  \n",
            "  inflating: data/train_imgs/P004400.png  \n",
            "  inflating: data/train_imgs/P004401.png  \n",
            "  inflating: data/train_imgs/P004402.png  \n",
            "  inflating: data/train_imgs/P004403.png  \n",
            "  inflating: data/train_imgs/P004404.png  \n",
            "  inflating: data/train_imgs/P004405.png  \n",
            "  inflating: data/train_imgs/P004406.png  \n",
            "  inflating: data/train_imgs/P004407.png  \n",
            "  inflating: data/train_imgs/P004408.png  \n",
            "  inflating: data/train_imgs/P004409.png  \n",
            "  inflating: data/train_imgs/P004410.png  \n",
            "  inflating: data/train_imgs/P004411.png  \n",
            "  inflating: data/train_imgs/P004412.png  \n",
            "  inflating: data/train_imgs/P004413.png  \n",
            "  inflating: data/train_imgs/P004414.png  \n",
            "  inflating: data/train_imgs/P004415.png  \n",
            "  inflating: data/train_imgs/P004416.png  \n",
            "  inflating: data/train_imgs/P004417.png  \n",
            "  inflating: data/train_imgs/P004418.png  \n",
            "  inflating: data/train_imgs/P004419.png  \n",
            "  inflating: data/train_imgs/P004420.png  \n",
            "  inflating: data/train_imgs/P004421.png  \n",
            "  inflating: data/train_imgs/P004422.png  \n",
            "  inflating: data/train_imgs/P004423.png  \n",
            "  inflating: data/train_imgs/P004424.png  \n",
            "  inflating: data/train_imgs/P004425.png  \n",
            "  inflating: data/train_imgs/P004426.png  \n",
            "  inflating: data/train_imgs/P004427.png  \n",
            "  inflating: data/train_imgs/P004428.png  \n",
            "  inflating: data/train_imgs/P004429.png  \n",
            "  inflating: data/train_imgs/P004430.png  \n",
            "  inflating: data/train_imgs/P004431.png  \n",
            "  inflating: data/train_imgs/P004432.png  \n",
            "  inflating: data/train_imgs/P004433.png  \n",
            "  inflating: data/train_imgs/P004434.png  \n",
            "  inflating: data/train_imgs/P004435.png  \n",
            "  inflating: data/train_imgs/P004436.png  \n",
            "  inflating: data/train_imgs/P004437.png  \n",
            "  inflating: data/train_imgs/P004438.png  \n",
            "  inflating: data/train_imgs/P004439.png  \n",
            "  inflating: data/train_imgs/P004440.png  \n",
            "  inflating: data/train_imgs/P004441.png  \n",
            "  inflating: data/train_imgs/P004442.png  \n",
            "  inflating: data/train_imgs/P004443.png  \n",
            "  inflating: data/train_imgs/P004444.png  \n",
            "  inflating: data/train_imgs/P004445.png  \n",
            "  inflating: data/train_imgs/P004446.png  \n",
            "  inflating: data/train_imgs/P004447.png  \n",
            "  inflating: data/train_imgs/P004448.png  \n",
            "  inflating: data/train_imgs/P004449.png  \n",
            "  inflating: data/train_imgs/P004450.png  \n",
            "  inflating: data/train_imgs/P004451.png  \n",
            "  inflating: data/train_imgs/P004452.png  \n",
            "  inflating: data/train_imgs/P004453.png  \n",
            "  inflating: data/train_imgs/P004454.png  \n",
            "  inflating: data/train_imgs/P004455.png  \n",
            "  inflating: data/train_imgs/P004456.png  \n",
            "  inflating: data/train_imgs/P004457.png  \n",
            "  inflating: data/train_imgs/P004458.png  \n",
            "  inflating: data/train_imgs/P004459.png  \n",
            "  inflating: data/train_imgs/P004460.png  \n",
            "  inflating: data/train_imgs/P004461.png  \n",
            "  inflating: data/train_imgs/P004462.png  \n",
            "  inflating: data/train_imgs/P004463.png  \n",
            "  inflating: data/train_imgs/P004464.png  \n",
            "  inflating: data/train_imgs/P004465.png  \n",
            "  inflating: data/train_imgs/P004466.png  \n",
            "  inflating: data/train_imgs/P004467.png  \n",
            "  inflating: data/train_imgs/P004468.png  \n",
            "  inflating: data/train_imgs/P004469.png  \n",
            "  inflating: data/train_imgs/P004470.png  \n",
            "  inflating: data/train_imgs/P004471.png  \n",
            "  inflating: data/train_imgs/P004472.png  \n",
            "  inflating: data/train_imgs/P004473.png  \n",
            "  inflating: data/train_imgs/P004474.png  \n",
            "  inflating: data/train_imgs/P004475.png  \n",
            "  inflating: data/train_imgs/P004476.png  \n",
            "  inflating: data/train_imgs/P004477.png  \n",
            "  inflating: data/train_imgs/P004478.png  \n",
            "  inflating: data/train_imgs/P004479.png  \n",
            "  inflating: data/train_imgs/P004480.png  \n",
            "  inflating: data/train_imgs/P004481.png  \n",
            "  inflating: data/train_imgs/P004482.png  \n",
            "  inflating: data/train_imgs/P004483.png  \n",
            "  inflating: data/train_imgs/P004484.png  \n",
            "  inflating: data/train_imgs/P004485.png  \n",
            "  inflating: data/train_imgs/P004486.png  \n",
            "  inflating: data/train_imgs/P004487.png  \n",
            "  inflating: data/train_imgs/P004488.png  \n",
            "  inflating: data/train_imgs/P004489.png  \n",
            "  inflating: data/train_imgs/P004490.png  \n",
            "  inflating: data/train_imgs/P004491.png  \n",
            "  inflating: data/train_imgs/P004492.png  \n",
            "  inflating: data/train_imgs/P004493.png  \n",
            "  inflating: data/train_imgs/P004494.png  \n",
            "  inflating: data/train_imgs/P004495.png  \n",
            "  inflating: data/train_imgs/P004496.png  \n",
            "  inflating: data/train_imgs/P004497.png  \n",
            "  inflating: data/train_imgs/P004498.png  \n",
            "  inflating: data/train_imgs/P004499.png  \n",
            "  inflating: data/train_imgs/P004500.png  \n",
            "  inflating: data/train_imgs/P004501.png  \n",
            "  inflating: data/train_imgs/P004502.png  \n",
            "  inflating: data/train_imgs/P004503.png  \n",
            "  inflating: data/train_imgs/P004504.png  \n",
            "  inflating: data/train_imgs/P004505.png  \n",
            "  inflating: data/train_imgs/P004506.png  \n",
            "  inflating: data/train_imgs/P004507.png  \n",
            "  inflating: data/train_imgs/P004508.png  \n",
            "  inflating: data/train_imgs/P004509.png  \n",
            "  inflating: data/train_imgs/P004510.png  \n",
            "  inflating: data/train_imgs/P004511.png  \n",
            "  inflating: data/train_imgs/P004512.png  \n",
            "  inflating: data/train_imgs/P004513.png  \n",
            "  inflating: data/train_imgs/P004514.png  \n",
            "  inflating: data/train_imgs/P004515.png  \n",
            "  inflating: data/train_imgs/P004516.png  \n",
            "  inflating: data/train_imgs/P004517.png  \n",
            "  inflating: data/train_imgs/P004518.png  \n",
            "  inflating: data/train_imgs/P004519.png  \n",
            "  inflating: data/train_imgs/P004520.png  \n",
            "  inflating: data/train_imgs/P004521.png  \n",
            "  inflating: data/train_imgs/P004522.png  \n",
            "  inflating: data/train_imgs/P004523.png  \n",
            "  inflating: data/train_imgs/P004524.png  \n",
            "  inflating: data/train_imgs/P004525.png  \n",
            "  inflating: data/train_imgs/P004526.png  \n",
            "  inflating: data/train_imgs/P004527.png  \n",
            "  inflating: data/train_imgs/P004528.png  \n",
            "  inflating: data/train_imgs/P004529.png  \n",
            "  inflating: data/train_imgs/P004530.png  \n",
            "  inflating: data/train_imgs/P004531.png  \n",
            "  inflating: data/train_imgs/P004532.png  \n",
            "  inflating: data/train_imgs/P004533.png  \n",
            "  inflating: data/train_imgs/P004534.png  \n",
            "  inflating: data/train_imgs/P004535.png  \n",
            "  inflating: data/train_imgs/P004536.png  \n",
            "  inflating: data/train_imgs/P004537.png  \n",
            "  inflating: data/train_imgs/P004538.png  \n",
            "  inflating: data/train_imgs/P004539.png  \n",
            "  inflating: data/train_imgs/P004540.png  \n",
            "  inflating: data/train_imgs/P004541.png  \n",
            "  inflating: data/train_imgs/P004542.png  \n",
            "  inflating: data/train_imgs/P004543.png  \n",
            "  inflating: data/train_imgs/P004544.png  \n",
            "  inflating: data/train_imgs/P004545.png  \n",
            "  inflating: data/train_imgs/P004546.png  \n",
            "  inflating: data/train_imgs/P004547.png  \n",
            "  inflating: data/train_imgs/P004548.png  \n",
            "  inflating: data/train_imgs/P004549.png  \n",
            "  inflating: data/train_imgs/P004550.png  \n",
            "  inflating: data/train_imgs/P004551.png  \n",
            "  inflating: data/train_imgs/P004552.png  \n",
            "  inflating: data/train_imgs/P004553.png  \n",
            "  inflating: data/train_imgs/P004554.png  \n",
            "  inflating: data/train_imgs/P004555.png  \n",
            "  inflating: data/train_imgs/P004556.png  \n",
            "  inflating: data/train_imgs/P004557.png  \n",
            "  inflating: data/train_imgs/P004558.png  \n",
            "  inflating: data/train_imgs/P004559.png  \n",
            "  inflating: data/train_imgs/P004560.png  \n",
            "  inflating: data/train_imgs/P004561.png  \n",
            "  inflating: data/train_imgs/P004562.png  \n",
            "  inflating: data/train_imgs/P004563.png  \n",
            "  inflating: data/train_imgs/P004564.png  \n",
            "  inflating: data/train_imgs/P004565.png  \n",
            "  inflating: data/train_imgs/P004566.png  \n",
            "  inflating: data/train_imgs/P004567.png  \n",
            "  inflating: data/train_imgs/P004568.png  \n",
            "  inflating: data/train_imgs/P004569.png  \n",
            "  inflating: data/train_imgs/P004570.png  \n",
            "  inflating: data/train_imgs/P004571.png  \n",
            "  inflating: data/train_imgs/P004572.png  \n",
            "  inflating: data/train_imgs/P004573.png  \n",
            "  inflating: data/train_imgs/P004574.png  \n",
            "  inflating: data/train_imgs/P004575.png  \n",
            "  inflating: data/train_imgs/P004576.png  \n",
            "  inflating: data/train_imgs/P004577.png  \n",
            "  inflating: data/train_imgs/P004578.png  \n",
            "  inflating: data/train_imgs/P004579.png  \n",
            "  inflating: data/train_imgs/P004580.png  \n",
            "  inflating: data/train_imgs/P004581.png  \n",
            "  inflating: data/train_imgs/P004582.png  \n",
            "  inflating: data/train_imgs/P004583.png  \n",
            "  inflating: data/train_imgs/P004584.png  \n",
            "  inflating: data/train_imgs/P004585.png  \n",
            "  inflating: data/train_imgs/P004586.png  \n",
            "  inflating: data/train_imgs/P004587.png  \n",
            "  inflating: data/train_imgs/P004588.png  \n",
            "  inflating: data/train_imgs/P004589.png  \n",
            "  inflating: data/train_imgs/P004590.png  \n",
            "  inflating: data/train_imgs/P004591.png  \n",
            "  inflating: data/train_imgs/P004592.png  \n",
            "  inflating: data/train_imgs/P004593.png  \n",
            "  inflating: data/train_imgs/P004594.png  \n",
            "  inflating: data/train_imgs/P004595.png  \n",
            "  inflating: data/train_imgs/P004596.png  \n",
            "  inflating: data/train_imgs/P004597.png  \n",
            "  inflating: data/train_imgs/P004598.png  \n",
            "  inflating: data/train_imgs/P004599.png  \n",
            "  inflating: data/train_imgs/P004600.png  \n",
            "  inflating: data/train_imgs/P004601.png  \n",
            "  inflating: data/train_imgs/P004602.png  \n",
            "  inflating: data/train_imgs/P004603.png  \n",
            "  inflating: data/train_imgs/P004604.png  \n",
            "  inflating: data/train_imgs/P004605.png  \n",
            "  inflating: data/train_imgs/P004606.png  \n",
            "  inflating: data/train_imgs/P004607.png  \n",
            "  inflating: data/train_imgs/P004608.png  \n",
            "  inflating: data/train_imgs/P004609.png  \n",
            "  inflating: data/train_imgs/P004610.png  \n",
            "  inflating: data/train_imgs/P004611.png  \n",
            "  inflating: data/train_imgs/P004612.png  \n",
            "  inflating: data/train_imgs/P004613.png  \n",
            "  inflating: data/train_imgs/P004614.png  \n",
            "  inflating: data/train_imgs/P004615.png  \n",
            "  inflating: data/train_imgs/P004616.png  \n",
            "  inflating: data/train_imgs/P004617.png  \n",
            "  inflating: data/train_imgs/P004618.png  \n",
            "  inflating: data/train_imgs/P004619.png  \n",
            "  inflating: data/train_imgs/P004620.png  \n",
            "  inflating: data/train_imgs/P004621.png  \n",
            "  inflating: data/train_imgs/P004622.png  \n",
            "  inflating: data/train_imgs/P004623.png  \n",
            "  inflating: data/train_imgs/P004624.png  \n",
            "  inflating: data/train_imgs/P004625.png  \n",
            "  inflating: data/train_imgs/P004626.png  \n",
            "  inflating: data/train_imgs/P004627.png  \n",
            "  inflating: data/train_imgs/P004628.png  \n",
            "  inflating: data/train_imgs/P004629.png  \n",
            "  inflating: data/train_imgs/P004630.png  \n",
            "  inflating: data/train_imgs/P004631.png  \n",
            "  inflating: data/train_imgs/P004632.png  \n",
            "  inflating: data/train_imgs/P004633.png  \n",
            "  inflating: data/train_imgs/P004634.png  \n",
            "  inflating: data/train_imgs/P004635.png  \n",
            "  inflating: data/train_imgs/P004636.png  \n",
            "  inflating: data/train_imgs/P004637.png  \n",
            "  inflating: data/train_imgs/P004638.png  \n",
            "  inflating: data/train_imgs/P004639.png  \n",
            "  inflating: data/train_imgs/P004640.png  \n",
            "  inflating: data/train_imgs/P004641.png  \n",
            "  inflating: data/train_imgs/P004642.png  \n",
            "  inflating: data/train_imgs/P004643.png  \n",
            "  inflating: data/train_imgs/P004644.png  \n",
            "  inflating: data/train_imgs/P004645.png  \n",
            "  inflating: data/train_imgs/P004646.png  \n",
            "  inflating: data/train_imgs/P004647.png  \n",
            "  inflating: data/train_imgs/P004648.png  \n",
            "  inflating: data/train_imgs/P004649.png  \n",
            "  inflating: data/train_imgs/P004650.png  \n",
            "  inflating: data/train_imgs/P004651.png  \n",
            "  inflating: data/train_imgs/P004652.png  \n",
            "  inflating: data/train_imgs/P004653.png  \n",
            "  inflating: data/train_imgs/P004654.png  \n",
            "  inflating: data/train_imgs/P004655.png  \n",
            "  inflating: data/train_imgs/P004656.png  \n",
            "  inflating: data/train_imgs/P004657.png  \n",
            "  inflating: data/train_imgs/P004658.png  \n",
            "  inflating: data/train_imgs/P004659.png  \n",
            "  inflating: data/train_imgs/P004660.png  \n",
            "  inflating: data/train_imgs/P004661.png  \n",
            "  inflating: data/train_imgs/P004662.png  \n",
            "  inflating: data/train_imgs/P004663.png  \n",
            "  inflating: data/train_imgs/P004664.png  \n",
            "  inflating: data/train_imgs/P004665.png  \n",
            "  inflating: data/train_imgs/P004666.png  \n",
            "  inflating: data/train_imgs/P004667.png  \n",
            "  inflating: data/train_imgs/P004668.png  \n",
            "  inflating: data/train_imgs/P004669.png  \n",
            "  inflating: data/train_imgs/P004670.png  \n",
            "  inflating: data/train_imgs/P004671.png  \n",
            "  inflating: data/train_imgs/P004672.png  \n",
            "  inflating: data/train_imgs/P004673.png  \n",
            "  inflating: data/train_imgs/P004674.png  \n",
            "  inflating: data/train_imgs/P004675.png  \n",
            "  inflating: data/train_imgs/P004676.png  \n",
            "  inflating: data/train_imgs/P004677.png  \n",
            "  inflating: data/train_imgs/P004678.png  \n",
            "  inflating: data/train_imgs/P004679.png  \n",
            "  inflating: data/train_imgs/P004680.png  \n",
            "  inflating: data/train_imgs/P004681.png  \n",
            "  inflating: data/train_imgs/P004682.png  \n",
            "  inflating: data/train_imgs/P004683.png  \n",
            "  inflating: data/train_imgs/P004684.png  \n",
            "  inflating: data/train_imgs/P004685.png  \n",
            "  inflating: data/train_imgs/P004686.png  \n",
            "  inflating: data/train_imgs/P004687.png  \n",
            "  inflating: data/train_imgs/P004688.png  \n",
            "  inflating: data/train_imgs/P004689.png  \n",
            "  inflating: data/train_imgs/P004690.png  \n",
            "  inflating: data/train_imgs/P004691.png  \n",
            "  inflating: data/train_imgs/P004692.png  \n",
            "  inflating: data/train_imgs/P004693.png  \n",
            "  inflating: data/train_imgs/P004694.png  \n",
            "  inflating: data/train_imgs/P004695.png  \n",
            "  inflating: data/train_imgs/P004696.png  \n",
            "  inflating: data/train_imgs/P004697.png  \n",
            "  inflating: data/train_imgs/P004698.png  \n",
            "  inflating: data/train_imgs/P004699.png  \n",
            "  inflating: data/train_imgs/P004700.png  \n",
            "  inflating: data/train_imgs/P004701.png  \n",
            "  inflating: data/train_imgs/P004702.png  \n",
            "  inflating: data/train_imgs/P004703.png  \n",
            "  inflating: data/train_imgs/P004704.png  \n",
            "  inflating: data/train_imgs/P004705.png  \n",
            "  inflating: data/train_imgs/P004706.png  \n",
            "  inflating: data/train_imgs/P004707.png  \n",
            "  inflating: data/train_imgs/P004708.png  \n",
            "  inflating: data/train_imgs/P004709.png  \n",
            "  inflating: data/train_imgs/P004710.png  \n",
            "  inflating: data/train_imgs/P004711.png  \n",
            "  inflating: data/train_imgs/P004712.png  \n",
            "  inflating: data/train_imgs/P004713.png  \n",
            "  inflating: data/train_imgs/P004714.png  \n",
            "  inflating: data/train_imgs/P004715.png  \n",
            "  inflating: data/train_imgs/P004716.png  \n",
            "  inflating: data/train_imgs/P004717.png  \n",
            "  inflating: data/train_imgs/P004718.png  \n",
            "  inflating: data/train_imgs/P004719.png  \n",
            "  inflating: data/train_imgs/P004720.png  \n",
            "  inflating: data/train_imgs/P004721.png  \n",
            "  inflating: data/train_imgs/P004722.png  \n",
            "  inflating: data/train_imgs/P004723.png  \n",
            "  inflating: data/train_imgs/P004724.png  \n",
            "  inflating: data/train_imgs/P004725.png  \n",
            "  inflating: data/train_imgs/P004726.png  \n",
            "  inflating: data/train_imgs/P004727.png  \n",
            "  inflating: data/train_imgs/P004728.png  \n",
            "  inflating: data/train_imgs/P004729.png  \n",
            "  inflating: data/train_imgs/P004730.png  \n",
            "  inflating: data/train_imgs/P004731.png  \n",
            "  inflating: data/train_imgs/P004732.png  \n",
            "  inflating: data/train_imgs/P004733.png  \n",
            "  inflating: data/train_imgs/P004734.png  \n",
            "  inflating: data/train_imgs/P004735.png  \n",
            "  inflating: data/train_imgs/P004736.png  \n",
            "  inflating: data/train_imgs/P004737.png  \n",
            "  inflating: data/train_imgs/P004738.png  \n",
            "  inflating: data/train_imgs/P004739.png  \n",
            "  inflating: data/train_imgs/P004740.png  \n",
            "  inflating: data/train_imgs/P004741.png  \n",
            "  inflating: data/train_imgs/P004742.png  \n",
            "  inflating: data/train_imgs/P004743.png  \n",
            "  inflating: data/train_imgs/P004744.png  \n",
            "  inflating: data/train_imgs/P004745.png  \n",
            "  inflating: data/train_imgs/P004746.png  \n",
            "  inflating: data/train_imgs/P004747.png  \n",
            "  inflating: data/train_imgs/P004748.png  \n",
            "  inflating: data/train_imgs/P004749.png  \n",
            "  inflating: data/train_imgs/P004750.png  \n",
            "  inflating: data/train_imgs/P004751.png  \n",
            "  inflating: data/train_imgs/P004752.png  \n",
            "  inflating: data/train_imgs/P004753.png  \n",
            "  inflating: data/train_imgs/P004754.png  \n",
            "  inflating: data/train_imgs/P004755.png  \n",
            "  inflating: data/train_imgs/P004756.png  \n",
            "  inflating: data/train_imgs/P004757.png  \n",
            "  inflating: data/train_imgs/P004758.png  \n",
            "  inflating: data/train_imgs/P004759.png  \n",
            "  inflating: data/train_imgs/P004760.png  \n",
            "  inflating: data/train_imgs/P004761.png  \n",
            "  inflating: data/train_imgs/P004762.png  \n",
            "  inflating: data/train_imgs/P004763.png  \n",
            "  inflating: data/train_imgs/P004764.png  \n",
            "  inflating: data/train_imgs/P004765.png  \n",
            "  inflating: data/train_imgs/P004766.png  \n",
            "  inflating: data/train_imgs/P004767.png  \n",
            "  inflating: data/train_imgs/P004768.png  \n",
            "  inflating: data/train_imgs/P004769.png  \n",
            "  inflating: data/train_imgs/P004770.png  \n",
            "  inflating: data/train_imgs/P004771.png  \n",
            "  inflating: data/train_imgs/P004772.png  \n",
            "  inflating: data/train_imgs/P004773.png  \n",
            "  inflating: data/train_imgs/P004774.png  \n",
            "  inflating: data/train_imgs/P004775.png  \n",
            "  inflating: data/train_imgs/P004776.png  \n",
            "  inflating: data/train_imgs/P004777.png  \n",
            "  inflating: data/train_imgs/P004778.png  \n",
            "  inflating: data/train_imgs/P004779.png  \n",
            "  inflating: data/train_imgs/P004780.png  \n",
            "  inflating: data/train_imgs/P004781.png  \n",
            "  inflating: data/train_imgs/P004782.png  \n",
            "  inflating: data/train_imgs/P004783.png  \n",
            "  inflating: data/train_imgs/P004784.png  \n",
            "  inflating: data/train_imgs/P004785.png  \n",
            "  inflating: data/train_imgs/P004786.png  \n",
            "  inflating: data/train_imgs/P004787.png  \n",
            "  inflating: data/train_imgs/P004788.png  \n",
            "  inflating: data/train_imgs/P004789.png  \n",
            "  inflating: data/train_imgs/P004790.png  \n",
            "  inflating: data/train_imgs/P004791.png  \n",
            "  inflating: data/train_imgs/P004792.png  \n",
            "  inflating: data/train_imgs/P004793.png  \n",
            "  inflating: data/train_imgs/P004794.png  \n",
            "  inflating: data/train_imgs/P004795.png  \n",
            "  inflating: data/train_imgs/P004796.png  \n",
            "  inflating: data/train_imgs/P004797.png  \n",
            "  inflating: data/train_imgs/P004798.png  \n",
            "  inflating: data/train_imgs/P004799.png  \n",
            "  inflating: data/train_imgs/P004800.png  \n",
            "  inflating: data/train_imgs/P004801.png  \n",
            "  inflating: data/train_imgs/P004802.png  \n",
            "  inflating: data/train_imgs/P004803.png  \n",
            "  inflating: data/train_imgs/P004804.png  \n",
            "  inflating: data/train_imgs/P004805.png  \n",
            "  inflating: data/train_imgs/P004806.png  \n",
            "  inflating: data/train_imgs/P004807.png  \n",
            "  inflating: data/train_imgs/P004808.png  \n",
            "  inflating: data/train_imgs/P004809.png  \n",
            "  inflating: data/train_imgs/P004810.png  \n",
            "  inflating: data/train_imgs/P004811.png  \n",
            "  inflating: data/train_imgs/P004812.png  \n",
            "  inflating: data/train_imgs/P004813.png  \n",
            "  inflating: data/train_imgs/P004814.png  \n",
            "  inflating: data/train_imgs/P004815.png  \n",
            "  inflating: data/train_imgs/P004816.png  \n",
            "  inflating: data/train_imgs/P004817.png  \n",
            "  inflating: data/train_imgs/P004818.png  \n",
            "  inflating: data/train_imgs/P004819.png  \n",
            "  inflating: data/train_imgs/P004820.png  \n",
            "  inflating: data/train_imgs/P004821.png  \n",
            "  inflating: data/train_imgs/P004822.png  \n",
            "  inflating: data/train_imgs/P004823.png  \n",
            "  inflating: data/train_imgs/P004824.png  \n",
            "  inflating: data/train_imgs/P004825.png  \n",
            "  inflating: data/train_imgs/P004826.png  \n",
            "  inflating: data/train_imgs/P004827.png  \n",
            "  inflating: data/train_imgs/P004828.png  \n",
            "  inflating: data/train_imgs/P004829.png  \n",
            "  inflating: data/train_imgs/P004830.png  \n",
            "  inflating: data/train_imgs/P004831.png  \n",
            "  inflating: data/train_imgs/P004832.png  \n",
            "  inflating: data/train_imgs/P004833.png  \n",
            "  inflating: data/train_imgs/P004834.png  \n",
            "  inflating: data/train_imgs/P004835.png  \n",
            "  inflating: data/train_imgs/P004836.png  \n",
            "  inflating: data/train_imgs/P004837.png  \n",
            "  inflating: data/train_imgs/P004838.png  \n",
            "  inflating: data/train_imgs/P004839.png  \n",
            "  inflating: data/train_imgs/P004840.png  \n",
            "  inflating: data/train_imgs/P004841.png  \n",
            "  inflating: data/train_imgs/P004842.png  \n",
            "  inflating: data/train_imgs/P004843.png  \n",
            "  inflating: data/train_imgs/P004844.png  \n",
            "  inflating: data/train_imgs/P004845.png  \n",
            "  inflating: data/train_imgs/P004846.png  \n",
            "  inflating: data/train_imgs/P004847.png  \n",
            "  inflating: data/train_imgs/P004848.png  \n",
            "  inflating: data/train_imgs/P004849.png  \n",
            "  inflating: data/train_imgs/P004850.png  \n",
            "  inflating: data/train_imgs/P004851.png  \n",
            "  inflating: data/train_imgs/P004852.png  \n",
            "  inflating: data/train_imgs/P004853.png  \n",
            "  inflating: data/train_imgs/P004854.png  \n",
            "  inflating: data/train_imgs/P004855.png  \n",
            "  inflating: data/train_imgs/P004856.png  \n",
            "  inflating: data/train_imgs/P004857.png  \n",
            "  inflating: data/train_imgs/P004858.png  \n",
            "  inflating: data/train_imgs/P004859.png  \n",
            "  inflating: data/train_imgs/P004860.png  \n",
            "  inflating: data/train_imgs/P004861.png  \n",
            "  inflating: data/train_imgs/P004862.png  \n",
            "  inflating: data/train_imgs/P004863.png  \n",
            "  inflating: data/train_imgs/P004864.png  \n",
            "  inflating: data/train_imgs/P004865.png  \n",
            "  inflating: data/train_imgs/P004866.png  \n",
            "  inflating: data/train_imgs/P004867.png  \n",
            "  inflating: data/train_imgs/P004868.png  \n",
            "  inflating: data/train_imgs/P004869.png  \n",
            "  inflating: data/train_imgs/P004870.png  \n",
            "  inflating: data/train_imgs/P004871.png  \n",
            "  inflating: data/train_imgs/P004872.png  \n",
            "  inflating: data/train_imgs/P004873.png  \n",
            "  inflating: data/train_imgs/P004874.png  \n",
            "  inflating: data/train_imgs/P004875.png  \n",
            "  inflating: data/train_imgs/P004876.png  \n",
            "  inflating: data/train_imgs/P004877.png  \n",
            "  inflating: data/train_imgs/P004878.png  \n",
            "  inflating: data/train_imgs/P004879.png  \n",
            "  inflating: data/train_imgs/P004880.png  \n",
            "  inflating: data/train_imgs/P004881.png  \n",
            "  inflating: data/train_imgs/P004882.png  \n",
            "  inflating: data/train_imgs/P004883.png  \n",
            "  inflating: data/train_imgs/P004884.png  \n",
            "  inflating: data/train_imgs/P004885.png  \n",
            "  inflating: data/train_imgs/P004886.png  \n",
            "  inflating: data/train_imgs/P004887.png  \n",
            "  inflating: data/train_imgs/P004888.png  \n",
            "  inflating: data/train_imgs/P004889.png  \n",
            "  inflating: data/train_imgs/P004890.png  \n",
            "  inflating: data/train_imgs/P004891.png  \n",
            "  inflating: data/train_imgs/P004892.png  \n",
            "  inflating: data/train_imgs/P004893.png  \n",
            "  inflating: data/train_imgs/P004894.png  \n",
            "  inflating: data/train_imgs/P004895.png  \n",
            "  inflating: data/train_imgs/P004896.png  \n",
            "  inflating: data/train_imgs/P004897.png  \n",
            "  inflating: data/train_imgs/P004898.png  \n",
            "  inflating: data/train_imgs/P004899.png  \n",
            "  inflating: data/train_imgs/P004900.png  \n",
            "  inflating: data/train_imgs/P004901.png  \n",
            "  inflating: data/train_imgs/P004902.png  \n",
            "  inflating: data/train_imgs/P004903.png  \n",
            "  inflating: data/train_imgs/P004904.png  \n",
            "  inflating: data/train_imgs/P004905.png  \n",
            "  inflating: data/train_imgs/P004906.png  \n",
            "  inflating: data/train_imgs/P004907.png  \n",
            "  inflating: data/train_imgs/P004908.png  \n",
            "  inflating: data/train_imgs/P004909.png  \n",
            "  inflating: data/train_imgs/P004910.png  \n",
            "  inflating: data/train_imgs/P004911.png  \n",
            "  inflating: data/train_imgs/P004912.png  \n",
            "  inflating: data/train_imgs/P004913.png  \n",
            "  inflating: data/train_imgs/P004914.png  \n",
            "  inflating: data/train_imgs/P004915.png  \n",
            "  inflating: data/train_imgs/P004916.png  \n",
            "  inflating: data/train_imgs/P004917.png  \n",
            "  inflating: data/train_imgs/P004918.png  \n",
            "  inflating: data/train_imgs/P004919.png  \n",
            "  inflating: data/train_imgs/P004920.png  \n",
            "  inflating: data/train_imgs/P004921.png  \n",
            "  inflating: data/train_imgs/P004922.png  \n",
            "  inflating: data/train_imgs/P004923.png  \n",
            "  inflating: data/train_imgs/P004924.png  \n",
            "  inflating: data/train_imgs/P004925.png  \n",
            "  inflating: data/train_imgs/P004926.png  \n",
            "  inflating: data/train_imgs/P004927.png  \n",
            "  inflating: data/train_imgs/P004928.png  \n",
            "  inflating: data/train_imgs/P004929.png  \n",
            "  inflating: data/train_imgs/P004930.png  \n",
            "  inflating: data/train_imgs/P004931.png  \n",
            "  inflating: data/train_imgs/P004932.png  \n",
            "  inflating: data/train_imgs/P004933.png  \n",
            "  inflating: data/train_imgs/P004934.png  \n",
            "  inflating: data/train_imgs/P004935.png  \n",
            "  inflating: data/train_imgs/P004936.png  \n",
            "  inflating: data/train_imgs/P004937.png  \n",
            "  inflating: data/train_imgs/P004938.png  \n",
            "  inflating: data/train_imgs/P004939.png  \n",
            "  inflating: data/train_imgs/P004940.png  \n",
            "  inflating: data/train_imgs/P004941.png  \n",
            "  inflating: data/train_imgs/P004942.png  \n",
            "  inflating: data/train_imgs/P004943.png  \n",
            "  inflating: data/train_imgs/P004944.png  \n",
            "  inflating: data/train_imgs/P004945.png  \n",
            "  inflating: data/train_imgs/P004946.png  \n",
            "  inflating: data/train_imgs/P004947.png  \n",
            "  inflating: data/train_imgs/P004948.png  \n",
            "  inflating: data/train_imgs/P004949.png  \n",
            "  inflating: data/train_imgs/P004950.png  \n",
            "  inflating: data/train_imgs/P004951.png  \n",
            "  inflating: data/train_imgs/P004952.png  \n",
            "  inflating: data/train_imgs/P004953.png  \n",
            "  inflating: data/train_imgs/P004954.png  \n",
            "  inflating: data/train_imgs/P004955.png  \n",
            "  inflating: data/train_imgs/P004956.png  \n",
            "  inflating: data/train_imgs/P004957.png  \n",
            "  inflating: data/train_imgs/P004958.png  \n",
            "  inflating: data/train_imgs/P004959.png  \n",
            "  inflating: data/train_imgs/P004960.png  \n",
            "  inflating: data/train_imgs/P004961.png  \n",
            "  inflating: data/train_imgs/P004962.png  \n",
            "  inflating: data/train_imgs/P004963.png  \n",
            "  inflating: data/train_imgs/P004964.png  \n",
            "  inflating: data/train_imgs/P004965.png  \n",
            "  inflating: data/train_imgs/P004966.png  \n",
            "  inflating: data/train_imgs/P004967.png  \n",
            "  inflating: data/train_imgs/P004968.png  \n",
            "  inflating: data/train_imgs/P004969.png  \n",
            "  inflating: data/train_imgs/P004970.png  \n",
            "  inflating: data/train_imgs/P004971.png  \n",
            "  inflating: data/train_imgs/P004972.png  \n",
            "  inflating: data/train_imgs/P004973.png  \n",
            "  inflating: data/train_imgs/P004974.png  \n",
            "  inflating: data/train_imgs/P004975.png  \n",
            "  inflating: data/train_imgs/P004976.png  \n",
            "  inflating: data/train_imgs/P004977.png  \n",
            "  inflating: data/train_imgs/P004978.png  \n",
            "  inflating: data/train_imgs/P004979.png  \n",
            "  inflating: data/train_imgs/P004980.png  \n",
            "  inflating: data/train_imgs/P004981.png  \n",
            "  inflating: data/train_imgs/P004982.png  \n",
            "  inflating: data/train_imgs/P004983.png  \n",
            "  inflating: data/train_imgs/P004984.png  \n",
            "  inflating: data/train_imgs/P004985.png  \n",
            "  inflating: data/train_imgs/P004986.png  \n",
            "  inflating: data/train_imgs/P004987.png  \n",
            "  inflating: data/train_imgs/P004988.png  \n",
            "  inflating: data/train_imgs/P004989.png  \n",
            "  inflating: data/train_imgs/P004990.png  \n",
            "  inflating: data/train_imgs/P004991.png  \n",
            "  inflating: data/train_imgs/P004992.png  \n",
            "  inflating: data/train_imgs/P004993.png  \n",
            "  inflating: data/train_imgs/P004994.png  \n",
            "  inflating: data/train_imgs/P004995.png  \n",
            "  inflating: data/train_imgs/P004996.png  \n",
            "  inflating: data/train_imgs/P004997.png  \n",
            "  inflating: data/train_imgs/P004998.png  \n",
            "  inflating: data/train_imgs/P004999.png  \n",
            "  inflating: data/train_imgs/P005000.png  \n",
            "  inflating: data/train_imgs/P005001.png  \n",
            "  inflating: data/train_imgs/P005002.png  \n",
            "  inflating: data/train_imgs/P005003.png  \n",
            "  inflating: data/train_imgs/P005004.png  \n",
            "  inflating: data/train_imgs/P005005.png  \n",
            "  inflating: data/train_imgs/P005006.png  \n",
            "  inflating: data/train_imgs/P005007.png  \n",
            "  inflating: data/train_imgs/P005008.png  \n",
            "  inflating: data/train_imgs/P005009.png  \n",
            "  inflating: data/train_imgs/P005010.png  \n",
            "  inflating: data/train_imgs/P005011.png  \n",
            "  inflating: data/train_imgs/P005012.png  \n",
            "  inflating: data/train_imgs/P005013.png  \n",
            "  inflating: data/train_imgs/P005014.png  \n",
            "  inflating: data/train_imgs/P005015.png  \n",
            "  inflating: data/train_imgs/P005016.png  \n",
            "  inflating: data/train_imgs/P005017.png  \n",
            "  inflating: data/train_imgs/P005018.png  \n",
            "  inflating: data/train_imgs/P005019.png  \n",
            "  inflating: data/train_imgs/P005020.png  \n",
            "  inflating: data/train_imgs/P005021.png  \n",
            "  inflating: data/train_imgs/P005022.png  \n",
            "  inflating: data/train_imgs/P005023.png  \n",
            "  inflating: data/train_imgs/P005024.png  \n",
            "  inflating: data/train_imgs/P005025.png  \n",
            "  inflating: data/train_imgs/P005026.png  \n",
            "  inflating: data/train_imgs/P005027.png  \n",
            "  inflating: data/train_imgs/P005028.png  \n",
            "  inflating: data/train_imgs/P005029.png  \n",
            "  inflating: data/train_imgs/P005030.png  \n",
            "  inflating: data/train_imgs/P005031.png  \n",
            "  inflating: data/train_imgs/P005032.png  \n",
            "  inflating: data/train_imgs/P005033.png  \n",
            "  inflating: data/train_imgs/P005034.png  \n",
            "  inflating: data/train_imgs/P005035.png  \n",
            "  inflating: data/train_imgs/P005036.png  \n",
            "  inflating: data/train_imgs/P005037.png  \n",
            "  inflating: data/train_imgs/P005038.png  \n",
            "  inflating: data/train_imgs/P005039.png  \n",
            "  inflating: data/train_imgs/P005040.png  \n",
            "  inflating: data/train_imgs/P005041.png  \n",
            "  inflating: data/train_imgs/P005042.png  \n",
            "  inflating: data/train_imgs/P005043.png  \n",
            "  inflating: data/train_imgs/P005044.png  \n",
            "  inflating: data/train_imgs/P005045.png  \n",
            "  inflating: data/train_imgs/P005046.png  \n",
            "  inflating: data/train_imgs/P005047.png  \n",
            "  inflating: data/train_imgs/P005048.png  \n",
            "  inflating: data/train_imgs/P005049.png  \n",
            "  inflating: data/train_imgs/P005050.png  \n",
            "  inflating: data/train_imgs/P005051.png  \n",
            "  inflating: data/train_imgs/P005052.png  \n",
            "  inflating: data/train_imgs/P005053.png  \n",
            "  inflating: data/train_imgs/P005054.png  \n",
            "  inflating: data/train_imgs/P005055.png  \n",
            "  inflating: data/train_imgs/P005056.png  \n",
            "  inflating: data/train_imgs/P005057.png  \n",
            "  inflating: data/train_imgs/P005058.png  \n",
            "  inflating: data/train_imgs/P005059.png  \n",
            "  inflating: data/train_imgs/P005060.png  \n",
            "  inflating: data/train_imgs/P005061.png  \n",
            "  inflating: data/train_imgs/P005062.png  \n",
            "  inflating: data/train_imgs/P005063.png  \n",
            "  inflating: data/train_imgs/P005064.png  \n",
            "  inflating: data/train_imgs/P005065.png  \n",
            "  inflating: data/train_imgs/P005066.png  \n",
            "  inflating: data/train_imgs/P005067.png  \n",
            "  inflating: data/train_imgs/P005068.png  \n",
            "  inflating: data/train_imgs/P005069.png  \n",
            "  inflating: data/train_imgs/P005070.png  \n",
            "  inflating: data/train_imgs/P005071.png  \n",
            "  inflating: data/train_imgs/P005072.png  \n",
            "  inflating: data/train_imgs/P005073.png  \n",
            "  inflating: data/train_imgs/P005074.png  \n",
            "  inflating: data/train_imgs/P005075.png  \n",
            "  inflating: data/train_imgs/P005076.png  \n",
            "  inflating: data/train_imgs/P005077.png  \n",
            "  inflating: data/train_imgs/P005078.png  \n",
            "  inflating: data/train_imgs/P005079.png  \n",
            "  inflating: data/train_imgs/P005080.png  \n",
            "  inflating: data/train_imgs/P005081.png  \n",
            "  inflating: data/train_imgs/P005082.png  \n",
            "  inflating: data/train_imgs/P005083.png  \n",
            "  inflating: data/train_imgs/P005084.png  \n",
            "  inflating: data/train_imgs/P005085.png  \n",
            "  inflating: data/train_imgs/P005086.png  \n",
            "  inflating: data/train_imgs/P005087.png  \n",
            "  inflating: data/train_imgs/P005088.png  \n",
            "  inflating: data/train_imgs/P005089.png  \n",
            "  inflating: data/train_imgs/P005090.png  \n",
            "  inflating: data/train_imgs/P005091.png  \n",
            "  inflating: data/train_imgs/P005092.png  \n",
            "  inflating: data/train_imgs/P005093.png  \n",
            "  inflating: data/train_imgs/P005094.png  \n",
            "  inflating: data/train_imgs/P005095.png  \n",
            "  inflating: data/train_imgs/P005096.png  \n",
            "  inflating: data/train_imgs/P005097.png  \n",
            "  inflating: data/train_imgs/P005098.png  \n",
            "  inflating: data/train_imgs/P005099.png  \n",
            "  inflating: data/train_imgs/P005100.png  \n",
            "  inflating: data/train_imgs/P005101.png  \n",
            "  inflating: data/train_imgs/P005102.png  \n",
            "  inflating: data/train_imgs/P005103.png  \n",
            "  inflating: data/train_imgs/P005104.png  \n",
            "  inflating: data/train_imgs/P005105.png  \n",
            "  inflating: data/train_imgs/P005106.png  \n",
            "  inflating: data/train_imgs/P005107.png  \n",
            "  inflating: data/train_imgs/P005108.png  \n",
            "  inflating: data/train_imgs/P005109.png  \n",
            "  inflating: data/train_imgs/P005110.png  \n",
            "  inflating: data/train_imgs/P005111.png  \n",
            "  inflating: data/train_imgs/P005112.png  \n",
            "  inflating: data/train_imgs/P005113.png  \n",
            "  inflating: data/train_imgs/P005114.png  \n",
            "  inflating: data/train_imgs/P005115.png  \n",
            "  inflating: data/train_imgs/P005116.png  \n",
            "  inflating: data/train_imgs/P005117.png  \n",
            "  inflating: data/train_imgs/P005118.png  \n",
            "  inflating: data/train_imgs/P005119.png  \n",
            "  inflating: data/train_imgs/P005120.png  \n",
            "  inflating: data/train_imgs/P005121.png  \n",
            "  inflating: data/train_imgs/P005122.png  \n",
            "  inflating: data/train_imgs/P005123.png  \n",
            "  inflating: data/train_imgs/P005124.png  \n",
            "  inflating: data/train_imgs/P005125.png  \n",
            "  inflating: data/train_imgs/P005126.png  \n",
            "  inflating: data/train_imgs/P005127.png  \n",
            "  inflating: data/train_imgs/P005128.png  \n",
            "  inflating: data/train_imgs/P005129.png  \n",
            "  inflating: data/train_imgs/P005130.png  \n",
            "  inflating: data/train_imgs/P005131.png  \n",
            "  inflating: data/train_imgs/P005132.png  \n",
            "  inflating: data/train_imgs/P005133.png  \n",
            "  inflating: data/train_imgs/P005134.png  \n",
            "  inflating: data/train_imgs/P005135.png  \n",
            "  inflating: data/train_imgs/P005136.png  \n",
            "  inflating: data/train_imgs/P005137.png  \n",
            "  inflating: data/train_imgs/P005138.png  \n",
            "  inflating: data/train_imgs/P005139.png  \n",
            "  inflating: data/train_imgs/P005140.png  \n",
            "  inflating: data/train_imgs/P005141.png  \n",
            "  inflating: data/train_imgs/P005142.png  \n",
            "  inflating: data/train_imgs/P005143.png  \n",
            "  inflating: data/train_imgs/P005144.png  \n",
            "  inflating: data/train_imgs/P005145.png  \n",
            "  inflating: data/train_imgs/P005146.png  \n",
            "  inflating: data/train_imgs/P005147.png  \n",
            "  inflating: data/train_imgs/P005148.png  \n",
            "  inflating: data/train_imgs/P005149.png  \n",
            "  inflating: data/train_imgs/P005150.png  \n",
            "  inflating: data/train_imgs/P005151.png  \n",
            "  inflating: data/train_imgs/P005152.png  \n",
            "  inflating: data/train_imgs/P005153.png  \n",
            "  inflating: data/train_imgs/P005154.png  \n",
            "  inflating: data/train_imgs/P005155.png  \n",
            "  inflating: data/train_imgs/P005156.png  \n",
            "  inflating: data/train_imgs/P005157.png  \n",
            "  inflating: data/train_imgs/P005158.png  \n",
            "  inflating: data/train_imgs/P005159.png  \n",
            "  inflating: data/train_imgs/P005160.png  \n",
            "  inflating: data/train_imgs/P005161.png  \n",
            "  inflating: data/train_imgs/P005162.png  \n",
            "  inflating: data/train_imgs/P005163.png  \n",
            "  inflating: data/train_imgs/P005164.png  \n",
            "  inflating: data/train_imgs/P005165.png  \n",
            "  inflating: data/train_imgs/P005166.png  \n",
            "  inflating: data/train_imgs/P005167.png  \n",
            "  inflating: data/train_imgs/P005168.png  \n",
            "  inflating: data/train_imgs/P005169.png  \n",
            "  inflating: data/train_imgs/P005170.png  \n",
            "  inflating: data/train_imgs/P005171.png  \n",
            "  inflating: data/train_imgs/P005172.png  \n",
            "  inflating: data/train_imgs/P005173.png  \n",
            "  inflating: data/train_imgs/P005174.png  \n",
            "  inflating: data/train_imgs/P005175.png  \n",
            "  inflating: data/train_imgs/P005176.png  \n",
            "  inflating: data/train_imgs/P005177.png  \n",
            "  inflating: data/train_imgs/P005178.png  \n",
            "  inflating: data/train_imgs/P005179.png  \n",
            "  inflating: data/train_imgs/P005180.png  \n",
            "  inflating: data/train_imgs/P005181.png  \n",
            "  inflating: data/train_imgs/P005182.png  \n",
            "  inflating: data/train_imgs/P005183.png  \n",
            "  inflating: data/train_imgs/P005184.png  \n",
            "  inflating: data/train_imgs/P005185.png  \n",
            "  inflating: data/train_imgs/P005186.png  \n",
            "  inflating: data/train_imgs/P005187.png  \n",
            "  inflating: data/train_imgs/P005188.png  \n",
            "  inflating: data/train_imgs/P005189.png  \n",
            "  inflating: data/train_imgs/P005190.png  \n",
            "  inflating: data/train_imgs/P005191.png  \n",
            "  inflating: data/train_imgs/P005192.png  \n",
            "  inflating: data/train_imgs/P005193.png  \n",
            "  inflating: data/train_imgs/P005194.png  \n",
            "  inflating: data/train_imgs/P005195.png  \n",
            "  inflating: data/train_imgs/P005196.png  \n",
            "  inflating: data/train_imgs/P005197.png  \n",
            "  inflating: data/train_imgs/P005198.png  \n",
            "  inflating: data/train_imgs/P005199.png  \n",
            "  inflating: data/train_imgs/P005200.png  \n",
            "  inflating: data/train_imgs/P005201.png  \n",
            "  inflating: data/train_imgs/P005202.png  \n",
            "  inflating: data/train_imgs/P005203.png  \n",
            "  inflating: data/train_imgs/P005204.png  \n",
            "  inflating: data/train_imgs/P005205.png  \n",
            "  inflating: data/train_imgs/P005206.png  \n",
            "  inflating: data/train_imgs/P005207.png  \n",
            "  inflating: data/train_imgs/P005208.png  \n",
            "  inflating: data/train_imgs/P005209.png  \n",
            "  inflating: data/train_imgs/P005210.png  \n",
            "  inflating: data/train_imgs/P005211.png  \n",
            "  inflating: data/train_imgs/P005212.png  \n",
            "  inflating: data/train_imgs/P005213.png  \n",
            "  inflating: data/train_imgs/P005214.png  \n",
            "  inflating: data/train_imgs/P005215.png  \n",
            "  inflating: data/train_imgs/P005216.png  \n",
            "  inflating: data/train_imgs/P005217.png  \n",
            "  inflating: data/train_imgs/P005218.png  \n",
            "  inflating: data/train_imgs/P005219.png  \n",
            "  inflating: data/train_imgs/P005220.png  \n",
            "  inflating: data/train_imgs/P005221.png  \n",
            "  inflating: data/train_imgs/P005222.png  \n",
            "  inflating: data/train_imgs/P005223.png  \n",
            "  inflating: data/train_imgs/P005224.png  \n",
            "  inflating: data/train_imgs/P005225.png  \n",
            "  inflating: data/train_imgs/P005226.png  \n",
            "  inflating: data/train_imgs/P005227.png  \n",
            "  inflating: data/train_imgs/P005228.png  \n",
            "  inflating: data/train_imgs/P005229.png  \n",
            "  inflating: data/train_imgs/P005230.png  \n",
            "  inflating: data/train_imgs/P005231.png  \n",
            "  inflating: data/train_imgs/P005232.png  \n",
            "  inflating: data/train_imgs/P005233.png  \n",
            "  inflating: data/train_imgs/P005234.png  \n",
            "  inflating: data/train_imgs/P005235.png  \n",
            "  inflating: data/train_imgs/P005236.png  \n",
            "  inflating: data/train_imgs/P005237.png  \n",
            "  inflating: data/train_imgs/P005238.png  \n",
            "  inflating: data/train_imgs/P005239.png  \n",
            "  inflating: data/train_imgs/P005240.png  \n",
            "  inflating: data/train_imgs/P005241.png  \n",
            "  inflating: data/train_imgs/P005242.png  \n",
            "  inflating: data/train_imgs/P005243.png  \n",
            "  inflating: data/train_imgs/P005244.png  \n",
            "  inflating: data/train_imgs/P005245.png  \n",
            "  inflating: data/train_imgs/P005246.png  \n",
            "  inflating: data/train_imgs/P005247.png  \n",
            "  inflating: data/train_imgs/P005248.png  \n",
            "  inflating: data/train_imgs/P005249.png  \n",
            "  inflating: data/train_imgs/P005250.png  \n",
            "  inflating: data/train_imgs/P005251.png  \n",
            "  inflating: data/train_imgs/P005252.png  \n",
            "  inflating: data/train_imgs/P005253.png  \n",
            "  inflating: data/train_imgs/P005254.png  \n",
            "  inflating: data/train_imgs/P005255.png  \n",
            "  inflating: data/train_imgs/P005256.png  \n",
            "  inflating: data/train_imgs/P005257.png  \n",
            "  inflating: data/train_imgs/P005258.png  \n",
            "  inflating: data/train_imgs/P005259.png  \n",
            "  inflating: data/train_imgs/P005260.png  \n",
            "  inflating: data/train_imgs/P005261.png  \n",
            "  inflating: data/train_imgs/P005262.png  \n",
            "  inflating: data/train_imgs/P005263.png  \n",
            "  inflating: data/train_imgs/P005264.png  \n",
            "  inflating: data/train_imgs/P005265.png  \n",
            "  inflating: data/train_imgs/P005266.png  \n",
            "  inflating: data/train_imgs/P005267.png  \n",
            "  inflating: data/train_imgs/P005268.png  \n",
            "  inflating: data/train_imgs/P005269.png  \n",
            "  inflating: data/train_imgs/P005270.png  \n",
            "  inflating: data/train_imgs/P005271.png  \n",
            "  inflating: data/train_imgs/P005272.png  \n",
            "  inflating: data/train_imgs/P005273.png  \n",
            "  inflating: data/train_imgs/P005274.png  \n",
            "  inflating: data/train_imgs/P005275.png  \n",
            "  inflating: data/train_imgs/P005276.png  \n",
            "  inflating: data/train_imgs/P005277.png  \n",
            "  inflating: data/train_imgs/P005278.png  \n",
            "  inflating: data/train_imgs/P005279.png  \n",
            "  inflating: data/train_imgs/P005280.png  \n",
            "  inflating: data/train_imgs/P005281.png  \n",
            "  inflating: data/train_imgs/P005282.png  \n",
            "  inflating: data/train_imgs/P005283.png  \n",
            "  inflating: data/train_imgs/P005284.png  \n",
            "  inflating: data/train_imgs/P005285.png  \n",
            "  inflating: data/train_imgs/P005286.png  \n",
            "  inflating: data/train_imgs/P005287.png  \n",
            "  inflating: data/train_imgs/P005288.png  \n",
            "  inflating: data/train_imgs/P005289.png  \n",
            "  inflating: data/train_imgs/P005290.png  \n",
            "  inflating: data/train_imgs/P005291.png  \n",
            "  inflating: data/train_imgs/P005292.png  \n",
            "  inflating: data/train_imgs/P005293.png  \n",
            "  inflating: data/train_imgs/P005294.png  \n",
            "  inflating: data/train_imgs/P005295.png  \n",
            "  inflating: data/train_imgs/P005296.png  \n",
            "  inflating: data/train_imgs/P005297.png  \n",
            "  inflating: data/train_imgs/P005298.png  \n",
            "  inflating: data/train_imgs/P005299.png  \n",
            "  inflating: data/train_imgs/P005300.png  \n",
            "  inflating: data/train_imgs/P005301.png  \n",
            "  inflating: data/train_imgs/P005302.png  \n",
            "  inflating: data/train_imgs/P005303.png  \n",
            "  inflating: data/train_imgs/P005304.png  \n",
            "  inflating: data/train_imgs/P005305.png  \n",
            "  inflating: data/train_imgs/P005306.png  \n",
            "  inflating: data/train_imgs/P005307.png  \n",
            "  inflating: data/train_imgs/P005308.png  \n",
            "  inflating: data/train_imgs/P005309.png  \n",
            "  inflating: data/train_imgs/P005310.png  \n",
            "  inflating: data/train_imgs/P005311.png  \n",
            "  inflating: data/train_imgs/P005312.png  \n",
            "  inflating: data/train_imgs/P005313.png  \n",
            "  inflating: data/train_imgs/P005314.png  \n",
            "  inflating: data/train_imgs/P005315.png  \n",
            "  inflating: data/train_imgs/P005316.png  \n",
            "  inflating: data/train_imgs/P005317.png  \n",
            "  inflating: data/train_imgs/P005318.png  \n",
            "  inflating: data/train_imgs/P005319.png  \n",
            "  inflating: data/train_imgs/P005320.png  \n",
            "  inflating: data/train_imgs/P005321.png  \n",
            "  inflating: data/train_imgs/P005322.png  \n",
            "  inflating: data/train_imgs/P005323.png  \n",
            "  inflating: data/train_imgs/P005324.png  \n",
            "  inflating: data/train_imgs/P005325.png  \n",
            "  inflating: data/train_imgs/P005326.png  \n",
            "  inflating: data/train_imgs/P005327.png  \n",
            "  inflating: data/train_imgs/P005328.png  \n",
            "  inflating: data/train_imgs/P005329.png  \n",
            "  inflating: data/train_imgs/P005330.png  \n",
            "  inflating: data/train_imgs/P005331.png  \n",
            "  inflating: data/train_imgs/P005332.png  \n",
            "  inflating: data/train_imgs/P005333.png  \n",
            "  inflating: data/train_imgs/P005334.png  \n",
            "  inflating: data/train_imgs/P005335.png  \n",
            "  inflating: data/train_imgs/P005336.png  \n",
            "  inflating: data/train_imgs/P005337.png  \n",
            "  inflating: data/train_imgs/P005338.png  \n",
            "  inflating: data/train_imgs/P005339.png  \n",
            "  inflating: data/train_imgs/P005340.png  \n",
            "  inflating: data/train_imgs/P005341.png  \n",
            "  inflating: data/train_imgs/P005342.png  \n",
            "  inflating: data/train_imgs/P005343.png  \n",
            "  inflating: data/train_imgs/P005344.png  \n",
            "  inflating: data/train_imgs/P005345.png  \n",
            "  inflating: data/train_imgs/P005346.png  \n",
            "  inflating: data/train_imgs/P005347.png  \n",
            "  inflating: data/train_imgs/P005348.png  \n",
            "  inflating: data/train_imgs/P005349.png  \n",
            "  inflating: data/train_imgs/P005350.png  \n",
            "  inflating: data/train_imgs/P005351.png  \n",
            "  inflating: data/train_imgs/P005352.png  \n",
            "  inflating: data/train_imgs/P005353.png  \n",
            "  inflating: data/train_imgs/P005354.png  \n",
            "  inflating: data/train_imgs/P005355.png  \n",
            "  inflating: data/train_imgs/P005356.png  \n",
            "  inflating: data/train_imgs/P005357.png  \n",
            "  inflating: data/train_imgs/P005358.png  \n",
            "  inflating: data/train_imgs/P005359.png  \n",
            "  inflating: data/train_imgs/P005360.png  \n",
            "  inflating: data/train_imgs/P005361.png  \n",
            "  inflating: data/train_imgs/P005362.png  \n",
            "  inflating: data/train_imgs/P005363.png  \n",
            "  inflating: data/train_imgs/P005364.png  \n",
            "  inflating: data/train_imgs/P005365.png  \n",
            "  inflating: data/train_imgs/P005366.png  \n",
            "  inflating: data/train_imgs/P005367.png  \n",
            "  inflating: data/train_imgs/P005368.png  \n",
            "  inflating: data/train_imgs/P005369.png  \n",
            "  inflating: data/train_imgs/P005370.png  \n",
            "  inflating: data/train_imgs/P005371.png  \n",
            "  inflating: data/train_imgs/P005372.png  \n",
            "  inflating: data/train_imgs/P005373.png  \n",
            "  inflating: data/train_imgs/P005374.png  \n",
            "  inflating: data/train_imgs/P005375.png  \n",
            "  inflating: data/train_imgs/P005376.png  \n",
            "  inflating: data/train_imgs/P005377.png  \n",
            "  inflating: data/train_imgs/P005378.png  \n",
            "  inflating: data/train_imgs/P005379.png  \n",
            "  inflating: data/train_imgs/P005380.png  \n",
            "  inflating: data/train_imgs/P005381.png  \n",
            "  inflating: data/train_imgs/P005382.png  \n",
            "  inflating: data/train_imgs/P005383.png  \n",
            "  inflating: data/train_imgs/P005384.png  \n",
            "  inflating: data/train_imgs/P005385.png  \n",
            "  inflating: data/train_imgs/P005386.png  \n",
            "  inflating: data/train_imgs/P005387.png  \n",
            "  inflating: data/train_imgs/P005388.png  \n",
            "  inflating: data/train_imgs/P005389.png  \n",
            "  inflating: data/train_imgs/P005390.png  \n",
            "  inflating: data/train_imgs/P005391.png  \n",
            "  inflating: data/train_imgs/P005392.png  \n",
            "  inflating: data/train_imgs/P005393.png  \n",
            "  inflating: data/train_imgs/P005394.png  \n",
            "  inflating: data/train_imgs/P005395.png  \n",
            "  inflating: data/train_imgs/P005396.png  \n",
            "  inflating: data/train_imgs/P005397.png  \n",
            "  inflating: data/train_imgs/P005398.png  \n",
            "  inflating: data/train_imgs/P005399.png  \n",
            "  inflating: data/train_imgs/P005400.png  \n",
            "  inflating: data/train_imgs/P005401.png  \n",
            "  inflating: data/train_imgs/P005402.png  \n",
            "  inflating: data/train_imgs/P005403.png  \n",
            "  inflating: data/train_imgs/P005404.png  \n",
            "  inflating: data/train_imgs/P005405.png  \n",
            "  inflating: data/train_imgs/P005406.png  \n",
            "  inflating: data/train_imgs/P005407.png  \n",
            "  inflating: data/train_imgs/P005408.png  \n",
            "  inflating: data/train_imgs/P005409.png  \n",
            "  inflating: data/train_imgs/P005410.png  \n",
            "  inflating: data/train_imgs/P005411.png  \n",
            "  inflating: data/train_imgs/P005412.png  \n",
            "  inflating: data/train_imgs/P005413.png  \n",
            "  inflating: data/train_imgs/P005414.png  \n",
            "  inflating: data/train_imgs/P005415.png  \n",
            "  inflating: data/train_imgs/P005416.png  \n",
            "  inflating: data/train_imgs/P005417.png  \n",
            "  inflating: data/train_imgs/P005418.png  \n",
            "  inflating: data/train_imgs/P005419.png  \n",
            "  inflating: data/train_imgs/P005420.png  \n",
            "  inflating: data/train_imgs/P005421.png  \n",
            "  inflating: data/train_imgs/P005422.png  \n",
            "  inflating: data/train_imgs/P005423.png  \n",
            "  inflating: data/train_imgs/P005424.png  \n",
            "  inflating: data/train_imgs/P005425.png  \n",
            "  inflating: data/train_imgs/P005426.png  \n",
            "  inflating: data/train_imgs/P005427.png  \n",
            "  inflating: data/train_imgs/P005428.png  \n",
            "  inflating: data/train_imgs/P005429.png  \n",
            "  inflating: data/train_imgs/P005430.png  \n",
            "  inflating: data/train_imgs/P005431.png  \n",
            "  inflating: data/train_imgs/P005432.png  \n",
            "  inflating: data/train_imgs/P005433.png  \n",
            "  inflating: data/train_imgs/P005434.png  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Explore and prepare data"
      ],
      "metadata": {
        "id": "XymM1mcoRqVj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuration class\n",
        "class Config:\n",
        "    resize = False\n",
        "    batch_size = 32\n",
        "    numworkers = 2"
      ],
      "metadata": {
        "id": "02ahlm8tRqVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import torchvision\n",
        "from skimage import io, img_as_float32\n",
        "import numpy as np\n",
        "import torch\n",
        "from skimage.io import imread\n",
        "from skimage.util import img_as_ubyte\n",
        "from skimage import exposure\n",
        "import cv2\n",
        "\n",
        "class ToTensor3D(object):\n",
        "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
        "    def __call__(self, image):\n",
        "        image = img_as_float32(image)\n",
        "\n",
        "        # The following two lines are to duplicate the grayscale image onto\n",
        "        # 3 channels. That's to make the input compatible with those models\n",
        "        # trained on color images. If you don't use pretrained models, you can\n",
        "        # delete these two lines.\n",
        "        new_shape = (3,) + image.shape\n",
        "        dup_img = np.broadcast_to(image, new_shape)\n",
        "\n",
        "        return torch.from_numpy(dup_img.copy())\n",
        "\n",
        "class CustomImageDataset(torch.utils.data.Dataset):\n",
        "    \"\"\"Make a custom dataset for the mammography patches\"\"\"  \n",
        "    def __init__(self, image_dir, df, transform=None, testset=False):\n",
        "        # Create one iterable that can be __getitemed__\n",
        "        self.image_dir = image_dir\n",
        "        self.df = df\n",
        "        self.transform = transform # added transform\n",
        "        self.testset = testset # indicates if dataset is the test set\n",
        "\n",
        "    def __len__(self): # Denotes the total number of samples\n",
        "        # return self.df.shape[0] # orig\n",
        "        return len(self.df) # try this\n",
        "\n",
        "    def normalize(self, image):\n",
        "      \"\"\"\n",
        "      Apply image-level normalization for pre-processing.\n",
        "      For more background, read here: \n",
        "      https://towardsdatascience.com/train-a-neural-network-to-detect-breast-mri-tumors-with-pytorch-250a02be7777\n",
        "      https://scikit-image.org/docs/stable/user_guide/data_types.html\n",
        "      https://www.di.ubi.pt/~lfbaa/pubs/recpad2017b.pdf \n",
        "      \"\"\"\n",
        "      # OLD\n",
        "      # image = image.astype(float) * 255. / image.max()\n",
        "      # # Convert float --> uint8. This maps pixel intensities from 0 to 255\n",
        "      # # Source: above and here: https://scikit-image.org/docs/stable/user_guide/data_types.html\n",
        "      # image = image.astype(np.uint8)\n",
        "\n",
        "      # NEW\n",
        "      # Convert to 8-bit uint (going from [0 to 65535] to [0 to 255])\n",
        "      # I read the skimage page more closely, where it cautions against using\n",
        "      # astype. It calls for the below usage instead. These functions convert \n",
        "      # images to the desired dtype and properly rescale their values:\n",
        "      image = img_as_ubyte(image) \n",
        "\n",
        "      # Histogram equalization --> poor val acc\n",
        "      # image = exposure.equalize_hist(image) # skimage implementation\n",
        "      # image = cv2.equalizeHist(image) # OpenCV implementation\n",
        "\n",
        "      # Subtract image mean and divide by standard deviation --> poor val acc\n",
        "      # image_mean = image.mean()\n",
        "      # image_std = image.std()\n",
        "      # image = (image - image_mean) / image_std\n",
        "\n",
        "      return image\n",
        "\n",
        "    def __getitem__(self, index): # Generates one sample of data\n",
        "        \n",
        "        # added this\n",
        "        if torch.is_tensor(index):\n",
        "          index = index.tolist()\n",
        "\n",
        "        # Goes to image_tensor below\n",
        "        image_path = os.path.join(self.image_dir, self.df.iloc[index]['img_name'])\n",
        "        # image_og = Image.open(image_path)\n",
        "        image_og = imread(image_path, as_gray=True) # read in png or jpg\n",
        "\n",
        "        # Apply image-level normalization for preprocessing\n",
        "        image = self.normalize(image_og)\n",
        "\n",
        "        # Convert to 3D tensor\n",
        "        t = ToTensor3D()\n",
        "        image = t(image)\n",
        "\n",
        "        if self.transform:\n",
        "          image = self.transform(image)\n",
        "          # image = self.transform(image_og)\n",
        "\n",
        "        # Since the test set has no label_num, we get the image id\n",
        "        if not(self.testset):\n",
        "          label = torch.tensor(self.df.iloc[index]['label_num'],dtype=torch.long)\n",
        "        else:\n",
        "          label = self.df.iloc[index]['id'] \n",
        "\n",
        "        # # Resize, depending on the network ---> CAN REMOVE\n",
        "        # if Config.resize:\n",
        "        #     resize = torchvision.transforms.Resize(384)\n",
        "        #     image = resize(image)\n",
        "        \n",
        "        return image, label"
      ],
      "metadata": {
        "id": "SFVcsJuNRqVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# New numeric labels.\n",
        "labels_num = {'background': 0, 'calc_ben': 1, 'calc_mal': 2, \n",
        "              'mass_ben': 3, 'mass_mal': 4}\n",
        "\n",
        "# Read image metadata\n",
        "traindf = pd.read_csv('data/train.csv') \n",
        "traindf['label_num'] = traindf['label'].map(labels_num)\n",
        "\n",
        "testdf = pd.read_csv('data/test.csv')\n",
        "\n",
        "# print(traindf)\n",
        "# print()\n",
        "# print(testdf)"
      ],
      "metadata": {
        "id": "Gnc3HEk2RqVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get how many in each label category\n",
        "traindf.groupby([\"label_num\"]).count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "qubBLKRIgnP8",
        "outputId": "c646d1b5-fc8d-4e80-8d19-5976a08d3402"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             id  label  img_name\n",
              "label_num                       \n",
              "0          2495   2495      2495\n",
              "1          1042   1042      1042\n",
              "2           579    579       579\n",
              "3           681    681       681\n",
              "4           637    637       637"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a7a2e8e5-6c2b-486c-a312-6ab254c102eb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "      <th>img_name</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>label_num</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2495</td>\n",
              "      <td>2495</td>\n",
              "      <td>2495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1042</td>\n",
              "      <td>1042</td>\n",
              "      <td>1042</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>579</td>\n",
              "      <td>579</td>\n",
              "      <td>579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>681</td>\n",
              "      <td>681</td>\n",
              "      <td>681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>637</td>\n",
              "      <td>637</td>\n",
              "      <td>637</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a7a2e8e5-6c2b-486c-a312-6ab254c102eb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a7a2e8e5-6c2b-486c-a312-6ab254c102eb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a7a2e8e5-6c2b-486c-a312-6ab254c102eb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize the distribution of the raw data. Notice the class imbalance such that the majority of the data is \"background\"."
      ],
      "metadata": {
        "id": "OAdG3KEafvTS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Visualize the different classes\n",
        "fig, ax = plt.subplots()\n",
        "ax = sns.countplot(data=traindf,\n",
        "                   x=\"label\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "dE1AifjQhFNT",
        "outputId": "5c30de40-1a66-4933-a4be-07e65c66db09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For more ease getting word labels from numerical predictions later\n",
        "num_labels = {v:k for k,v in labels_num.items()}\n",
        "num_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eX84idCWWCqu",
        "outputId": "45b4e78f-cc4f-4d7b-a747-121b89ada934"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'background', 1: 'calc_ben', 2: 'calc_mal', 3: 'mass_ben', 4: 'mass_mal'}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Consider the data augmentation steps we would like to apply to the mammography patches. \n",
        "\n",
        "Here are some helpful resources:\n",
        "*   https://www.kaggle.com/competitions/rsna-breast-cancer-detection/discussion/372567\n",
        "*   https://www.nature.com/articles/s41598-019-48995-4#Sec2\n",
        "\n"
      ],
      "metadata": {
        "id": "afaHU_GkgOeJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, WeightedRandomSampler\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# First, work with some minimal transforms\n",
        "initial_transforms = transforms.Compose([\n",
        "      transforms.Resize((224,224)),\n",
        "      transforms.Normalize([0, 0, 0], [1, 1, 1])\n",
        "      ])\n",
        "\n",
        "# First, create the original train dataset without transforms\n",
        "untransformed_train_dataset = CustomImageDataset('data/train_imgs', traindf,\n",
        "                                                 transform = initial_transforms)\n",
        "# Create the original val dataset, which is basically a copy of the \n",
        "# orig_train_dataset, but with a different set of transformations\n",
        "untransformed_val_dataset = CustomImageDataset('data/train_imgs', traindf,\n",
        "                                                 transform = initial_transforms)\n",
        "\n",
        "# Split the orig_train_dataset into preliminary train and val datasets\n",
        "train_size = int(0.9 * len(untransformed_train_dataset))\n",
        "val_size = len(untransformed_train_dataset) - train_size\n",
        "temp_train_dataset, temp_val_dataset = torch.utils.data.random_split(untransformed_train_dataset, \n",
        "                                                     [train_size, val_size])\n",
        "\n",
        "# Keep track of the indices for each dataset for later\n",
        "train_indices = temp_train_dataset.indices\n",
        "val_indices = temp_val_dataset.indices\n",
        "\n",
        "image_loader = DataLoader(temp_train_dataset, batch_size=Config.batch_size,\n",
        "                          shuffle=False, num_workers=Config.numworkers)\n",
        "\n",
        "def batch_mean_and_sd(loader):\n",
        "    \"\"\"\n",
        "    Helper function to get mean and std of dataset using the dataloader.\n",
        "    See: https://www.google.com/url?q=https://www.binarystudy.com/2022/04/how-to-normalize-image-dataset-inpytorch.html&sa=D&source=editors&ust=1679883727112650&usg=AOvVaw0FvYMWXTnXnGFI5RooK_pJ\n",
        "    \"\"\"\n",
        "    cnt = 0\n",
        "    fst_moment = torch.empty(3)\n",
        "    snd_moment = torch.empty(3)\n",
        "\n",
        "    for images, _ in loader:\n",
        "        b, c, h, w = images.shape\n",
        "        nb_pixels = b * h * w\n",
        "        sum_ = torch.sum(images, dim=[0, 2, 3])\n",
        "        sum_of_square = torch.sum(images ** 2,\n",
        "                                  dim=[0, 2, 3])\n",
        "        fst_moment = (cnt * fst_moment + sum_) / (\n",
        "                      cnt + nb_pixels)\n",
        "        snd_moment = (cnt * snd_moment + sum_of_square) / (\n",
        "                            cnt + nb_pixels)\n",
        "        cnt += nb_pixels\n",
        "\n",
        "    mean, std = fst_moment, torch.sqrt(snd_moment - fst_moment ** 2)        \n",
        "    return mean,std\n",
        "  \n",
        "train_ds_mean, train_ds_std = batch_mean_and_sd(image_loader)\n",
        "print(\"mean and std: \\n\", train_ds_mean, train_ds_std)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9RLFX3aHj9D",
        "outputId": "90cd401c-ea3f-44fc-9bef-dc995bff13fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean and std: \n",
            " tensor([0.3804, 0.3804, 0.3804]) tensor([0.2353, 0.2353, 0.2353])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define transforms I want to use\n",
        "data_transforms = {\n",
        "  \"train\": transforms.Compose([\n",
        "      transforms.Resize((224,224)),\n",
        "      # transforms.Resize(256),\n",
        "      # transforms.CenterCrop(224),\n",
        "      # transforms.RandomResizedCrop(224), # Some data augmentation --> get rid of? Seems to get padded areas\n",
        "      # transforms.Normalize(train_ds_mean, [1., 1., 1.]),\n",
        "      transforms.RandomHorizontalFlip(), # Some data augmentation\n",
        "      transforms.RandomVerticalFlip(), # Data augmentation\n",
        "      transforms.RandomRotation(25), # Data augmentation\n",
        "      # transforms.Normalize(train_ds_mean, [1., 1., 1.])\n",
        "      transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1),\n",
        "      # transforms.RandomAutocontrast(),\n",
        "      transforms.Normalize(train_ds_mean, train_ds_std)\n",
        "      ]),\n",
        "\n",
        "  \"val\": transforms.Compose([\n",
        "      transforms.Resize((224,224)),\n",
        "      transforms.Normalize(train_ds_mean, train_ds_std)\n",
        "  ]),\n",
        "  \"test\": transforms.Compose([\n",
        "      transforms.Resize((224,224)),\n",
        "      transforms.Normalize(train_ds_mean, train_ds_std)\n",
        "  ])\n",
        "}"
      ],
      "metadata": {
        "id": "WUHS8zLoWdeo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before addressing class imbalance, note how each batch had so much more \"background\""
      ],
      "metadata": {
        "id": "B0hT_qln1BxA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# BEFORE ADDRESSING CLASS IMBALANCE\n",
        "# Make datasets \n",
        "\n",
        "# train_dataset = CustomImageDataset('data/train_imgs', traindf, \n",
        "#                                    transform=data_transforms[\"train\"])\n",
        "\n",
        "# train_size = int(0.5 * len(train_dataset))\n",
        "# val_size = len(train_dataset) - train_size\n",
        "# train_dataset, val_dataset = torch.utils.data.random_split(train_dataset, \n",
        "#                                                      [train_size, val_size])\n",
        "\n",
        "# test_dataset = CustomImageDataset('data/test_imgs', testdf)\n",
        "\n",
        "# # Make dataloaders\n",
        "# train_loader = torch.utils.data.DataLoader(train_dataset, Config.batch_size, \n",
        "#                                            shuffle=True, num_workers=Config.numworkers)\n",
        "\n",
        "# val_loader = torch.utils.data.DataLoader(val_dataset, Config.batch_size, \n",
        "#                                          shuffle=True, num_workers=Config.numworkers)\n",
        "\n",
        "# # Build batches - check distribution of classes per batch\n",
        "# for step, (img,label) in enumerate(train_loader):\n",
        "#   print(\"batch index {}, 0/1/2/3/4: {}/{}/{}/{}/{}\".format(step,\n",
        "#                                                            len(np.where(label.numpy() == 0)[0]),\n",
        "#                                                            len(np.where(label.numpy() == 1)[0]),\n",
        "#                                                            len(np.where(label.numpy() == 2)[0]),\n",
        "#                                                            len(np.where(label.numpy() == 3)[0]),\n",
        "#                                                            len(np.where(label.numpy() == 4)[0]))\n",
        "#   )\n",
        "\n",
        "# # Putting these into a dict format for compatibility with the train function later\n",
        "# dataloaders = {\"train\": train_loader,\n",
        "#                \"val\": val_loader\n",
        "#                }\n",
        "\n",
        "# dataset_sizes = {\"train\": len(train_dataset),\n",
        "#                  \"val\": len(val_dataset)\n",
        "#                  }"
      ],
      "metadata": {
        "id": "4P1PJ2ZXWJGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Address class imbalance\n",
        "We can address class imbalance by creating weights for each class and then doing weighted random sampling.\n",
        "\n",
        "Side note: I will split the original train set into 90% train and 10% validation. There is a tradeoff between how representative the validation accuracy is and how much data my models can train on."
      ],
      "metadata": {
        "id": "wCVQN_1wgggC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, WeightedRandomSampler\n",
        "\n",
        "# Want to create separate training and validation datasets, each having their\n",
        "# own transformations. We also want to prevent leakage!\n",
        "\n",
        "# First, create the original train dataset\n",
        "orig_train_dataset = CustomImageDataset('data/train_imgs', traindf, \n",
        "                                   transform=data_transforms[\"train\"])\n",
        "# Create the original val dataset, which is basically a copy of the \n",
        "# orig_train_dataset, but with a different set of transformations\n",
        "orig_val_dataset = CustomImageDataset('data/train_imgs', traindf, \n",
        "                                   transform=data_transforms[\"val\"])\n",
        "\n",
        "# Split the orig_train_dataset into preliminary train and val datasets\n",
        "# train_size = int(0.9 * len(orig_train_dataset))\n",
        "# val_size = len(orig_train_dataset) - train_size\n",
        "# train_dataset, temp_val_dataset = torch.utils.data.random_split(orig_train_dataset, \n",
        "#                                                      [train_size, val_size])\n",
        "\n",
        "# Get the indices for the data that belongs to the temp_val_dataset, and use it \n",
        "# to subset the orig_val_dataset. Since we are not shuffling anything, the \n",
        "# indices should be the same between train and val.\n",
        "train_dataset = torch.utils.data.Subset(orig_train_dataset, train_indices)\n",
        "val_dataset = torch.utils.data.Subset(orig_val_dataset, val_indices)\n",
        "\n",
        "test_dataset = CustomImageDataset('data/test_imgs', testdf, \n",
        "                                  transform=data_transforms[\"test\"],\n",
        "                                  testset=True)"
      ],
      "metadata": {
        "id": "OhHRsovkk7Ap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making sure there is no overlap to avoid data leakage into val --> should be False if no overlap\n",
        "bool(set(val_dataset.indices) & set(train_dataset.indices))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLEUnoX5xSKw",
        "outputId": "9803d10e-246b-479c-ad4d-e44a0c156d65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Addressing class imbalance by weighting samples \n",
        "# Adjust sample weights within each batch to balance the five classes.\n",
        "y_train = [orig_train_dataset.df.loc[i][\"label_num\"] for i in train_dataset.indices]\n",
        "class_sample_count = np.array([len(np.where(y_train == t)[0]) for t in np.unique(y_train)])\n",
        "weight = 1. / class_sample_count\n",
        "samples_weight = np.array([weight[t] for t in y_train])\n",
        "samples_weight = torch.from_numpy(samples_weight)\n",
        "\n",
        "# sampler = WeightedRandomSampler(samples_weight.type('torch.DoubleTensor'), len(samples_weight))\n",
        "sampler = WeightedRandomSampler(samples_weight, len(samples_weight))\n",
        "\n",
        "# Remake the train dataloader\n",
        "train_loader = DataLoader(train_dataset, sampler=sampler, batch_size=Config.batch_size,\n",
        "                          num_workers=Config.numworkers)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, Config.batch_size, \n",
        "                                         shuffle=True, num_workers=Config.numworkers)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, Config.batch_size, \n",
        "                                         shuffle=False)\n",
        "# Can uncomment to see the distribution of each batch\n",
        "# # Build batches - check distribution of classes per batch\n",
        "# for step, (img,label) in enumerate(train_loader):\n",
        "#   print(\"batch index {}, 0/1/2/3/4: {}/{}/{}/{}/{}\".format(step,\n",
        "#                                                            len(np.where(label.numpy() == 0)[0]),\n",
        "#                                                            len(np.where(label.numpy() == 1)[0]),\n",
        "#                                                            len(np.where(label.numpy() == 2)[0]),\n",
        "#                                                            len(np.where(label.numpy() == 3)[0]),\n",
        "#                                                            len(np.where(label.numpy() == 4)[0]))\n",
        "#   )\n",
        "\n",
        "\n",
        "# Putting these into a dict format for easier use later\n",
        "dataloaders = {\"train\": train_loader,\n",
        "               \"val\": val_loader,\n",
        "               \"test\": test_loader\n",
        "               }\n",
        "\n",
        "dataset_sizes = {\"train\": len(train_dataset),\n",
        "                 \"val\": len(val_dataset),\n",
        "                 \"test\": len(test_dataset)\n",
        "                 }"
      ],
      "metadata": {
        "id": "YCibr8mAwn1K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow for Tensor.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = train_ds_mean.numpy()\n",
        "    std = train_ds_std.numpy()\n",
        "    \n",
        "    # mean = np.array([0.485, 0.456, 0.406])\n",
        "    # std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated"
      ],
      "metadata": {
        "id": "CyHWW3WVwG4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device: \", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mo09aA-E7Pw5",
        "outputId": "500167a9-7441-4066-f978-448b70f1497a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device:  cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from skimage import io, img_as_float32\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# To get one image:\n",
        "# temp_img, temp_lab = train_dataset[0]\n",
        "# print(temp_img.shape)\n",
        "# imshow(temp_img, title=num_labels[temp_lab.item()])\n",
        "# plt.title(num_labels[temp_lab.item()])\n",
        "\n",
        "# To get a batch of images\n",
        "temp_img, temp_lab = next(iter(dataloaders[\"train\"]))\n",
        "# Make a grid from batch\n",
        "out = torchvision.utils.make_grid(temp_img)\n",
        "imshow(out)\n",
        "# imshow(out, title=[num_labels[x.item()] for x in temp_lab])\n",
        "labels_list = [num_labels[x.item()] for x in temp_lab]\n",
        "print(labels_list)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "Az_WQoCDXvOE",
        "outputId": "eb4eb1b1-1235-43e0-8fab-b558511b0c96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['calc_ben', 'mass_mal', 'mass_mal', 'background', 'mass_ben', 'background', 'calc_mal', 'mass_ben', 'background', 'background', 'background', 'calc_ben', 'background', 'mass_mal', 'background', 'background', 'calc_mal', 'calc_ben', 'background', 'mass_mal', 'mass_mal', 'mass_ben', 'calc_ben', 'mass_mal', 'mass_mal', 'mass_ben', 'calc_ben', 'background', 'mass_mal', 'mass_ben', 'background', 'mass_mal']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To get a batch of images\n",
        "temp_img, temp_lab = next(iter(dataloaders[\"val\"]))\n",
        "# Make a grid from batch\n",
        "out = torchvision.utils.make_grid(temp_img)\n",
        "imshow(out)\n",
        "# imshow(out, title=[num_labels[x.item()] for x in temp_lab])\n",
        "labels_list = [num_labels[x.item()] for x in temp_lab]\n",
        "print(labels_list)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "NqtWUuK0Llrz",
        "outputId": "f9ed4d1b-723b-4e75-9bd5-9504c06408a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['background', 'background', 'calc_mal', 'background', 'background', 'mass_mal', 'background', 'background', 'calc_ben', 'calc_ben', 'calc_mal', 'background', 'background', 'mass_mal', 'calc_mal', 'background', 'background', 'background', 'background', 'calc_ben', 'background', 'background', 'background', 'background', 'calc_ben', 'calc_ben', 'background', 'background', 'background', 'mass_mal', 'background', 'background']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To get a batch of images\n",
        "temp_img, temp_lab = next(iter(dataloaders[\"test\"]))\n",
        "# Make a grid from batch\n",
        "out = torchvision.utils.make_grid(temp_img)\n",
        "imshow(out)\n",
        "# imshow(out, title=[num_labels[x.item()] for x in temp_lab])\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "NutwFEv1LqwT",
        "outputId": "7fd5bc0e-bf7b-443d-9598-acef6f858f04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up training functions"
      ],
      "metadata": {
        "id": "VRVFijCM6lwL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resources:\n",
        "* https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html"
      ],
      "metadata": {
        "id": "6kVQLMTUiam3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function, division\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.backends.cudnn as cudnn\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import random\n",
        "\n",
        "cudnn.benchmark = True\n",
        "plt.ion()   # interactive mode"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "839cb479-6bf0-48ed-c762-59599e30722d",
        "id": "AWFdZpa1RqV9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<contextlib.ExitStack at 0x7f6a2e2689d0>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    # # For book-keeping the losses and accuracies\n",
        "    # epoch_ls = []\n",
        "    # train_loss_ls = []\n",
        "    # val_loss_ls = []\n",
        "    # train_acc_ls = []\n",
        "    # val_acc_ls = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "    print(f'Best val Acc: {best_acc:4f}')\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "metadata": {
        "id": "V_X6rQnl2kuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_model(model, num_images=6):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(dataloaders['val']):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(num_images//2, 2, images_so_far)\n",
        "                ax.axis('off')\n",
        "                ax.set_title(f'predicted: {num_labels[preds[j]]}')\n",
        "                imshow(inputs.cpu().data[j])\n",
        "\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "        model.train(mode=was_training)"
      ],
      "metadata": {
        "id": "PW7r6cHv5xw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Try ResNet50 \n",
        "Read from bottom up, since most updated model training is higher up."
      ],
      "metadata": {
        "id": "lnYW2Ce7CsTe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "ULk0dO-JmqSp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-phase training approach with progressive unfreezing of layers\n",
        "This time with the train dataset mean and std normalization"
      ],
      "metadata": {
        "id": "YxYYREQtu2YK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stage 1"
      ],
      "metadata": {
        "id": "SIwaIladu2YO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet50_model = models.resnet50(weights=\"DEFAULT\")\n",
        "\n",
        "# Freeze all parameters...except for the final layer\n",
        "for param in resnet50_model.parameters():\n",
        "    param.requires_grad = False\n",
        "num_ftrs = resnet50_model.fc.in_features\n",
        "resnet50_model.fc = nn.Linear(num_ftrs, 5)\n",
        "\n",
        "resnet50_model = resnet50_model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized --> change for each stage\n",
        "optimizer = optim.Adam(resnet50_model.parameters(), lr=0.001)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 10 epochs\n",
        "# If don't want to decay, then set the step_size to very high\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "bdbf3548aadb400b9bd2bf09abe091d1",
            "56c0d412b19f4c8c9647ad906b1be15a",
            "e4a0cbfb131f4d3f82e8875fc9bbc060",
            "9e2df7b89ded4f2b91102129dafe2d4c",
            "c4b5be2a321241a99ce334add1fc0cc1",
            "1e422e391ae648b1a4b02c55be600478",
            "0facdd41f5d841e49d9d5ca8883bd732",
            "9a51dd271827438ab60c065ce21f93be",
            "e6db472b7e4a46fa9c2854eb147ef748",
            "1d5c885ddddc45dc8033327d8f9d922f",
            "9d57bcc50c034992b2acc7099cd6ccd8"
          ]
        },
        "outputId": "42dc7352-4a44-4be2-d980-26fc42463b04",
        "id": "np9yMl_cu2YR"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bdbf3548aadb400b9bd2bf09abe091d1"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resnet50_model = train_model(resnet50_model, criterion, optimizer, exp_lr_scheduler,\n",
        "                       num_epochs=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0da5653-6647-4bf0-e682-82db28efe36f",
        "id": "7cXto_UNu2YX"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/2\n",
            "----------\n",
            "train Loss: 1.4428 Acc: 0.3798\n",
            "val Loss: 1.2218 Acc: 0.5551\n",
            "\n",
            "Epoch 1/2\n",
            "----------\n",
            "train Loss: 1.3253 Acc: 0.4564\n",
            "val Loss: 1.1227 Acc: 0.5938\n",
            "\n",
            "Epoch 2/2\n",
            "----------\n",
            "train Loss: 1.2997 Acc: 0.4693\n",
            "val Loss: 1.1122 Acc: 0.5846\n",
            "\n",
            "Training complete in 3m 56s\n",
            "Best val Acc: 0.593750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stage 2"
      ],
      "metadata": {
        "id": "PJjAf9Anu2Ya"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For simplicity, first unfreeze all layers\n",
        "for param in resnet50_model.parameters():\n",
        "    param.requires_grad = True"
      ],
      "metadata": {
        "id": "DJsSG71Tu2Yb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet50_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e961df06-01b7-4c4f-9e55-c49c493ff4c6",
        "id": "gl0d-oWpu2Ye"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=2048, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "layer_count = 0\n",
        "for child in resnet50_model.children():\n",
        "  print(\"Child \", layer_count)\n",
        "  print(child)\n",
        "  children_of_child_counter = 0\n",
        "  for children_of_child in child.children():\n",
        "    print(\"child \", children_of_child_counter, \"of child\", layer_count)\n",
        "    print(children_of_child)\n",
        "    children_of_child_counter += 1 \n",
        "  layer_count += 1\n",
        "\n",
        "# print(\"total layers: \", layer_count)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6750abfc-a90f-44ea-8232-25f19437c368",
        "id": "8vCwBEyku2Yg"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Child  0\n",
            "Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "Child  1\n",
            "BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Child  2\n",
            "ReLU(inplace=True)\n",
            "Child  3\n",
            "MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "Child  4\n",
            "Sequential(\n",
            "  (0): Bottleneck(\n",
            "    (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (downsample): Sequential(\n",
            "      (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (1): Bottleneck(\n",
            "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "  )\n",
            "  (2): Bottleneck(\n",
            "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "  )\n",
            ")\n",
            "child  0 of child 4\n",
            "Bottleneck(\n",
            "  (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (downsample): Sequential(\n",
            "    (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            ")\n",
            "child  1 of child 4\n",
            "Bottleneck(\n",
            "  (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            ")\n",
            "child  2 of child 4\n",
            "Bottleneck(\n",
            "  (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            ")\n",
            "Child  5\n",
            "Sequential(\n",
            "  (0): Bottleneck(\n",
            "    (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (downsample): Sequential(\n",
            "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (1): Bottleneck(\n",
            "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "  )\n",
            "  (2): Bottleneck(\n",
            "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "  )\n",
            "  (3): Bottleneck(\n",
            "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "  )\n",
            ")\n",
            "child  0 of child 5\n",
            "Bottleneck(\n",
            "  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (downsample): Sequential(\n",
            "    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            ")\n",
            "child  1 of child 5\n",
            "Bottleneck(\n",
            "  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            ")\n",
            "child  2 of child 5\n",
            "Bottleneck(\n",
            "  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            ")\n",
            "child  3 of child 5\n",
            "Bottleneck(\n",
            "  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            ")\n",
            "Child  6\n",
            "Sequential(\n",
            "  (0): Bottleneck(\n",
            "    (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (downsample): Sequential(\n",
            "      (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (1): Bottleneck(\n",
            "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "  )\n",
            "  (2): Bottleneck(\n",
            "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "  )\n",
            "  (3): Bottleneck(\n",
            "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "  )\n",
            "  (4): Bottleneck(\n",
            "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "  )\n",
            "  (5): Bottleneck(\n",
            "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "  )\n",
            ")\n",
            "child  0 of child 6\n",
            "Bottleneck(\n",
            "  (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (downsample): Sequential(\n",
            "    (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            ")\n",
            "child  1 of child 6\n",
            "Bottleneck(\n",
            "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            ")\n",
            "child  2 of child 6\n",
            "Bottleneck(\n",
            "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            ")\n",
            "child  3 of child 6\n",
            "Bottleneck(\n",
            "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            ")\n",
            "child  4 of child 6\n",
            "Bottleneck(\n",
            "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            ")\n",
            "child  5 of child 6\n",
            "Bottleneck(\n",
            "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            ")\n",
            "Child  7\n",
            "Sequential(\n",
            "  (0): Bottleneck(\n",
            "    (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (downsample): Sequential(\n",
            "      (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (1): Bottleneck(\n",
            "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "  )\n",
            "  (2): Bottleneck(\n",
            "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "  )\n",
            ")\n",
            "child  0 of child 7\n",
            "Bottleneck(\n",
            "  (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (downsample): Sequential(\n",
            "    (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            ")\n",
            "child  1 of child 7\n",
            "Bottleneck(\n",
            "  (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            ")\n",
            "child  2 of child 7\n",
            "Bottleneck(\n",
            "  (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            ")\n",
            "Child  8\n",
            "AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "Child  9\n",
            "Linear(in_features=2048, out_features=5, bias=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now selectively freeze layers\n",
        "child_counter = 0\n",
        "for child in resnet50_model.children():\n",
        "  if child_counter < 7:\n",
        "    print(\"child\", child_counter, \"was frozen\")\n",
        "    for param in child.parameters():\n",
        "      param.requires_grad = False\n",
        "  elif child_counter == 7:\n",
        "    children_of_child_counter = 0\n",
        "    for children_of_child in child.children():\n",
        "      if children_of_child_counter < 2:\n",
        "        for param in children_of_child.parameters():\n",
        "          param.requires_grad = False\n",
        "        print(\"child\", children_of_child_counter, \"of child\", child_counter, \"was frozen\")\n",
        "      else:\n",
        "        print('child ', children_of_child_counter, 'of child',child_counter,' was not frozen')\n",
        "      children_of_child_counter += 1\n",
        "  else:\n",
        "    print(\"child \",child_counter,\" was not frozen\")\n",
        "  child_counter += 1\n",
        "    \n",
        "    # print(\"child \",child_counter,\" was frozen\")\n",
        "    # for param in child.parameters():\n",
        "    #     param.requires_grad = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17cea489-a893-4c27-c1f9-44e60c9d0927",
        "id": "WlYcLj19u2Yj"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "child 0 was frozen\n",
            "child 1 was frozen\n",
            "child 2 was frozen\n",
            "child 3 was frozen\n",
            "child 4 was frozen\n",
            "child 5 was frozen\n",
            "child 6 was frozen\n",
            "child 0 of child 7 was frozen\n",
            "child 1 of child 7 was frozen\n",
            "child  2 of child 7  was not frozen\n",
            "child  8  was not frozen\n",
            "child  9  was not frozen\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resnet50_model = resnet50_model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized --> change for each stage\n",
        "optimizer = optim.Adam(resnet50_model.parameters(), lr=0.0001)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 10 epochs\n",
        "# If don't want to decay, then set the step_size to very high\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=11, gamma=0.1)"
      ],
      "metadata": {
        "id": "N_PHNKffu2Ym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet50_model = train_model(resnet50_model, criterion, optimizer, exp_lr_scheduler,\n",
        "                       num_epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5247223c-d56b-475b-b16d-d3f4051f89a6",
        "id": "TPufQgsvu2Yo"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/9\n",
            "----------\n",
            "train Loss: 1.2400 Acc: 0.5027\n",
            "val Loss: 1.0105 Acc: 0.6121\n",
            "\n",
            "Epoch 1/9\n",
            "----------\n",
            "train Loss: 1.1617 Acc: 0.5348\n",
            "val Loss: 0.9577 Acc: 0.6305\n",
            "\n",
            "Epoch 2/9\n",
            "----------\n",
            "train Loss: 1.0836 Acc: 0.5755\n",
            "val Loss: 0.9667 Acc: 0.6324\n",
            "\n",
            "Epoch 3/9\n",
            "----------\n",
            "train Loss: 1.0556 Acc: 0.5751\n",
            "val Loss: 0.9546 Acc: 0.6452\n",
            "\n",
            "Epoch 4/9\n",
            "----------\n",
            "train Loss: 1.0134 Acc: 0.5935\n",
            "val Loss: 0.9142 Acc: 0.6544\n",
            "\n",
            "Epoch 5/9\n",
            "----------\n",
            "train Loss: 0.9982 Acc: 0.6057\n",
            "val Loss: 0.9168 Acc: 0.6654\n",
            "\n",
            "Epoch 6/9\n",
            "----------\n",
            "train Loss: 0.9940 Acc: 0.6027\n",
            "val Loss: 0.8705 Acc: 0.6710\n",
            "\n",
            "Epoch 7/9\n",
            "----------\n",
            "train Loss: 0.9592 Acc: 0.6141\n",
            "val Loss: 0.8723 Acc: 0.6691\n",
            "\n",
            "Epoch 8/9\n",
            "----------\n",
            "train Loss: 0.9457 Acc: 0.6292\n",
            "val Loss: 0.9059 Acc: 0.6636\n",
            "\n",
            "Epoch 9/9\n",
            "----------\n",
            "train Loss: 0.9269 Acc: 0.6342\n",
            "val Loss: 0.8671 Acc: 0.6838\n",
            "\n",
            "Training complete in 12m 52s\n",
            "Best val Acc: 0.683824\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stage 3"
      ],
      "metadata": {
        "id": "UDiQwVcju2Yq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Unfreeze all parameters\n",
        "for param in resnet50_model.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "resnet50_model = resnet50_model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized --> change for each stage\n",
        "optimizer = optim.Adam(resnet50_model.parameters(), lr=0.00001)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 10 epochs\n",
        "# If don't want to decay, then set the step_size to very high\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)"
      ],
      "metadata": {
        "id": "T0KyQ6zDu2Yr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet50_model = train_model(resnet50_model, criterion, optimizer, exp_lr_scheduler,\n",
        "                       num_epochs=37)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43859397-4d05-4e4f-a3b4-9fef7f51da3f",
        "id": "UbVQTiZRu2Ys"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/36\n",
            "----------\n",
            "train Loss: 0.9040 Acc: 0.6409\n",
            "val Loss: 0.8100 Acc: 0.6949\n",
            "\n",
            "Epoch 1/36\n",
            "----------\n",
            "train Loss: 0.8459 Acc: 0.6740\n",
            "val Loss: 0.8006 Acc: 0.7059\n",
            "\n",
            "Epoch 2/36\n",
            "----------\n",
            "train Loss: 0.8120 Acc: 0.6894\n",
            "val Loss: 0.7604 Acc: 0.7059\n",
            "\n",
            "Epoch 3/36\n",
            "----------\n",
            "train Loss: 0.7615 Acc: 0.6975\n",
            "val Loss: 0.7529 Acc: 0.7132\n",
            "\n",
            "Epoch 4/36\n",
            "----------\n",
            "train Loss: 0.7509 Acc: 0.7045\n",
            "val Loss: 0.7469 Acc: 0.7022\n",
            "\n",
            "Epoch 5/36\n",
            "----------\n",
            "train Loss: 0.7528 Acc: 0.7008\n",
            "val Loss: 0.7383 Acc: 0.7279\n",
            "\n",
            "Epoch 6/36\n",
            "----------\n",
            "train Loss: 0.7052 Acc: 0.7170\n",
            "val Loss: 0.7089 Acc: 0.7151\n",
            "\n",
            "Epoch 7/36\n",
            "----------\n",
            "train Loss: 0.7106 Acc: 0.7188\n",
            "val Loss: 0.6898 Acc: 0.7298\n",
            "\n",
            "Epoch 8/36\n",
            "----------\n",
            "train Loss: 0.6809 Acc: 0.7372\n",
            "val Loss: 0.6901 Acc: 0.7316\n",
            "\n",
            "Epoch 9/36\n",
            "----------\n",
            "train Loss: 0.6501 Acc: 0.7411\n",
            "val Loss: 0.6815 Acc: 0.7371\n",
            "\n",
            "Epoch 10/36\n",
            "----------\n",
            "train Loss: 0.6392 Acc: 0.7462\n",
            "val Loss: 0.6439 Acc: 0.7610\n",
            "\n",
            "Epoch 11/36\n",
            "----------\n",
            "train Loss: 0.6624 Acc: 0.7399\n",
            "val Loss: 0.6310 Acc: 0.7518\n",
            "\n",
            "Epoch 12/36\n",
            "----------\n",
            "train Loss: 0.6289 Acc: 0.7517\n",
            "val Loss: 0.6382 Acc: 0.7482\n",
            "\n",
            "Epoch 13/36\n",
            "----------\n",
            "train Loss: 0.6226 Acc: 0.7591\n",
            "val Loss: 0.6242 Acc: 0.7555\n",
            "\n",
            "Epoch 14/36\n",
            "----------\n",
            "train Loss: 0.5948 Acc: 0.7654\n",
            "val Loss: 0.6038 Acc: 0.7794\n",
            "\n",
            "Epoch 15/36\n",
            "----------\n",
            "train Loss: 0.5719 Acc: 0.7791\n",
            "val Loss: 0.5922 Acc: 0.7610\n",
            "\n",
            "Epoch 16/36\n",
            "----------\n",
            "train Loss: 0.5704 Acc: 0.7820\n",
            "val Loss: 0.5956 Acc: 0.7610\n",
            "\n",
            "Epoch 17/36\n",
            "----------\n",
            "train Loss: 0.5585 Acc: 0.7793\n",
            "val Loss: 0.6159 Acc: 0.7555\n",
            "\n",
            "Epoch 18/36\n",
            "----------\n",
            "train Loss: 0.5425 Acc: 0.7879\n",
            "val Loss: 0.5775 Acc: 0.7868\n",
            "\n",
            "Epoch 19/36\n",
            "----------\n",
            "train Loss: 0.5297 Acc: 0.7941\n",
            "val Loss: 0.5825 Acc: 0.7794\n",
            "\n",
            "Epoch 20/36\n",
            "----------\n",
            "train Loss: 0.4986 Acc: 0.8063\n",
            "val Loss: 0.6046 Acc: 0.7757\n",
            "\n",
            "Epoch 21/36\n",
            "----------\n",
            "train Loss: 0.4972 Acc: 0.8043\n",
            "val Loss: 0.6088 Acc: 0.7702\n",
            "\n",
            "Epoch 22/36\n",
            "----------\n",
            "train Loss: 0.4718 Acc: 0.8184\n",
            "val Loss: 0.5838 Acc: 0.7721\n",
            "\n",
            "Epoch 23/36\n",
            "----------\n",
            "train Loss: 0.4424 Acc: 0.8297\n",
            "val Loss: 0.5843 Acc: 0.7757\n",
            "\n",
            "Epoch 24/36\n",
            "----------\n",
            "train Loss: 0.4626 Acc: 0.8160\n",
            "val Loss: 0.5564 Acc: 0.7721\n",
            "\n",
            "Epoch 25/36\n",
            "----------\n",
            "train Loss: 0.4480 Acc: 0.8266\n",
            "val Loss: 0.5699 Acc: 0.7923\n",
            "\n",
            "Epoch 26/36\n",
            "----------\n",
            "train Loss: 0.4370 Acc: 0.8307\n",
            "val Loss: 0.5936 Acc: 0.7721\n",
            "\n",
            "Epoch 27/36\n",
            "----------\n",
            "train Loss: 0.4040 Acc: 0.8479\n",
            "val Loss: 0.5951 Acc: 0.7757\n",
            "\n",
            "Epoch 28/36\n",
            "----------\n",
            "train Loss: 0.4115 Acc: 0.8378\n",
            "val Loss: 0.5684 Acc: 0.7886\n",
            "\n",
            "Epoch 29/36\n",
            "----------\n",
            "train Loss: 0.4045 Acc: 0.8436\n",
            "val Loss: 0.5715 Acc: 0.7886\n",
            "\n",
            "Epoch 30/36\n",
            "----------\n",
            "train Loss: 0.3889 Acc: 0.8511\n",
            "val Loss: 0.5789 Acc: 0.7904\n",
            "\n",
            "Epoch 31/36\n",
            "----------\n",
            "train Loss: 0.3819 Acc: 0.8519\n",
            "val Loss: 0.5657 Acc: 0.7849\n",
            "\n",
            "Epoch 32/36\n",
            "----------\n",
            "train Loss: 0.3747 Acc: 0.8587\n",
            "val Loss: 0.5733 Acc: 0.7886\n",
            "\n",
            "Epoch 33/36\n",
            "----------\n",
            "train Loss: 0.3533 Acc: 0.8644\n",
            "val Loss: 0.6010 Acc: 0.7904\n",
            "\n",
            "Epoch 34/36\n",
            "----------\n",
            "train Loss: 0.3335 Acc: 0.8785\n",
            "val Loss: 0.5868 Acc: 0.7886\n",
            "\n",
            "Epoch 35/36\n",
            "----------\n",
            "train Loss: 0.3320 Acc: 0.8783\n",
            "val Loss: 0.5892 Acc: 0.7849\n",
            "\n",
            "Epoch 36/36\n",
            "----------\n",
            "train Loss: 0.3235 Acc: 0.8763\n",
            "val Loss: 0.6113 Acc: 0.7868\n",
            "\n",
            "Training complete in 54m 8s\n",
            "Best val Acc: 0.792279\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Save the best model --> checkpoint\n",
        "torch.save(resnet50_model.state_dict(), \n",
        "           save_models_dir + \"best_resnet50_multistage_train.pt\")"
      ],
      "metadata": {
        "id": "4XV_sbrDu2Yu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## With new TRAIN DATASET mean std normalization\n",
        "This time with a lr=0.0005 and more data augmentations (color jitter to 0.5 for each category)"
      ],
      "metadata": {
        "id": "z_Mr5KzqwKry"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft = models.resnet50(weights=\"DEFAULT\")\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "\n",
        "model_ft.fc = nn.Linear(num_ftrs, 5)\n",
        "\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.0005)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 10 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)"
      ],
      "metadata": {
        "id": "G65gFAYxwKr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
        "                       num_epochs=25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30d91040-ee8d-4b2d-bed7-dd0de0c476b3",
        "id": "VOWYRMCNwKr-"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/24\n",
            "----------\n",
            "train Loss: 1.1033 Acc: 0.5562\n",
            "val Loss: 0.8630 Acc: 0.7077\n",
            "\n",
            "Epoch 1/24\n",
            "----------\n",
            "train Loss: 0.8391 Acc: 0.6622\n",
            "val Loss: 0.7262 Acc: 0.7151\n",
            "\n",
            "Epoch 2/24\n",
            "----------\n",
            "train Loss: 0.7800 Acc: 0.6908\n",
            "val Loss: 0.7016 Acc: 0.7040\n",
            "\n",
            "Epoch 3/24\n",
            "----------\n",
            "train Loss: 0.7539 Acc: 0.6924\n",
            "val Loss: 0.6687 Acc: 0.7316\n",
            "\n",
            "Epoch 4/24\n",
            "----------\n",
            "train Loss: 0.7034 Acc: 0.7247\n",
            "val Loss: 0.7680 Acc: 0.7188\n",
            "\n",
            "Epoch 5/24\n",
            "----------\n",
            "train Loss: 0.6718 Acc: 0.7282\n",
            "val Loss: 0.6052 Acc: 0.7776\n",
            "\n",
            "Epoch 6/24\n",
            "----------\n",
            "train Loss: 0.6419 Acc: 0.7479\n",
            "val Loss: 0.6500 Acc: 0.7335\n",
            "\n",
            "Epoch 7/24\n",
            "----------\n",
            "train Loss: 0.6513 Acc: 0.7532\n",
            "val Loss: 0.6859 Acc: 0.7390\n",
            "\n",
            "Epoch 8/24\n",
            "----------\n",
            "train Loss: 0.6411 Acc: 0.7481\n",
            "val Loss: 0.7589 Acc: 0.7040\n",
            "\n",
            "Epoch 9/24\n",
            "----------\n",
            "train Loss: 0.6036 Acc: 0.7609\n",
            "val Loss: 0.5714 Acc: 0.7721\n",
            "\n",
            "Epoch 10/24\n",
            "----------\n",
            "train Loss: 0.5174 Acc: 0.7945\n",
            "val Loss: 0.5133 Acc: 0.7996\n",
            "\n",
            "Epoch 11/24\n",
            "----------\n",
            "train Loss: 0.4837 Acc: 0.8131\n",
            "val Loss: 0.4997 Acc: 0.8051\n",
            "\n",
            "Epoch 12/24\n",
            "----------\n",
            "train Loss: 0.4652 Acc: 0.8180\n",
            "val Loss: 0.4788 Acc: 0.8180\n",
            "\n",
            "Epoch 13/24\n",
            "----------\n",
            "train Loss: 0.4430 Acc: 0.8276\n",
            "val Loss: 0.4858 Acc: 0.8162\n",
            "\n",
            "Epoch 14/24\n",
            "----------\n",
            "train Loss: 0.4344 Acc: 0.8393\n",
            "val Loss: 0.5089 Acc: 0.8162\n",
            "\n",
            "Epoch 15/24\n",
            "----------\n",
            "train Loss: 0.4092 Acc: 0.8454\n",
            "val Loss: 0.4973 Acc: 0.8180\n",
            "\n",
            "Epoch 16/24\n",
            "----------\n",
            "train Loss: 0.4043 Acc: 0.8421\n",
            "val Loss: 0.5290 Acc: 0.8015\n",
            "\n",
            "Epoch 17/24\n",
            "----------\n",
            "train Loss: 0.3852 Acc: 0.8564\n",
            "val Loss: 0.5394 Acc: 0.8015\n",
            "\n",
            "Epoch 18/24\n",
            "----------\n",
            "train Loss: 0.3497 Acc: 0.8710\n",
            "val Loss: 0.5282 Acc: 0.8143\n",
            "\n",
            "Epoch 19/24\n",
            "----------\n",
            "train Loss: 0.3308 Acc: 0.8730\n",
            "val Loss: 0.5551 Acc: 0.8088\n",
            "\n",
            "Epoch 20/24\n",
            "----------\n",
            "train Loss: 0.3557 Acc: 0.8726\n",
            "val Loss: 0.5600 Acc: 0.8070\n",
            "\n",
            "Epoch 21/24\n",
            "----------\n",
            "train Loss: 0.3165 Acc: 0.8875\n",
            "val Loss: 0.5608 Acc: 0.8051\n",
            "\n",
            "Epoch 22/24\n",
            "----------\n",
            "train Loss: 0.3286 Acc: 0.8763\n",
            "val Loss: 0.5597 Acc: 0.8088\n",
            "\n",
            "Epoch 23/24\n",
            "----------\n",
            "train Loss: 0.3109 Acc: 0.8840\n",
            "val Loss: 0.5644 Acc: 0.8070\n",
            "\n",
            "Epoch 24/24\n",
            "----------\n",
            "train Loss: 0.3245 Acc: 0.8820\n",
            "val Loss: 0.5750 Acc: 0.8033\n",
            "\n",
            "Training complete in 37m 43s\n",
            "Best val Acc: 0.818015\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the best model\n",
        "torch.save(model_ft.state_dict(), save_models_dir+'best_resnet50_dsnormalized_lrincr.pt')"
      ],
      "metadata": {
        "id": "gKsFYL--wKsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## With new TRAIN DATASET mean normalization"
      ],
      "metadata": {
        "id": "zw3_qM_NEgDi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft = models.resnet50(weights=\"DEFAULT\")\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "\n",
        "model_ft.fc = nn.Linear(num_ftrs, 5)\n",
        "\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.0001)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 10 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "b43f5bdfc168490396379badb8b4893a",
            "2b3e941fa57545039f699319245e37d1",
            "947e22b6e21d459eb969d6004edb590f",
            "2c8615ec5f584916850a11e2d763a737",
            "def08db0d53a4d16b66dc9f1fa73949e",
            "cf561bff439d4a1e9dadc949a1ba0f63",
            "2434fc7003464780ace9b43e5f23f6d0",
            "d6e982de27ea438599c9e72f0fc724bf",
            "8136696512dd49b1b11131df237ee9f5",
            "1b70b2e7efd14f95a6e248153a9bcd56",
            "3ae14bb13bbb4c189087872309cca838"
          ]
        },
        "outputId": "f71873a7-0912-48f8-ed44-c2603eb7db6b",
        "id": "U_CbDXwlEgDk"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b43f5bdfc168490396379badb8b4893a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
        "                       num_epochs=25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33996636-82c7-4987-8ad8-049a41b0eecf",
        "id": "sWLdJtYOEgDm"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/24\n",
            "----------\n",
            "train Loss: 1.1826 Acc: 0.5202\n",
            "val Loss: 1.0616 Acc: 0.5772\n",
            "\n",
            "Epoch 1/24\n",
            "----------\n",
            "train Loss: 0.7851 Acc: 0.6888\n",
            "val Loss: 0.6980 Acc: 0.7426\n",
            "\n",
            "Epoch 2/24\n",
            "----------\n",
            "train Loss: 0.6684 Acc: 0.7452\n",
            "val Loss: 0.6124 Acc: 0.7812\n",
            "\n",
            "Epoch 3/24\n",
            "----------\n",
            "train Loss: 0.5870 Acc: 0.7738\n",
            "val Loss: 0.5333 Acc: 0.7868\n",
            "\n",
            "Epoch 4/24\n",
            "----------\n",
            "train Loss: 0.5150 Acc: 0.8000\n",
            "val Loss: 0.5526 Acc: 0.7923\n",
            "\n",
            "Epoch 5/24\n",
            "----------\n",
            "train Loss: 0.4908 Acc: 0.8108\n",
            "val Loss: 0.5422 Acc: 0.8033\n",
            "\n",
            "Epoch 6/24\n",
            "----------\n",
            "train Loss: 0.4396 Acc: 0.8339\n",
            "val Loss: 0.5662 Acc: 0.8051\n",
            "\n",
            "Epoch 7/24\n",
            "----------\n",
            "train Loss: 0.4009 Acc: 0.8521\n",
            "val Loss: 0.5773 Acc: 0.7996\n",
            "\n",
            "Epoch 8/24\n",
            "----------\n",
            "train Loss: 0.3619 Acc: 0.8685\n",
            "val Loss: 0.6310 Acc: 0.7941\n",
            "\n",
            "Epoch 9/24\n",
            "----------\n",
            "train Loss: 0.3312 Acc: 0.8771\n",
            "val Loss: 0.6939 Acc: 0.7739\n",
            "\n",
            "Epoch 10/24\n",
            "----------\n",
            "train Loss: 0.2790 Acc: 0.8986\n",
            "val Loss: 0.6020 Acc: 0.7996\n",
            "\n",
            "Epoch 11/24\n",
            "----------\n",
            "train Loss: 0.2340 Acc: 0.9129\n",
            "val Loss: 0.6185 Acc: 0.8033\n",
            "\n",
            "Epoch 12/24\n",
            "----------\n",
            "train Loss: 0.2161 Acc: 0.9241\n",
            "val Loss: 0.6196 Acc: 0.8033\n",
            "\n",
            "Epoch 13/24\n",
            "----------\n",
            "train Loss: 0.2114 Acc: 0.9249\n",
            "val Loss: 0.6221 Acc: 0.8070\n",
            "\n",
            "Epoch 14/24\n",
            "----------\n",
            "train Loss: 0.1968 Acc: 0.9315\n",
            "val Loss: 0.6159 Acc: 0.8235\n",
            "\n",
            "Epoch 15/24\n",
            "----------\n",
            "train Loss: 0.1914 Acc: 0.9333\n",
            "val Loss: 0.6439 Acc: 0.8070\n",
            "\n",
            "Epoch 16/24\n",
            "----------\n",
            "train Loss: 0.1840 Acc: 0.9360\n",
            "val Loss: 0.6683 Acc: 0.8051\n",
            "\n",
            "Epoch 17/24\n",
            "----------\n",
            "train Loss: 0.1643 Acc: 0.9431\n",
            "val Loss: 0.6539 Acc: 0.8125\n",
            "\n",
            "Epoch 18/24\n",
            "----------\n",
            "train Loss: 0.1565 Acc: 0.9450\n",
            "val Loss: 0.6437 Acc: 0.8107\n",
            "\n",
            "Epoch 19/24\n",
            "----------\n",
            "train Loss: 0.1431 Acc: 0.9511\n",
            "val Loss: 0.6662 Acc: 0.8088\n",
            "\n",
            "Epoch 20/24\n",
            "----------\n",
            "train Loss: 0.1426 Acc: 0.9511\n",
            "val Loss: 0.6627 Acc: 0.8033\n",
            "\n",
            "Epoch 21/24\n",
            "----------\n",
            "train Loss: 0.1462 Acc: 0.9507\n",
            "val Loss: 0.6539 Acc: 0.8088\n",
            "\n",
            "Epoch 22/24\n",
            "----------\n",
            "train Loss: 0.1512 Acc: 0.9446\n",
            "val Loss: 0.6534 Acc: 0.8107\n",
            "\n",
            "Epoch 23/24\n",
            "----------\n",
            "train Loss: 0.1380 Acc: 0.9505\n",
            "val Loss: 0.6683 Acc: 0.8107\n",
            "\n",
            "Epoch 24/24\n",
            "----------\n",
            "train Loss: 0.1450 Acc: 0.9501\n",
            "val Loss: 0.6671 Acc: 0.8143\n",
            "\n",
            "Training complete in 22m 51s\n",
            "Best val Acc: 0.823529\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the best model\n",
        "# torch.save(model_ft.state_dict(), save_models_dir+'best_resnet50_dsnormalized.pt')"
      ],
      "metadata": {
        "id": "a8WoHy9YEgDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## With new TRAIN DATASET mean std normalization"
      ],
      "metadata": {
        "id": "5jml_EINwfh5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft = models.resnet50(weights=\"DEFAULT\")\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "\n",
        "model_ft.fc = nn.Linear(num_ftrs, 5)\n",
        "\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.0001)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 10 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "cb6291c8e9654ec78a1f403461c710ea",
            "7608a4df3f2f4cad9391cdac32655e58",
            "87173b8e0aac43e5a62d718f55be9c77",
            "06d09231d3c94824a69cbb678db53eb3",
            "bc99f7548e8a477f9094c075d94513ec",
            "c1cb1ea0fa824489928c0303a8fe46b2",
            "1f09fa190e114c64a8c1525b7ce7c2b9",
            "3e91c4d1d5d1408788ede8bd1b07f3bb",
            "3eb56695f58a4139a1c4366283873949",
            "2cfd1e636f9349fe8e56ad35b4fa4532",
            "f72186815f1e4e9eb084e6843d99f88c"
          ]
        },
        "outputId": "472cc23e-bc81-457a-c8bc-3a1aa0bfd00e",
        "id": "WH1UYGJcwfh6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cb6291c8e9654ec78a1f403461c710ea"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
        "                       num_epochs=25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a193af3-44b2-4e26-a385-a7f3d282a0c9",
        "id": "TNMmkBvAwfh8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/24\n",
            "----------\n",
            "train Loss: 1.1656 Acc: 0.5258\n",
            "val Loss: 0.7556 Acc: 0.7114\n",
            "\n",
            "Epoch 1/24\n",
            "----------\n",
            "train Loss: 0.7769 Acc: 0.6973\n",
            "val Loss: 0.6883 Acc: 0.7316\n",
            "\n",
            "Epoch 2/24\n",
            "----------\n",
            "train Loss: 0.6561 Acc: 0.7429\n",
            "val Loss: 0.5570 Acc: 0.7941\n",
            "\n",
            "Epoch 3/24\n",
            "----------\n",
            "train Loss: 0.6004 Acc: 0.7708\n",
            "val Loss: 0.6406 Acc: 0.7721\n",
            "\n",
            "Epoch 4/24\n",
            "----------\n",
            "train Loss: 0.5430 Acc: 0.7894\n",
            "val Loss: 0.5426 Acc: 0.7960\n",
            "\n",
            "Epoch 5/24\n",
            "----------\n",
            "train Loss: 0.4911 Acc: 0.8176\n",
            "val Loss: 0.5044 Acc: 0.8235\n",
            "\n",
            "Epoch 6/24\n",
            "----------\n",
            "train Loss: 0.4539 Acc: 0.8241\n",
            "val Loss: 0.5849 Acc: 0.7923\n",
            "\n",
            "Epoch 7/24\n",
            "----------\n",
            "train Loss: 0.4015 Acc: 0.8458\n",
            "val Loss: 0.5712 Acc: 0.8180\n",
            "\n",
            "Epoch 8/24\n",
            "----------\n",
            "train Loss: 0.3660 Acc: 0.8640\n",
            "val Loss: 0.5592 Acc: 0.7996\n",
            "\n",
            "Epoch 9/24\n",
            "----------\n",
            "train Loss: 0.3550 Acc: 0.8691\n",
            "val Loss: 0.6329 Acc: 0.8125\n",
            "\n",
            "Epoch 10/24\n",
            "----------\n",
            "train Loss: 0.2929 Acc: 0.8918\n",
            "val Loss: 0.5708 Acc: 0.8199\n",
            "\n",
            "Epoch 11/24\n",
            "----------\n",
            "train Loss: 0.2454 Acc: 0.9106\n",
            "val Loss: 0.5734 Acc: 0.8162\n",
            "\n",
            "Epoch 12/24\n",
            "----------\n",
            "train Loss: 0.2304 Acc: 0.9172\n",
            "val Loss: 0.5702 Acc: 0.8327\n",
            "\n",
            "Epoch 13/24\n",
            "----------\n",
            "train Loss: 0.2177 Acc: 0.9252\n",
            "val Loss: 0.5760 Acc: 0.8217\n",
            "\n",
            "Epoch 14/24\n",
            "----------\n",
            "train Loss: 0.2111 Acc: 0.9247\n",
            "val Loss: 0.5609 Acc: 0.8272\n",
            "\n",
            "Epoch 15/24\n",
            "----------\n",
            "train Loss: 0.1914 Acc: 0.9325\n",
            "val Loss: 0.5819 Acc: 0.8254\n",
            "\n",
            "Epoch 16/24\n",
            "----------\n",
            "train Loss: 0.1639 Acc: 0.9429\n",
            "val Loss: 0.5887 Acc: 0.8235\n",
            "\n",
            "Epoch 17/24\n",
            "----------\n",
            "train Loss: 0.1619 Acc: 0.9470\n",
            "val Loss: 0.6067 Acc: 0.8290\n",
            "\n",
            "Epoch 18/24\n",
            "----------\n",
            "train Loss: 0.1515 Acc: 0.9464\n",
            "val Loss: 0.6043 Acc: 0.8272\n",
            "\n",
            "Epoch 19/24\n",
            "----------\n",
            "train Loss: 0.1663 Acc: 0.9421\n",
            "val Loss: 0.6228 Acc: 0.8088\n",
            "\n",
            "Epoch 20/24\n",
            "----------\n",
            "train Loss: 0.1523 Acc: 0.9472\n",
            "val Loss: 0.6170 Acc: 0.8199\n",
            "\n",
            "Epoch 21/24\n",
            "----------\n",
            "train Loss: 0.1462 Acc: 0.9470\n",
            "val Loss: 0.6271 Acc: 0.8180\n",
            "\n",
            "Epoch 22/24\n",
            "----------\n",
            "train Loss: 0.1449 Acc: 0.9468\n",
            "val Loss: 0.6178 Acc: 0.8217\n",
            "\n",
            "Epoch 23/24\n",
            "----------\n",
            "train Loss: 0.1416 Acc: 0.9548\n",
            "val Loss: 0.6266 Acc: 0.8107\n",
            "\n",
            "Epoch 24/24\n",
            "----------\n",
            "train Loss: 0.1429 Acc: 0.9497\n",
            "val Loss: 0.6314 Acc: 0.8162\n",
            "\n",
            "Training complete in 35m 51s\n",
            "Best val Acc: 0.832721\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the best model\n",
        "torch.save(model_ft.state_dict(), save_models_dir+'best_resnet50_dsnormalized.pt')"
      ],
      "metadata": {
        "id": "jjgk_JWowfh-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## With new mean std normalization (normalization)"
      ],
      "metadata": {
        "id": "CmHMDyEJmqoy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft = models.resnet50(weights=\"DEFAULT\")\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "\n",
        "model_ft.fc = nn.Linear(num_ftrs, 5)\n",
        "\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.0001)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 10 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "a3c6d0a1a7e04fffb80cd8f3101084c7",
            "fa6ce8a7224e48ccb213854045e030b4",
            "4c6164f980c2413eb5d9618998577f05",
            "df1a6fbfa3534a79b27a2e3f9817bb67",
            "ea75c44c42c141cf8da4f213bdc74c86",
            "8eb9587b42df44debb05111bd95428da",
            "6c32e5f3997a44e2b3854ba1361179bf",
            "44850f41fb4342cca8ac24b32c9559f3",
            "0e9158be14544c4b96e8bf4cf1175386",
            "466668177bdc4c5b874245c6aedc82d4",
            "9801f5844e9c412eaf05ddac4abf649a"
          ]
        },
        "id": "EZI8l4RVmqoz",
        "outputId": "4c245c33-33a9-4b38-b674-21a87f3bb610"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a3c6d0a1a7e04fffb80cd8f3101084c7"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
        "                       num_epochs=25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b1fc82c5-18f3-45b8-ee3b-67074f26fc8c",
        "id": "MAgeD_ORmqo0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/24\n",
            "----------\n",
            "train Loss: 1.2847 Acc: 0.4569\n",
            "val Loss: 45.1800 Acc: 0.4062\n",
            "\n",
            "Epoch 1/24\n",
            "----------\n",
            "train Loss: 1.0325 Acc: 0.5775\n",
            "val Loss: 200.1276 Acc: 0.1544\n",
            "\n",
            "Epoch 2/24\n",
            "----------\n",
            "train Loss: 0.9124 Acc: 0.6387\n",
            "val Loss: 231.5662 Acc: 0.1471\n",
            "\n",
            "Epoch 3/24\n",
            "----------\n",
            "train Loss: 0.8290 Acc: 0.6597\n",
            "val Loss: 264.4141 Acc: 0.1415\n",
            "\n",
            "Epoch 4/24\n",
            "----------\n",
            "train Loss: 0.7677 Acc: 0.6894\n",
            "val Loss: 399.3575 Acc: 0.1415\n",
            "\n",
            "Epoch 5/24\n",
            "----------\n",
            "train Loss: 0.6958 Acc: 0.7241\n",
            "val Loss: 1182.9205 Acc: 0.1379\n",
            "\n",
            "Epoch 6/24\n",
            "----------\n",
            "train Loss: 0.6594 Acc: 0.7442\n",
            "val Loss: 277.2120 Acc: 0.2169\n",
            "\n",
            "Epoch 7/24\n",
            "----------\n",
            "train Loss: 0.6028 Acc: 0.7714\n",
            "val Loss: 512.3234 Acc: 0.4669\n",
            "\n",
            "Epoch 8/24\n",
            "----------\n",
            "train Loss: 0.5748 Acc: 0.7777\n",
            "val Loss: 646.2720 Acc: 0.4026\n",
            "\n",
            "Epoch 9/24\n",
            "----------\n",
            "train Loss: 0.5103 Acc: 0.8055\n",
            "val Loss: 1529.5891 Acc: 0.1397\n",
            "\n",
            "Epoch 10/24\n",
            "----------\n",
            "train Loss: 0.4530 Acc: 0.8307\n",
            "val Loss: 1500.4126 Acc: 0.1397\n",
            "\n",
            "Epoch 11/24\n",
            "----------\n",
            "train Loss: 0.3966 Acc: 0.8566\n",
            "val Loss: 1331.8796 Acc: 0.1397\n",
            "\n",
            "Epoch 12/24\n",
            "----------\n",
            "train Loss: 0.3853 Acc: 0.8589\n",
            "val Loss: 1452.8509 Acc: 0.1415\n",
            "\n",
            "Epoch 13/24\n",
            "----------\n",
            "train Loss: 0.3428 Acc: 0.8759\n",
            "val Loss: 1445.3858 Acc: 0.1397\n",
            "\n",
            "Epoch 14/24\n",
            "----------\n",
            "train Loss: 0.3453 Acc: 0.8755\n",
            "val Loss: 1211.5969 Acc: 0.1415\n",
            "\n",
            "Epoch 15/24\n",
            "----------\n",
            "train Loss: 0.3308 Acc: 0.8783\n",
            "val Loss: 1722.8007 Acc: 0.1397\n",
            "\n",
            "Epoch 16/24\n",
            "----------\n",
            "train Loss: 0.3044 Acc: 0.8863\n",
            "val Loss: 1709.3928 Acc: 0.1397\n",
            "\n",
            "Epoch 17/24\n",
            "----------\n",
            "train Loss: 0.3029 Acc: 0.8912\n",
            "val Loss: 1600.9623 Acc: 0.1415\n",
            "\n",
            "Epoch 18/24\n",
            "----------\n",
            "train Loss: 0.2805 Acc: 0.8992\n",
            "val Loss: 1444.9363 Acc: 0.1415\n",
            "\n",
            "Epoch 19/24\n",
            "----------\n",
            "train Loss: 0.2756 Acc: 0.9004\n",
            "val Loss: 1605.5196 Acc: 0.1415\n",
            "\n",
            "Epoch 20/24\n",
            "----------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-cc88ea5f8bd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n\u001b[0m\u001b[1;32m      2\u001b[0m                        num_epochs=25)\n",
            "\u001b[0;32m<ipython-input-24-93acec95e350>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;31m# Iterate over data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1316\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1317\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1280\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1281\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1282\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1283\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1118\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1120\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1121\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Save the best model\n",
        "# torch.save(model_ft.state_dict(), save_models_dir+'best_resnet50_equalhist.pt')"
      ],
      "metadata": {
        "id": "U2pTvl2smqo1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## With new histogram equalization (normalization)"
      ],
      "metadata": {
        "id": "9wPc0wNJerlx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft = models.resnet50(weights=\"DEFAULT\")\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "\n",
        "model_ft.fc = nn.Linear(num_ftrs, 5)\n",
        "\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.0001)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 10 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)"
      ],
      "metadata": {
        "id": "F8VtqWvherly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
        "                       num_epochs=25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea423383-c8b7-4565-9faa-16d4412e7dbe",
        "id": "Cra53EDCerlz"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/24\n",
            "----------\n",
            "train Loss: 1.2436 Acc: 0.4663\n",
            "val Loss: 0.9684 Acc: 0.6121\n",
            "\n",
            "Epoch 1/24\n",
            "----------\n",
            "train Loss: 0.9368 Acc: 0.6305\n",
            "val Loss: 0.8178 Acc: 0.6820\n",
            "\n",
            "Epoch 2/24\n",
            "----------\n",
            "train Loss: 0.8315 Acc: 0.6693\n",
            "val Loss: 0.7916 Acc: 0.6838\n",
            "\n",
            "Epoch 3/24\n",
            "----------\n",
            "train Loss: 0.7551 Acc: 0.7041\n",
            "val Loss: 0.7108 Acc: 0.7151\n",
            "\n",
            "Epoch 4/24\n",
            "----------\n",
            "train Loss: 0.6817 Acc: 0.7335\n",
            "val Loss: 0.6228 Acc: 0.7647\n",
            "\n",
            "Epoch 5/24\n",
            "----------\n",
            "train Loss: 0.6406 Acc: 0.7474\n",
            "val Loss: 0.7299 Acc: 0.7298\n",
            "\n",
            "Epoch 6/24\n",
            "----------\n",
            "train Loss: 0.5604 Acc: 0.7869\n",
            "val Loss: 0.7191 Acc: 0.7500\n",
            "\n",
            "Epoch 7/24\n",
            "----------\n",
            "train Loss: 0.5231 Acc: 0.7988\n",
            "val Loss: 0.6833 Acc: 0.7500\n",
            "\n",
            "Epoch 8/24\n",
            "----------\n",
            "train Loss: 0.5019 Acc: 0.8127\n",
            "val Loss: 0.7136 Acc: 0.7555\n",
            "\n",
            "Epoch 9/24\n",
            "----------\n",
            "train Loss: 0.4617 Acc: 0.8243\n",
            "val Loss: 0.7582 Acc: 0.7482\n",
            "\n",
            "Epoch 10/24\n",
            "----------\n",
            "train Loss: 0.3729 Acc: 0.8626\n",
            "val Loss: 0.7297 Acc: 0.7500\n",
            "\n",
            "Epoch 11/24\n",
            "----------\n",
            "train Loss: 0.3574 Acc: 0.8724\n",
            "val Loss: 0.7190 Acc: 0.7500\n",
            "\n",
            "Epoch 12/24\n",
            "----------\n",
            "train Loss: 0.3160 Acc: 0.8875\n",
            "val Loss: 0.7246 Acc: 0.7610\n",
            "\n",
            "Epoch 13/24\n",
            "----------\n",
            "train Loss: 0.3200 Acc: 0.8857\n",
            "val Loss: 0.7240 Acc: 0.7647\n",
            "\n",
            "Epoch 14/24\n",
            "----------\n",
            "train Loss: 0.3034 Acc: 0.8894\n",
            "val Loss: 0.7453 Acc: 0.7574\n",
            "\n",
            "Epoch 15/24\n",
            "----------\n",
            "train Loss: 0.2941 Acc: 0.8881\n",
            "val Loss: 0.7578 Acc: 0.7390\n",
            "\n",
            "Epoch 16/24\n",
            "----------\n",
            "train Loss: 0.2746 Acc: 0.9037\n",
            "val Loss: 0.7722 Acc: 0.7500\n",
            "\n",
            "Epoch 17/24\n",
            "----------\n",
            "train Loss: 0.2505 Acc: 0.9117\n",
            "val Loss: 0.7787 Acc: 0.7500\n",
            "\n",
            "Epoch 18/24\n",
            "----------\n",
            "train Loss: 0.2539 Acc: 0.9086\n",
            "val Loss: 0.7714 Acc: 0.7426\n",
            "\n",
            "Epoch 19/24\n",
            "----------\n",
            "train Loss: 0.2388 Acc: 0.9110\n",
            "val Loss: 0.7671 Acc: 0.7500\n",
            "\n",
            "Epoch 20/24\n",
            "----------\n",
            "train Loss: 0.2318 Acc: 0.9192\n",
            "val Loss: 0.7707 Acc: 0.7463\n",
            "\n",
            "Epoch 21/24\n",
            "----------\n",
            "train Loss: 0.2225 Acc: 0.9227\n",
            "val Loss: 0.7658 Acc: 0.7592\n",
            "\n",
            "Epoch 22/24\n",
            "----------\n",
            "train Loss: 0.2342 Acc: 0.9168\n",
            "val Loss: 0.7786 Acc: 0.7390\n",
            "\n",
            "Epoch 23/24\n",
            "----------\n",
            "train Loss: 0.2398 Acc: 0.9143\n",
            "val Loss: 0.7612 Acc: 0.7445\n",
            "\n",
            "Epoch 24/24\n",
            "----------\n",
            "train Loss: 0.2260 Acc: 0.9184\n",
            "val Loss: 0.7699 Acc: 0.7592\n",
            "\n",
            "Training complete in 36m 42s\n",
            "Best val Acc: 0.764706\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # Save the best model\n",
        "# torch.save(model_ft.state_dict(), save_models_dir+'best_resnet50_equalhist.pt')"
      ],
      "metadata": {
        "id": "jkA9nHc5erl0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-phase training approach with progressive unfreezing of layers"
      ],
      "metadata": {
        "id": "0-7jD_dvo9Tz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stage 1"
      ],
      "metadata": {
        "id": "1CT3SvMYo9T0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet50_model = models.resnet50(weights=\"DEFAULT\")\n",
        "\n",
        "# Freeze all parameters...except for the final layer\n",
        "for param in resnet50_model.parameters():\n",
        "    param.requires_grad = False\n",
        "num_ftrs = resnet50_model.fc.in_features\n",
        "resnet50_model.fc = nn.Linear(num_ftrs, 5)\n",
        "\n",
        "resnet50_model = resnet50_model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized --> change for each stage\n",
        "optimizer = optim.Adam(resnet50_model.parameters(), lr=0.001)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 10 epochs\n",
        "# If don't want to decay, then set the step_size to very high\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "399e790ee6434131a11cd670c93c14b2",
            "a9026ac38af14bd5bb862bf6c236b2c3",
            "58d74f10886c456c9c1094df0ff59502",
            "ca3a687ff63b43008a7386bf9d72eff0",
            "bd1470f7b8e743feb82d74c6e2810781",
            "5e40f4cc5f314e0d8c05a4f42d15fb40",
            "341bc14768844a95825250cf48162363",
            "9e95baf628ff4c5fb0e75f52b3221a05",
            "a17bfa7fef464e4a9bd63bde7eec0cd0",
            "a7ac05b417ac456fa41e2ff177d5b532",
            "43d02b09a14245c485d135f72f82657b"
          ]
        },
        "id": "9iQ8VVXto9T1",
        "outputId": "840fc6d4-e2a1-4c95-b727-66f6340974ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "399e790ee6434131a11cd670c93c14b2"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resnet50_model = train_model(resnet50_model, criterion, optimizer, exp_lr_scheduler,\n",
        "                       num_epochs=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47a51aa3-fb5d-4af0-9b8d-1191dd64ffd3",
        "id": "j92HIAWdo9T1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/2\n",
            "----------\n",
            "train Loss: 1.4431 Acc: 0.3933\n",
            "val Loss: 1.2371 Acc: 0.5368\n",
            "\n",
            "Epoch 1/2\n",
            "----------\n",
            "train Loss: 1.3161 Acc: 0.4605\n",
            "val Loss: 1.1856 Acc: 0.5312\n",
            "\n",
            "Epoch 2/2\n",
            "----------\n",
            "train Loss: 1.2868 Acc: 0.4769\n",
            "val Loss: 1.1716 Acc: 0.5441\n",
            "\n",
            "Training complete in 4m 4s\n",
            "Best val Acc: 0.544118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stage 2"
      ],
      "metadata": {
        "id": "fgOaNrNio9T2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For simplicity, first unfreeze all layers\n",
        "for param in resnet50_model.parameters():\n",
        "    param.requires_grad = True"
      ],
      "metadata": {
        "id": "Cdbv_fp_o9T3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet50_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a7a9163-8b0b-4d4c-a19c-b6ada03770df",
        "id": "EZXh4ckdo9T4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=2048, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "layer_count = 0\n",
        "for child in resnet50_model.children():\n",
        "  print(\"Child \", layer_count)\n",
        "  print(child)\n",
        "  children_of_child_counter = 0\n",
        "  for children_of_child in child.children():\n",
        "    print(\"child \", children_of_child_counter, \"of child\", layer_count)\n",
        "    print(children_of_child)\n",
        "    children_of_child_counter += 1 \n",
        "  layer_count += 1\n",
        "\n",
        "# print(\"total layers: \", layer_count)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf7dfda1-68a4-414a-e24a-290e8681d780",
        "id": "h8Jjqhllo9T4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Child  0\n",
            "Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "Child  1\n",
            "BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Child  2\n",
            "ReLU(inplace=True)\n",
            "Child  3\n",
            "MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "Child  4\n",
            "Sequential(\n",
            "  (0): Bottleneck(\n",
            "    (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (downsample): Sequential(\n",
            "      (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (1): Bottleneck(\n",
            "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "  )\n",
            "  (2): Bottleneck(\n",
            "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "  )\n",
            ")\n",
            "child  0 of child 4\n",
            "Bottleneck(\n",
            "  (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (downsample): Sequential(\n",
            "    (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            ")\n",
            "child  1 of child 4\n",
            "Bottleneck(\n",
            "  (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            ")\n",
            "child  2 of child 4\n",
            "Bottleneck(\n",
            "  (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            ")\n",
            "Child  5\n",
            "Sequential(\n",
            "  (0): Bottleneck(\n",
            "    (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (downsample): Sequential(\n",
            "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (1): Bottleneck(\n",
            "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "  )\n",
            "  (2): Bottleneck(\n",
            "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "  )\n",
            "  (3): Bottleneck(\n",
            "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "  )\n",
            ")\n",
            "child  0 of child 5\n",
            "Bottleneck(\n",
            "  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (downsample): Sequential(\n",
            "    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            ")\n",
            "child  1 of child 5\n",
            "Bottleneck(\n",
            "  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            ")\n",
            "child  2 of child 5\n",
            "Bottleneck(\n",
            "  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            ")\n",
            "child  3 of child 5\n",
            "Bottleneck(\n",
            "  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            ")\n",
            "Child  6\n",
            "Sequential(\n",
            "  (0): Bottleneck(\n",
            "    (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (downsample): Sequential(\n",
            "      (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (1): Bottleneck(\n",
            "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "  )\n",
            "  (2): Bottleneck(\n",
            "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "  )\n",
            "  (3): Bottleneck(\n",
            "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "  )\n",
            "  (4): Bottleneck(\n",
            "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "  )\n",
            "  (5): Bottleneck(\n",
            "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "  )\n",
            ")\n",
            "child  0 of child 6\n",
            "Bottleneck(\n",
            "  (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (downsample): Sequential(\n",
            "    (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            ")\n",
            "child  1 of child 6\n",
            "Bottleneck(\n",
            "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            ")\n",
            "child  2 of child 6\n",
            "Bottleneck(\n",
            "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            ")\n",
            "child  3 of child 6\n",
            "Bottleneck(\n",
            "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            ")\n",
            "child  4 of child 6\n",
            "Bottleneck(\n",
            "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            ")\n",
            "child  5 of child 6\n",
            "Bottleneck(\n",
            "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            ")\n",
            "Child  7\n",
            "Sequential(\n",
            "  (0): Bottleneck(\n",
            "    (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (downsample): Sequential(\n",
            "      (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (1): Bottleneck(\n",
            "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "  )\n",
            "  (2): Bottleneck(\n",
            "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "  )\n",
            ")\n",
            "child  0 of child 7\n",
            "Bottleneck(\n",
            "  (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (downsample): Sequential(\n",
            "    (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            ")\n",
            "child  1 of child 7\n",
            "Bottleneck(\n",
            "  (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            ")\n",
            "child  2 of child 7\n",
            "Bottleneck(\n",
            "  (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            ")\n",
            "Child  8\n",
            "AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "Child  9\n",
            "Linear(in_features=2048, out_features=5, bias=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now selectively freeze layers\n",
        "child_counter = 0\n",
        "for child in resnet50_model.children():\n",
        "  if child_counter < 7:\n",
        "    print(\"child\", child_counter, \"was frozen\")\n",
        "    for param in child.parameters():\n",
        "      param.requires_grad = False\n",
        "  elif child_counter == 7:\n",
        "    children_of_child_counter = 0\n",
        "    for children_of_child in child.children():\n",
        "      if children_of_child_counter < 2:\n",
        "        for param in children_of_child.parameters():\n",
        "          param.requires_grad = False\n",
        "        print(\"child\", children_of_child_counter, \"of child\", child_counter, \"was frozen\")\n",
        "      else:\n",
        "        print('child ', children_of_child_counter, 'of child',child_counter,' was not frozen')\n",
        "      children_of_child_counter += 1\n",
        "  else:\n",
        "    print(\"child \",child_counter,\" was not frozen\")\n",
        "  child_counter += 1\n",
        "    \n",
        "    # print(\"child \",child_counter,\" was frozen\")\n",
        "    # for param in child.parameters():\n",
        "    #     param.requires_grad = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45bc2ad5-16ad-4850-d67a-84dbdc808bf8",
        "id": "hHkhn3iMo9T5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "child 0 was frozen\n",
            "child 1 was frozen\n",
            "child 2 was frozen\n",
            "child 3 was frozen\n",
            "child 4 was frozen\n",
            "child 5 was frozen\n",
            "child 6 was frozen\n",
            "child 0 of child 7 was frozen\n",
            "child 1 of child 7 was frozen\n",
            "child  2 of child 7  was not frozen\n",
            "child  8  was not frozen\n",
            "child  9  was not frozen\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resnet50_model = resnet50_model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized --> change for each stage\n",
        "optimizer = optim.Adam(resnet50_model.parameters(), lr=0.0001)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 10 epochs\n",
        "# If don't want to decay, then set the step_size to very high\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=11, gamma=0.1)"
      ],
      "metadata": {
        "id": "hZ3EtAHfo9T6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet50_model = train_model(resnet50_model, criterion, optimizer, exp_lr_scheduler,\n",
        "                       num_epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3bd44cd-42bf-4832-853e-7f2c3e342cd5",
        "id": "ZuIJmzReo9T7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/9\n",
            "----------\n",
            "train Loss: 1.1914 Acc: 0.5307\n",
            "val Loss: 1.0674 Acc: 0.5827\n",
            "\n",
            "Epoch 1/9\n",
            "----------\n",
            "train Loss: 1.1433 Acc: 0.5366\n",
            "val Loss: 1.0331 Acc: 0.6066\n",
            "\n",
            "Epoch 2/9\n",
            "----------\n",
            "train Loss: 1.1083 Acc: 0.5487\n",
            "val Loss: 1.0304 Acc: 0.5974\n",
            "\n",
            "Epoch 3/9\n",
            "----------\n",
            "train Loss: 1.0801 Acc: 0.5579\n",
            "val Loss: 1.0193 Acc: 0.6268\n",
            "\n",
            "Epoch 4/9\n",
            "----------\n",
            "train Loss: 1.0202 Acc: 0.5849\n",
            "val Loss: 0.9306 Acc: 0.6287\n",
            "\n",
            "Epoch 5/9\n",
            "----------\n",
            "train Loss: 1.0037 Acc: 0.5988\n",
            "val Loss: 0.9270 Acc: 0.6232\n",
            "\n",
            "Epoch 6/9\n",
            "----------\n",
            "train Loss: 0.9851 Acc: 0.6092\n",
            "val Loss: 0.9268 Acc: 0.6268\n",
            "\n",
            "Epoch 7/9\n",
            "----------\n",
            "train Loss: 0.9685 Acc: 0.6172\n",
            "val Loss: 0.9372 Acc: 0.6397\n",
            "\n",
            "Epoch 8/9\n",
            "----------\n",
            "train Loss: 0.9616 Acc: 0.6125\n",
            "val Loss: 0.9039 Acc: 0.6489\n",
            "\n",
            "Epoch 9/9\n",
            "----------\n",
            "train Loss: 0.9448 Acc: 0.6258\n",
            "val Loss: 0.9171 Acc: 0.6305\n",
            "\n",
            "Training complete in 13m 9s\n",
            "Best val Acc: 0.648897\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stage 3"
      ],
      "metadata": {
        "id": "N4ViKT6Co9T8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Unfreeze all parameters\n",
        "for param in resnet50_model.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "resnet50_model = resnet50_model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized --> change for each stage\n",
        "optimizer = optim.Adam(resnet50_model.parameters(), lr=0.00001)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 10 epochs\n",
        "# If don't want to decay, then set the step_size to very high\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)"
      ],
      "metadata": {
        "id": "T5-5zGLKo9T8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet50_model = train_model(resnet50_model, criterion, optimizer, exp_lr_scheduler,\n",
        "                       num_epochs=37)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37f07c34-f257-4cc0-ac6d-c4d4b029d3f1",
        "id": "E65N2UPbo9T9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/36\n",
            "----------\n",
            "train Loss: 0.8716 Acc: 0.6532\n",
            "val Loss: 0.8317 Acc: 0.6599\n",
            "\n",
            "Epoch 1/36\n",
            "----------\n",
            "train Loss: 0.8595 Acc: 0.6679\n",
            "val Loss: 0.8484 Acc: 0.6673\n",
            "\n",
            "Epoch 2/36\n",
            "----------\n",
            "train Loss: 0.8024 Acc: 0.6828\n",
            "val Loss: 0.7976 Acc: 0.6746\n",
            "\n",
            "Epoch 3/36\n",
            "----------\n",
            "train Loss: 0.7816 Acc: 0.6883\n",
            "val Loss: 0.7721 Acc: 0.7096\n",
            "\n",
            "Epoch 4/36\n",
            "----------\n",
            "train Loss: 0.7671 Acc: 0.7006\n",
            "val Loss: 0.7608 Acc: 0.7132\n",
            "\n",
            "Epoch 5/36\n",
            "----------\n",
            "train Loss: 0.7522 Acc: 0.7004\n",
            "val Loss: 0.7432 Acc: 0.7224\n",
            "\n",
            "Epoch 6/36\n",
            "----------\n",
            "train Loss: 0.7281 Acc: 0.7178\n",
            "val Loss: 0.7183 Acc: 0.7298\n",
            "\n",
            "Epoch 7/36\n",
            "----------\n",
            "train Loss: 0.7030 Acc: 0.7160\n",
            "val Loss: 0.7336 Acc: 0.7206\n",
            "\n",
            "Epoch 8/36\n",
            "----------\n",
            "train Loss: 0.6744 Acc: 0.7399\n",
            "val Loss: 0.7237 Acc: 0.7371\n",
            "\n",
            "Epoch 9/36\n",
            "----------\n",
            "train Loss: 0.7010 Acc: 0.7219\n",
            "val Loss: 0.7185 Acc: 0.7316\n",
            "\n",
            "Epoch 10/36\n",
            "----------\n",
            "train Loss: 0.6352 Acc: 0.7452\n",
            "val Loss: 0.7222 Acc: 0.7279\n",
            "\n",
            "Epoch 11/36\n",
            "----------\n",
            "train Loss: 0.6518 Acc: 0.7454\n",
            "val Loss: 0.7224 Acc: 0.7298\n",
            "\n",
            "Epoch 12/36\n",
            "----------\n",
            "train Loss: 0.6321 Acc: 0.7603\n",
            "val Loss: 0.6815 Acc: 0.7463\n",
            "\n",
            "Epoch 13/36\n",
            "----------\n",
            "train Loss: 0.6219 Acc: 0.7536\n",
            "val Loss: 0.7012 Acc: 0.7426\n",
            "\n",
            "Epoch 14/36\n",
            "----------\n",
            "train Loss: 0.6127 Acc: 0.7550\n",
            "val Loss: 0.7004 Acc: 0.7574\n",
            "\n",
            "Epoch 15/36\n",
            "----------\n",
            "train Loss: 0.5671 Acc: 0.7765\n",
            "val Loss: 0.7023 Acc: 0.7371\n",
            "\n",
            "Epoch 16/36\n",
            "----------\n",
            "train Loss: 0.5676 Acc: 0.7740\n",
            "val Loss: 0.6586 Acc: 0.7629\n",
            "\n",
            "Epoch 17/36\n",
            "----------\n",
            "train Loss: 0.5430 Acc: 0.7859\n",
            "val Loss: 0.7118 Acc: 0.7390\n",
            "\n",
            "Epoch 18/36\n",
            "----------\n",
            "train Loss: 0.5393 Acc: 0.7920\n",
            "val Loss: 0.6817 Acc: 0.7445\n",
            "\n",
            "Epoch 19/36\n",
            "----------\n",
            "train Loss: 0.5206 Acc: 0.8016\n",
            "val Loss: 0.6752 Acc: 0.7537\n",
            "\n",
            "Epoch 20/36\n",
            "----------\n",
            "train Loss: 0.5103 Acc: 0.8029\n",
            "val Loss: 0.7016 Acc: 0.7500\n",
            "\n",
            "Epoch 21/36\n",
            "----------\n",
            "train Loss: 0.4911 Acc: 0.8070\n",
            "val Loss: 0.6472 Acc: 0.7537\n",
            "\n",
            "Epoch 22/36\n",
            "----------\n",
            "train Loss: 0.4938 Acc: 0.8094\n",
            "val Loss: 0.6673 Acc: 0.7537\n",
            "\n",
            "Epoch 23/36\n",
            "----------\n",
            "train Loss: 0.4932 Acc: 0.8065\n",
            "val Loss: 0.6484 Acc: 0.7721\n",
            "\n",
            "Epoch 24/36\n",
            "----------\n",
            "train Loss: 0.4737 Acc: 0.8151\n",
            "val Loss: 0.6705 Acc: 0.7629\n",
            "\n",
            "Epoch 25/36\n",
            "----------\n",
            "train Loss: 0.4337 Acc: 0.8301\n",
            "val Loss: 0.6660 Acc: 0.7721\n",
            "\n",
            "Epoch 26/36\n",
            "----------\n",
            "train Loss: 0.4549 Acc: 0.8198\n",
            "val Loss: 0.6825 Acc: 0.7647\n",
            "\n",
            "Epoch 27/36\n",
            "----------\n",
            "train Loss: 0.4256 Acc: 0.8286\n",
            "val Loss: 0.6723 Acc: 0.7757\n",
            "\n",
            "Epoch 28/36\n",
            "----------\n",
            "train Loss: 0.4139 Acc: 0.8421\n",
            "val Loss: 0.6779 Acc: 0.7574\n",
            "\n",
            "Epoch 29/36\n",
            "----------\n",
            "train Loss: 0.4094 Acc: 0.8395\n",
            "val Loss: 0.6812 Acc: 0.7831\n",
            "\n",
            "Epoch 30/36\n",
            "----------\n",
            "train Loss: 0.3956 Acc: 0.8462\n",
            "val Loss: 0.6484 Acc: 0.7886\n",
            "\n",
            "Epoch 31/36\n",
            "----------\n",
            "train Loss: 0.3864 Acc: 0.8534\n",
            "val Loss: 0.6589 Acc: 0.7868\n",
            "\n",
            "Epoch 32/36\n",
            "----------\n",
            "train Loss: 0.3738 Acc: 0.8605\n",
            "val Loss: 0.6551 Acc: 0.7794\n",
            "\n",
            "Epoch 33/36\n",
            "----------\n",
            "train Loss: 0.3614 Acc: 0.8630\n",
            "val Loss: 0.6816 Acc: 0.7849\n",
            "\n",
            "Epoch 34/36\n",
            "----------\n",
            "train Loss: 0.3569 Acc: 0.8618\n",
            "val Loss: 0.6912 Acc: 0.7684\n",
            "\n",
            "Epoch 35/36\n",
            "----------\n",
            "train Loss: 0.3406 Acc: 0.8787\n",
            "val Loss: 0.6957 Acc: 0.7776\n",
            "\n",
            "Epoch 36/36\n",
            "----------\n",
            "train Loss: 0.3332 Acc: 0.8753\n",
            "val Loss: 0.6999 Acc: 0.7739\n",
            "\n",
            "Training complete in 53m 26s\n",
            "Best val Acc: 0.788603\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the best model --> checkpoint\n",
        "torch.save(resnet50_model.state_dict(), \n",
        "           save_models_dir + \"best_resnet50_multistage_train.pt\")"
      ],
      "metadata": {
        "id": "RTMXKFq6o9T9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Continue with the above, so going to 100 epochs"
      ],
      "metadata": {
        "id": "-9s87iOXo9T-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet50_model = train_model(resnet50_model, criterion, optimizer, exp_lr_scheduler,\n",
        "                       num_epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9535bc35-ffb9-485b-8b87-bdee13b45179",
        "id": "k0PByKpCo9T-"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/49\n",
            "----------\n",
            "train Loss: 0.4078 Acc: 0.8476\n",
            "val Loss: 0.6840 Acc: 0.7586\n",
            "\n",
            "Epoch 1/49\n",
            "----------\n",
            "train Loss: 0.3722 Acc: 0.8627\n",
            "val Loss: 0.6709 Acc: 0.7622\n",
            "\n",
            "Epoch 2/49\n",
            "----------\n",
            "train Loss: 0.3637 Acc: 0.8668\n",
            "val Loss: 0.6854 Acc: 0.7611\n",
            "\n",
            "Epoch 3/49\n",
            "----------\n",
            "train Loss: 0.3626 Acc: 0.8653\n",
            "val Loss: 0.6646 Acc: 0.7648\n",
            "\n",
            "Epoch 4/49\n",
            "----------\n",
            "train Loss: 0.3472 Acc: 0.8800\n",
            "val Loss: 0.6832 Acc: 0.7670\n",
            "\n",
            "Epoch 5/49\n",
            "----------\n",
            "train Loss: 0.3416 Acc: 0.8734\n",
            "val Loss: 0.6845 Acc: 0.7644\n",
            "\n",
            "Epoch 6/49\n",
            "----------\n",
            "train Loss: 0.3365 Acc: 0.8763\n",
            "val Loss: 0.7069 Acc: 0.7667\n",
            "\n",
            "Epoch 7/49\n",
            "----------\n",
            "train Loss: 0.3579 Acc: 0.8671\n",
            "val Loss: 0.6753 Acc: 0.7696\n",
            "\n",
            "Epoch 8/49\n",
            "----------\n",
            "train Loss: 0.3174 Acc: 0.8837\n",
            "val Loss: 0.7006 Acc: 0.7637\n",
            "\n",
            "Epoch 9/49\n",
            "----------\n",
            "train Loss: 0.3093 Acc: 0.8929\n",
            "val Loss: 0.6888 Acc: 0.7755\n",
            "\n",
            "Epoch 10/49\n",
            "----------\n",
            "train Loss: 0.2931 Acc: 0.8914\n",
            "val Loss: 0.7001 Acc: 0.7648\n",
            "\n",
            "Epoch 11/49\n",
            "----------\n",
            "train Loss: 0.2829 Acc: 0.8966\n",
            "val Loss: 0.7060 Acc: 0.7703\n",
            "\n",
            "Epoch 12/49\n",
            "----------\n",
            "train Loss: 0.2733 Acc: 0.9028\n",
            "val Loss: 0.6913 Acc: 0.7762\n",
            "\n",
            "Epoch 13/49\n",
            "----------\n",
            "train Loss: 0.2638 Acc: 0.9054\n",
            "val Loss: 0.7001 Acc: 0.7703\n",
            "\n",
            "Epoch 14/49\n",
            "----------\n",
            "train Loss: 0.2735 Acc: 0.9032\n",
            "val Loss: 0.7053 Acc: 0.7740\n",
            "\n",
            "Epoch 15/49\n",
            "----------\n",
            "train Loss: 0.2575 Acc: 0.9106\n",
            "val Loss: 0.7048 Acc: 0.7725\n",
            "\n",
            "Epoch 16/49\n",
            "----------\n",
            "train Loss: 0.2650 Acc: 0.8980\n",
            "val Loss: 0.7145 Acc: 0.7714\n",
            "\n",
            "Epoch 17/49\n",
            "----------\n",
            "train Loss: 0.2670 Acc: 0.9039\n",
            "val Loss: 0.7099 Acc: 0.7736\n",
            "\n",
            "Epoch 18/49\n",
            "----------\n",
            "train Loss: 0.2809 Acc: 0.8929\n",
            "val Loss: 0.7075 Acc: 0.7744\n",
            "\n",
            "Epoch 19/49\n",
            "----------\n",
            "train Loss: 0.2651 Acc: 0.9084\n",
            "val Loss: 0.7104 Acc: 0.7718\n",
            "\n",
            "Epoch 20/49\n",
            "----------\n",
            "train Loss: 0.2517 Acc: 0.9165\n",
            "val Loss: 0.7088 Acc: 0.7707\n",
            "\n",
            "Epoch 21/49\n",
            "----------\n",
            "train Loss: 0.2655 Acc: 0.9065\n",
            "val Loss: 0.7112 Acc: 0.7718\n",
            "\n",
            "Epoch 22/49\n",
            "----------\n",
            "train Loss: 0.2461 Acc: 0.9153\n",
            "val Loss: 0.7125 Acc: 0.7722\n",
            "\n",
            "Epoch 23/49\n",
            "----------\n",
            "train Loss: 0.2376 Acc: 0.9176\n",
            "val Loss: 0.7149 Acc: 0.7707\n",
            "\n",
            "Epoch 24/49\n",
            "----------\n",
            "train Loss: 0.2680 Acc: 0.9006\n",
            "val Loss: 0.7053 Acc: 0.7748\n",
            "\n",
            "Epoch 25/49\n",
            "----------\n",
            "train Loss: 0.2574 Acc: 0.9039\n",
            "val Loss: 0.7065 Acc: 0.7759\n",
            "\n",
            "Epoch 26/49\n",
            "----------\n",
            "train Loss: 0.2527 Acc: 0.9095\n",
            "val Loss: 0.7098 Acc: 0.7755\n",
            "\n",
            "Epoch 27/49\n",
            "----------\n",
            "train Loss: 0.2529 Acc: 0.9102\n",
            "val Loss: 0.7110 Acc: 0.7766\n",
            "\n",
            "Epoch 28/49\n",
            "----------\n",
            "train Loss: 0.2734 Acc: 0.9003\n",
            "val Loss: 0.7193 Acc: 0.7659\n",
            "\n",
            "Epoch 29/49\n",
            "----------\n",
            "train Loss: 0.2430 Acc: 0.9216\n",
            "val Loss: 0.7121 Acc: 0.7722\n",
            "\n",
            "Epoch 30/49\n",
            "----------\n",
            "train Loss: 0.2371 Acc: 0.9150\n",
            "val Loss: 0.7119 Acc: 0.7751\n",
            "\n",
            "Epoch 31/49\n",
            "----------\n",
            "train Loss: 0.2492 Acc: 0.9113\n",
            "val Loss: 0.7104 Acc: 0.7725\n",
            "\n",
            "Epoch 32/49\n",
            "----------\n",
            "train Loss: 0.2624 Acc: 0.9084\n",
            "val Loss: 0.7087 Acc: 0.7733\n",
            "\n",
            "Epoch 33/49\n",
            "----------\n",
            "train Loss: 0.2482 Acc: 0.9153\n",
            "val Loss: 0.7119 Acc: 0.7707\n",
            "\n",
            "Epoch 34/49\n",
            "----------\n",
            "train Loss: 0.2418 Acc: 0.9168\n",
            "val Loss: 0.7263 Acc: 0.7648\n",
            "\n",
            "Epoch 35/49\n",
            "----------\n",
            "train Loss: 0.2363 Acc: 0.9172\n",
            "val Loss: 0.7191 Acc: 0.7659\n",
            "\n",
            "Epoch 36/49\n",
            "----------\n",
            "train Loss: 0.2574 Acc: 0.9098\n",
            "val Loss: 0.7122 Acc: 0.7751\n",
            "\n",
            "Epoch 37/49\n",
            "----------\n",
            "train Loss: 0.2173 Acc: 0.9297\n",
            "val Loss: 0.7066 Acc: 0.7773\n",
            "\n",
            "Epoch 38/49\n",
            "----------\n",
            "train Loss: 0.2210 Acc: 0.9260\n",
            "val Loss: 0.7085 Acc: 0.7718\n",
            "\n",
            "Epoch 39/49\n",
            "----------\n",
            "train Loss: 0.2419 Acc: 0.9153\n",
            "val Loss: 0.7229 Acc: 0.7714\n",
            "\n",
            "Epoch 40/49\n",
            "----------\n",
            "train Loss: 0.2314 Acc: 0.9179\n",
            "val Loss: 0.7166 Acc: 0.7736\n",
            "\n",
            "Epoch 41/49\n",
            "----------\n",
            "train Loss: 0.2437 Acc: 0.9139\n",
            "val Loss: 0.7198 Acc: 0.7777\n",
            "\n",
            "Epoch 42/49\n",
            "----------\n",
            "train Loss: 0.2317 Acc: 0.9205\n",
            "val Loss: 0.7148 Acc: 0.7792\n",
            "\n",
            "Epoch 43/49\n",
            "----------\n",
            "train Loss: 0.2368 Acc: 0.9172\n",
            "val Loss: 0.7157 Acc: 0.7711\n",
            "\n",
            "Epoch 44/49\n",
            "----------\n",
            "train Loss: 0.2388 Acc: 0.9172\n",
            "val Loss: 0.7212 Acc: 0.7792\n",
            "\n",
            "Epoch 45/49\n",
            "----------\n",
            "train Loss: 0.2323 Acc: 0.9201\n",
            "val Loss: 0.7143 Acc: 0.7729\n",
            "\n",
            "Epoch 46/49\n",
            "----------\n",
            "train Loss: 0.2446 Acc: 0.9113\n",
            "val Loss: 0.7208 Acc: 0.7714\n",
            "\n",
            "Epoch 47/49\n",
            "----------\n",
            "train Loss: 0.2417 Acc: 0.9128\n",
            "val Loss: 0.7201 Acc: 0.7725\n",
            "\n",
            "Epoch 48/49\n",
            "----------\n",
            "train Loss: 0.2471 Acc: 0.9102\n",
            "val Loss: 0.7176 Acc: 0.7689\n",
            "\n",
            "Epoch 49/49\n",
            "----------\n",
            "train Loss: 0.2295 Acc: 0.9150\n",
            "val Loss: 0.7200 Acc: 0.7725\n",
            "\n",
            "Training complete in 48m 41s\n",
            "Best val Acc: 0.779168\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the best model --> checkpoint\n",
        "torch.save(resnet50_model.state_dict(), \n",
        "           save_models_dir + \"best_resnet50_multistage_train.pt\")"
      ],
      "metadata": {
        "id": "b7UTyfnSo9T-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keep...going...(150 epochs)"
      ],
      "metadata": {
        "id": "iLXG0lYRo9T-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet50_model = train_model(resnet50_model, criterion, optimizer, exp_lr_scheduler,\n",
        "                       num_epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c69a93c3-2cb9-495c-e7e8-9d5c616b5677",
        "id": "o_MDo5Z2o9T_"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/49\n",
            "----------\n",
            "train Loss: 0.2426 Acc: 0.9172\n",
            "val Loss: 0.7228 Acc: 0.7670\n",
            "\n",
            "Epoch 1/49\n",
            "----------\n",
            "train Loss: 0.2324 Acc: 0.9216\n",
            "val Loss: 0.7220 Acc: 0.7692\n",
            "\n",
            "Epoch 2/49\n",
            "----------\n",
            "train Loss: 0.2195 Acc: 0.9264\n",
            "val Loss: 0.7093 Acc: 0.7784\n",
            "\n",
            "Epoch 3/49\n",
            "----------\n",
            "train Loss: 0.2277 Acc: 0.9124\n",
            "val Loss: 0.7207 Acc: 0.7751\n",
            "\n",
            "Epoch 4/49\n",
            "----------\n",
            "train Loss: 0.2209 Acc: 0.9268\n",
            "val Loss: 0.7239 Acc: 0.7652\n",
            "\n",
            "Epoch 5/49\n",
            "----------\n",
            "train Loss: 0.2331 Acc: 0.9220\n",
            "val Loss: 0.7302 Acc: 0.7644\n",
            "\n",
            "Epoch 6/49\n",
            "----------\n",
            "train Loss: 0.2514 Acc: 0.9084\n",
            "val Loss: 0.7318 Acc: 0.7736\n",
            "\n",
            "Epoch 7/49\n",
            "----------\n",
            "train Loss: 0.2234 Acc: 0.9234\n",
            "val Loss: 0.7202 Acc: 0.7722\n",
            "\n",
            "Epoch 8/49\n",
            "----------\n",
            "train Loss: 0.2176 Acc: 0.9290\n",
            "val Loss: 0.7201 Acc: 0.7736\n",
            "\n",
            "Epoch 9/49\n",
            "----------\n",
            "train Loss: 0.2315 Acc: 0.9183\n",
            "val Loss: 0.7291 Acc: 0.7703\n",
            "\n",
            "Epoch 10/49\n",
            "----------\n",
            "train Loss: 0.2199 Acc: 0.9279\n",
            "val Loss: 0.7208 Acc: 0.7788\n",
            "\n",
            "Epoch 11/49\n",
            "----------\n",
            "train Loss: 0.2391 Acc: 0.9165\n",
            "val Loss: 0.7119 Acc: 0.7751\n",
            "\n",
            "Epoch 12/49\n",
            "----------\n",
            "train Loss: 0.2162 Acc: 0.9253\n",
            "val Loss: 0.7250 Acc: 0.7707\n",
            "\n",
            "Epoch 13/49\n",
            "----------\n",
            "train Loss: 0.2155 Acc: 0.9338\n",
            "val Loss: 0.7177 Acc: 0.7729\n",
            "\n",
            "Epoch 14/49\n",
            "----------\n",
            "train Loss: 0.2271 Acc: 0.9190\n",
            "val Loss: 0.7238 Acc: 0.7703\n",
            "\n",
            "Epoch 15/49\n",
            "----------\n",
            "train Loss: 0.1989 Acc: 0.9345\n",
            "val Loss: 0.7212 Acc: 0.7711\n",
            "\n",
            "Epoch 16/49\n",
            "----------\n",
            "train Loss: 0.2272 Acc: 0.9238\n",
            "val Loss: 0.7191 Acc: 0.7718\n",
            "\n",
            "Epoch 17/49\n",
            "----------\n",
            "train Loss: 0.2115 Acc: 0.9271\n",
            "val Loss: 0.7221 Acc: 0.7722\n",
            "\n",
            "Epoch 18/49\n",
            "----------\n",
            "train Loss: 0.2139 Acc: 0.9253\n",
            "val Loss: 0.7345 Acc: 0.7689\n",
            "\n",
            "Epoch 19/49\n",
            "----------\n",
            "train Loss: 0.2246 Acc: 0.9205\n",
            "val Loss: 0.7245 Acc: 0.7733\n",
            "\n",
            "Epoch 20/49\n",
            "----------\n",
            "train Loss: 0.2288 Acc: 0.9279\n",
            "val Loss: 0.7285 Acc: 0.7773\n",
            "\n",
            "Epoch 21/49\n",
            "----------\n",
            "train Loss: 0.2313 Acc: 0.9187\n",
            "val Loss: 0.7236 Acc: 0.7674\n",
            "\n",
            "Epoch 22/49\n",
            "----------\n",
            "train Loss: 0.2454 Acc: 0.9102\n",
            "val Loss: 0.7368 Acc: 0.7659\n",
            "\n",
            "Epoch 23/49\n",
            "----------\n",
            "train Loss: 0.2226 Acc: 0.9231\n",
            "val Loss: 0.7250 Acc: 0.7770\n",
            "\n",
            "Epoch 24/49\n",
            "----------\n",
            "train Loss: 0.2162 Acc: 0.9301\n",
            "val Loss: 0.7260 Acc: 0.7696\n",
            "\n",
            "Epoch 25/49\n",
            "----------\n",
            "train Loss: 0.2271 Acc: 0.9205\n",
            "val Loss: 0.7301 Acc: 0.7718\n",
            "\n",
            "Epoch 26/49\n",
            "----------\n",
            "train Loss: 0.2061 Acc: 0.9286\n",
            "val Loss: 0.7184 Acc: 0.7722\n",
            "\n",
            "Epoch 27/49\n",
            "----------\n",
            "train Loss: 0.2468 Acc: 0.9065\n",
            "val Loss: 0.7269 Acc: 0.7685\n",
            "\n",
            "Epoch 28/49\n",
            "----------\n",
            "train Loss: 0.2168 Acc: 0.9264\n",
            "val Loss: 0.7197 Acc: 0.7670\n",
            "\n",
            "Epoch 29/49\n",
            "----------\n",
            "train Loss: 0.2392 Acc: 0.9165\n",
            "val Loss: 0.7312 Acc: 0.7711\n",
            "\n",
            "Epoch 30/49\n",
            "----------\n",
            "train Loss: 0.2232 Acc: 0.9198\n",
            "val Loss: 0.7255 Acc: 0.7722\n",
            "\n",
            "Epoch 31/49\n",
            "----------\n",
            "train Loss: 0.2288 Acc: 0.9238\n",
            "val Loss: 0.7279 Acc: 0.7696\n",
            "\n",
            "Epoch 32/49\n",
            "----------\n",
            "train Loss: 0.2264 Acc: 0.9198\n",
            "val Loss: 0.7243 Acc: 0.7689\n",
            "\n",
            "Epoch 33/49\n",
            "----------\n",
            "train Loss: 0.2125 Acc: 0.9293\n",
            "val Loss: 0.7248 Acc: 0.7729\n",
            "\n",
            "Epoch 34/49\n",
            "----------\n",
            "train Loss: 0.2151 Acc: 0.9227\n",
            "val Loss: 0.7263 Acc: 0.7729\n",
            "\n",
            "Epoch 35/49\n",
            "----------\n",
            "train Loss: 0.2059 Acc: 0.9282\n",
            "val Loss: 0.7245 Acc: 0.7678\n",
            "\n",
            "Epoch 36/49\n",
            "----------\n",
            "train Loss: 0.2234 Acc: 0.9238\n",
            "val Loss: 0.7341 Acc: 0.7711\n",
            "\n",
            "Epoch 37/49\n",
            "----------\n",
            "train Loss: 0.2270 Acc: 0.9165\n",
            "val Loss: 0.7272 Acc: 0.7689\n",
            "\n",
            "Epoch 38/49\n",
            "----------\n",
            "train Loss: 0.2301 Acc: 0.9205\n",
            "val Loss: 0.7303 Acc: 0.7718\n",
            "\n",
            "Epoch 39/49\n",
            "----------\n",
            "train Loss: 0.2143 Acc: 0.9201\n",
            "val Loss: 0.7214 Acc: 0.7692\n",
            "\n",
            "Epoch 40/49\n",
            "----------\n",
            "train Loss: 0.2304 Acc: 0.9220\n",
            "val Loss: 0.7228 Acc: 0.7674\n",
            "\n",
            "Epoch 41/49\n",
            "----------\n",
            "train Loss: 0.2253 Acc: 0.9216\n",
            "val Loss: 0.7314 Acc: 0.7685\n",
            "\n",
            "Epoch 42/49\n",
            "----------\n",
            "train Loss: 0.2070 Acc: 0.9282\n",
            "val Loss: 0.7108 Acc: 0.7759\n",
            "\n",
            "Epoch 43/49\n",
            "----------\n",
            "train Loss: 0.2069 Acc: 0.9326\n",
            "val Loss: 0.7287 Acc: 0.7689\n",
            "\n",
            "Epoch 44/49\n",
            "----------\n",
            "train Loss: 0.2093 Acc: 0.9282\n",
            "val Loss: 0.7252 Acc: 0.7711\n",
            "\n",
            "Epoch 45/49\n",
            "----------\n",
            "train Loss: 0.2232 Acc: 0.9231\n",
            "val Loss: 0.7247 Acc: 0.7681\n",
            "\n",
            "Epoch 46/49\n",
            "----------\n",
            "train Loss: 0.2212 Acc: 0.9183\n",
            "val Loss: 0.7298 Acc: 0.7667\n",
            "\n",
            "Epoch 47/49\n",
            "----------\n",
            "train Loss: 0.2235 Acc: 0.9231\n",
            "val Loss: 0.7256 Acc: 0.7711\n",
            "\n",
            "Epoch 48/49\n",
            "----------\n",
            "train Loss: 0.2256 Acc: 0.9194\n",
            "val Loss: 0.7326 Acc: 0.7689\n",
            "\n",
            "Epoch 49/49\n",
            "----------\n",
            "train Loss: 0.2142 Acc: 0.9268\n",
            "val Loss: 0.7189 Acc: 0.7725\n",
            "\n",
            "Training complete in 49m 36s\n",
            "Best val Acc: 0.778800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Is it possible to pop out of a local minima?"
      ],
      "metadata": {
        "id": "BIaRsdRgo9T_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Observe that all parameters are being optimized --> change for each stage\n",
        "optimizer = optim.Adam(resnet50_model.parameters(), lr=0.0001)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 10 epochs\n",
        "# If don't want to decay, then set the step_size to very high\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)"
      ],
      "metadata": {
        "id": "JGJuUnSmo9UA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet50_model = train_model(resnet50_model, criterion, optimizer, exp_lr_scheduler,\n",
        "                       num_epochs=25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef5c6f20-2288-470c-84ca-399de24e3aa1",
        "id": "I-A7-WG3o9UA"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/24\n",
            "----------\n",
            "train Loss: 0.4094 Acc: 0.8439\n",
            "val Loss: 0.8726 Acc: 0.7114\n",
            "\n",
            "Epoch 1/24\n",
            "----------\n",
            "train Loss: 0.4034 Acc: 0.8506\n",
            "val Loss: 0.7413 Acc: 0.7460\n",
            "\n",
            "Epoch 2/24\n",
            "----------\n",
            "train Loss: 0.3636 Acc: 0.8690\n",
            "val Loss: 0.8714 Acc: 0.7111\n",
            "\n",
            "Epoch 3/24\n",
            "----------\n",
            "train Loss: 0.3238 Acc: 0.8815\n",
            "val Loss: 0.7631 Acc: 0.7512\n",
            "\n",
            "Epoch 4/24\n",
            "----------\n",
            "train Loss: 0.2946 Acc: 0.8881\n",
            "val Loss: 0.8012 Acc: 0.7563\n",
            "\n",
            "Epoch 5/24\n",
            "----------\n",
            "train Loss: 0.2676 Acc: 0.9021\n",
            "val Loss: 0.8877 Acc: 0.7446\n",
            "\n",
            "Epoch 6/24\n",
            "----------\n",
            "train Loss: 0.2777 Acc: 0.9017\n",
            "val Loss: 0.7746 Acc: 0.7575\n",
            "\n",
            "Epoch 7/24\n",
            "----------\n",
            "train Loss: 0.2391 Acc: 0.9131\n",
            "val Loss: 0.8625 Acc: 0.7332\n",
            "\n",
            "Epoch 8/24\n",
            "----------\n",
            "train Loss: 0.2177 Acc: 0.9172\n",
            "val Loss: 0.8090 Acc: 0.7644\n",
            "\n",
            "Epoch 9/24\n",
            "----------\n",
            "train Loss: 0.2020 Acc: 0.9257\n",
            "val Loss: 0.8628 Acc: 0.7468\n",
            "\n",
            "Epoch 10/24\n",
            "----------\n",
            "train Loss: 0.1783 Acc: 0.9341\n",
            "val Loss: 0.8273 Acc: 0.7711\n",
            "\n",
            "Epoch 11/24\n",
            "----------\n",
            "train Loss: 0.1846 Acc: 0.9356\n",
            "val Loss: 0.8500 Acc: 0.7589\n",
            "\n",
            "Epoch 12/24\n",
            "----------\n",
            "train Loss: 0.1671 Acc: 0.9448\n",
            "val Loss: 0.9176 Acc: 0.7508\n",
            "\n",
            "Epoch 13/24\n",
            "----------\n",
            "train Loss: 0.1399 Acc: 0.9525\n",
            "val Loss: 0.9268 Acc: 0.7685\n",
            "\n",
            "Epoch 14/24\n",
            "----------\n",
            "train Loss: 0.1476 Acc: 0.9496\n",
            "val Loss: 0.9419 Acc: 0.7556\n",
            "\n",
            "Epoch 15/24\n",
            "----------\n",
            "train Loss: 0.1302 Acc: 0.9503\n",
            "val Loss: 0.8465 Acc: 0.7751\n",
            "\n",
            "Epoch 16/24\n",
            "----------\n",
            "train Loss: 0.1496 Acc: 0.9496\n",
            "val Loss: 0.9154 Acc: 0.7597\n",
            "\n",
            "Epoch 17/24\n",
            "----------\n",
            "train Loss: 0.1312 Acc: 0.9544\n",
            "val Loss: 0.8729 Acc: 0.7770\n",
            "\n",
            "Epoch 18/24\n",
            "----------\n",
            "train Loss: 0.1263 Acc: 0.9573\n",
            "val Loss: 0.8573 Acc: 0.7748\n",
            "\n",
            "Epoch 19/24\n",
            "----------\n",
            "train Loss: 0.1209 Acc: 0.9566\n",
            "val Loss: 0.9158 Acc: 0.7836\n",
            "\n",
            "Epoch 20/24\n",
            "----------\n",
            "train Loss: 0.0998 Acc: 0.9647\n",
            "val Loss: 0.8842 Acc: 0.7843\n",
            "\n",
            "Epoch 21/24\n",
            "----------\n",
            "train Loss: 0.1205 Acc: 0.9577\n",
            "val Loss: 0.8931 Acc: 0.7748\n",
            "\n",
            "Epoch 22/24\n",
            "----------\n",
            "train Loss: 0.0914 Acc: 0.9672\n",
            "val Loss: 0.8759 Acc: 0.7799\n",
            "\n",
            "Epoch 23/24\n",
            "----------\n",
            "train Loss: 0.0946 Acc: 0.9698\n",
            "val Loss: 0.9210 Acc: 0.7714\n",
            "\n",
            "Epoch 24/24\n",
            "----------\n",
            "train Loss: 0.0813 Acc: 0.9742\n",
            "val Loss: 0.9439 Acc: 0.7685\n",
            "\n",
            "Training complete in 24m 50s\n",
            "Best val Acc: 0.784321\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the best model\n",
        "torch.save(resnet50_model.state_dict(), \n",
        "           save_models_dir + \"best_resnet50_multistage_train_incrLRlate.pt\")"
      ],
      "metadata": {
        "id": "GFzit7z_o9UA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train 90%, val 10%"
      ],
      "metadata": {
        "id": "SBC46IlsKNNv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft = models.resnet50(weights=\"DEFAULT\")\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "\n",
        "model_ft.fc = nn.Linear(num_ftrs, 5)\n",
        "\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.0001)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 15 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=15, gamma=0.1)"
      ],
      "metadata": {
        "id": "cEhe6k0rKZ1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
        "                       num_epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7YHPsuA6KimS",
        "outputId": "cee2a9da-778a-4cd8-f4cf-f107f505edc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/49\n",
            "----------\n",
            "train Loss: 1.2134 Acc: 0.5012\n",
            "val Loss: 0.9849 Acc: 0.6379\n",
            "\n",
            "Epoch 1/49\n",
            "----------\n",
            "train Loss: 0.7908 Acc: 0.6814\n",
            "val Loss: 0.6718 Acc: 0.7592\n",
            "\n",
            "Epoch 2/49\n",
            "----------\n",
            "train Loss: 0.6592 Acc: 0.7354\n",
            "val Loss: 0.6610 Acc: 0.7629\n",
            "\n",
            "Epoch 3/49\n",
            "----------\n",
            "train Loss: 0.5832 Acc: 0.7712\n",
            "val Loss: 0.6563 Acc: 0.7574\n",
            "\n",
            "Epoch 4/49\n",
            "----------\n",
            "train Loss: 0.5543 Acc: 0.7791\n",
            "val Loss: 0.5824 Acc: 0.7684\n",
            "\n",
            "Epoch 5/49\n",
            "----------\n",
            "train Loss: 0.5193 Acc: 0.7957\n",
            "val Loss: 0.5410 Acc: 0.7849\n",
            "\n",
            "Epoch 6/49\n",
            "----------\n",
            "train Loss: 0.4593 Acc: 0.8188\n",
            "val Loss: 0.5653 Acc: 0.7886\n",
            "\n",
            "Epoch 7/49\n",
            "----------\n",
            "train Loss: 0.4298 Acc: 0.8370\n",
            "val Loss: 0.5994 Acc: 0.7757\n",
            "\n",
            "Epoch 8/49\n",
            "----------\n",
            "train Loss: 0.3819 Acc: 0.8497\n",
            "val Loss: 0.6744 Acc: 0.7776\n",
            "\n",
            "Epoch 9/49\n",
            "----------\n",
            "train Loss: 0.3541 Acc: 0.8693\n",
            "val Loss: 0.6198 Acc: 0.7904\n",
            "\n",
            "Epoch 10/49\n",
            "----------\n",
            "train Loss: 0.3317 Acc: 0.8810\n",
            "val Loss: 0.6081 Acc: 0.7960\n",
            "\n",
            "Epoch 11/49\n",
            "----------\n",
            "train Loss: 0.3025 Acc: 0.8869\n",
            "val Loss: 0.5990 Acc: 0.7978\n",
            "\n",
            "Epoch 12/49\n",
            "----------\n",
            "train Loss: 0.2958 Acc: 0.8906\n",
            "val Loss: 0.6235 Acc: 0.7978\n",
            "\n",
            "Epoch 13/49\n",
            "----------\n",
            "train Loss: 0.2683 Acc: 0.8973\n",
            "val Loss: 0.6278 Acc: 0.7868\n",
            "\n",
            "Epoch 14/49\n",
            "----------\n",
            "train Loss: 0.2481 Acc: 0.9102\n",
            "val Loss: 0.6400 Acc: 0.7831\n",
            "\n",
            "Epoch 15/49\n",
            "----------\n",
            "train Loss: 0.2003 Acc: 0.9288\n",
            "val Loss: 0.6035 Acc: 0.8015\n",
            "\n",
            "Epoch 16/49\n",
            "----------\n",
            "train Loss: 0.1561 Acc: 0.9466\n",
            "val Loss: 0.6017 Acc: 0.7923\n",
            "\n",
            "Epoch 17/49\n",
            "----------\n",
            "train Loss: 0.1470 Acc: 0.9472\n",
            "val Loss: 0.6247 Acc: 0.7904\n",
            "\n",
            "Epoch 18/49\n",
            "----------\n",
            "train Loss: 0.1417 Acc: 0.9519\n",
            "val Loss: 0.6303 Acc: 0.8015\n",
            "\n",
            "Epoch 19/49\n",
            "----------\n",
            "train Loss: 0.1298 Acc: 0.9575\n",
            "val Loss: 0.6355 Acc: 0.7960\n",
            "\n",
            "Epoch 20/49\n",
            "----------\n",
            "train Loss: 0.1241 Acc: 0.9583\n",
            "val Loss: 0.6564 Acc: 0.7923\n",
            "\n",
            "Epoch 21/49\n",
            "----------\n",
            "train Loss: 0.1057 Acc: 0.9646\n",
            "val Loss: 0.6788 Acc: 0.7868\n",
            "\n",
            "Epoch 22/49\n",
            "----------\n",
            "train Loss: 0.1184 Acc: 0.9607\n",
            "val Loss: 0.7027 Acc: 0.7831\n",
            "\n",
            "Epoch 23/49\n",
            "----------\n",
            "train Loss: 0.0990 Acc: 0.9683\n",
            "val Loss: 0.7071 Acc: 0.7831\n",
            "\n",
            "Epoch 24/49\n",
            "----------\n",
            "train Loss: 0.0985 Acc: 0.9679\n",
            "val Loss: 0.7436 Acc: 0.7739\n",
            "\n",
            "Epoch 25/49\n",
            "----------\n",
            "train Loss: 0.0878 Acc: 0.9697\n",
            "val Loss: 0.7242 Acc: 0.7904\n",
            "\n",
            "Epoch 26/49\n",
            "----------\n",
            "train Loss: 0.0896 Acc: 0.9689\n",
            "val Loss: 0.7128 Acc: 0.7904\n",
            "\n",
            "Epoch 27/49\n",
            "----------\n",
            "train Loss: 0.0845 Acc: 0.9742\n",
            "val Loss: 0.7376 Acc: 0.7849\n",
            "\n",
            "Epoch 28/49\n",
            "----------\n",
            "train Loss: 0.0869 Acc: 0.9736\n",
            "val Loss: 0.7361 Acc: 0.7886\n",
            "\n",
            "Epoch 29/49\n",
            "----------\n",
            "train Loss: 0.0757 Acc: 0.9763\n",
            "val Loss: 0.7453 Acc: 0.7886\n",
            "\n",
            "Epoch 30/49\n",
            "----------\n",
            "train Loss: 0.0704 Acc: 0.9779\n",
            "val Loss: 0.7545 Acc: 0.7904\n",
            "\n",
            "Epoch 31/49\n",
            "----------\n",
            "train Loss: 0.0799 Acc: 0.9748\n",
            "val Loss: 0.7623 Acc: 0.7941\n",
            "\n",
            "Epoch 32/49\n",
            "----------\n",
            "train Loss: 0.0748 Acc: 0.9761\n",
            "val Loss: 0.7517 Acc: 0.7923\n",
            "\n",
            "Epoch 33/49\n",
            "----------\n",
            "train Loss: 0.0695 Acc: 0.9771\n",
            "val Loss: 0.7595 Acc: 0.7960\n",
            "\n",
            "Epoch 34/49\n",
            "----------\n",
            "train Loss: 0.0662 Acc: 0.9783\n",
            "val Loss: 0.7498 Acc: 0.7941\n",
            "\n",
            "Epoch 35/49\n",
            "----------\n",
            "train Loss: 0.0766 Acc: 0.9738\n",
            "val Loss: 0.7706 Acc: 0.7960\n",
            "\n",
            "Epoch 36/49\n",
            "----------\n",
            "train Loss: 0.0631 Acc: 0.9820\n",
            "val Loss: 0.7413 Acc: 0.7941\n",
            "\n",
            "Epoch 37/49\n",
            "----------\n",
            "train Loss: 0.0687 Acc: 0.9804\n",
            "val Loss: 0.7599 Acc: 0.7923\n",
            "\n",
            "Epoch 38/49\n",
            "----------\n",
            "train Loss: 0.0640 Acc: 0.9796\n",
            "val Loss: 0.7478 Acc: 0.7904\n",
            "\n",
            "Epoch 39/49\n",
            "----------\n",
            "train Loss: 0.0661 Acc: 0.9781\n",
            "val Loss: 0.7418 Acc: 0.7923\n",
            "\n",
            "Epoch 40/49\n",
            "----------\n",
            "train Loss: 0.0720 Acc: 0.9771\n",
            "val Loss: 0.7669 Acc: 0.7978\n",
            "\n",
            "Epoch 41/49\n",
            "----------\n",
            "train Loss: 0.0594 Acc: 0.9828\n",
            "val Loss: 0.7671 Acc: 0.7960\n",
            "\n",
            "Epoch 42/49\n",
            "----------\n",
            "train Loss: 0.0618 Acc: 0.9824\n",
            "val Loss: 0.7734 Acc: 0.7904\n",
            "\n",
            "Epoch 43/49\n",
            "----------\n",
            "train Loss: 0.0685 Acc: 0.9783\n",
            "val Loss: 0.7390 Acc: 0.7996\n",
            "\n",
            "Epoch 44/49\n",
            "----------\n",
            "train Loss: 0.0704 Acc: 0.9767\n",
            "val Loss: 0.7487 Acc: 0.7941\n",
            "\n",
            "Epoch 45/49\n",
            "----------\n",
            "train Loss: 0.0696 Acc: 0.9763\n",
            "val Loss: 0.7633 Acc: 0.7904\n",
            "\n",
            "Epoch 46/49\n",
            "----------\n",
            "train Loss: 0.0662 Acc: 0.9800\n",
            "val Loss: 0.7598 Acc: 0.7941\n",
            "\n",
            "Epoch 47/49\n",
            "----------\n",
            "train Loss: 0.0608 Acc: 0.9830\n",
            "val Loss: 0.7662 Acc: 0.7923\n",
            "\n",
            "Epoch 48/49\n",
            "----------\n",
            "train Loss: 0.0739 Acc: 0.9744\n",
            "val Loss: 0.7718 Acc: 0.7978\n",
            "\n",
            "Epoch 49/49\n",
            "----------\n",
            "train Loss: 0.0660 Acc: 0.9779\n",
            "val Loss: 0.7617 Acc: 0.7904\n",
            "\n",
            "Training complete in 75m 40s\n",
            "Best val Acc: 0.801471\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the best model\n",
        "torch.save(model_ft.state_dict(), '/content/drive/MyDrive/ML for BDS/Hackathon - graddiss/best_resnet50_balanced_AdamOptim.pt')"
      ],
      "metadata": {
        "id": "keb5dX-rKsRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-phase training approach with progressive unfreezing of layers"
      ],
      "metadata": {
        "id": "iFpFroBS7P0U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stage 1"
      ],
      "metadata": {
        "id": "aZ0DxHP986qu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet50_model = models.resnet50(weights=\"DEFAULT\")\n",
        "\n",
        "# Freeze all parameters...except for the final layer\n",
        "for param in resnet50_model.parameters():\n",
        "    param.requires_grad = False\n",
        "num_ftrs = resnet50_model.fc.in_features\n",
        "resnet50_model.fc = nn.Linear(num_ftrs, 5)\n",
        "\n",
        "resnet50_model = resnet50_model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized --> change for each stage\n",
        "optimizer = optim.Adam(resnet50_model.parameters(), lr=0.001)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 10 epochs\n",
        "# If don't want to decay, then set the step_size to very high\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"
      ],
      "metadata": {
        "id": "ldBQeQADZ9cM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet50_model = train_model(resnet50_model, criterion, optimizer, exp_lr_scheduler,\n",
        "                       num_epochs=3)"
      ],
      "metadata": {
        "id": "Bnj1D-vo7Cfu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c513dd2-210c-47c1-f7c8-9d11eb632e3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/2\n",
            "----------\n",
            "train Loss: 1.4885 Acc: 0.3636\n",
            "val Loss: 1.3313 Acc: 0.5123\n",
            "\n",
            "Epoch 1/2\n",
            "----------\n",
            "train Loss: 1.3827 Acc: 0.4461\n",
            "val Loss: 1.1956 Acc: 0.5539\n",
            "\n",
            "Epoch 2/2\n",
            "----------\n",
            "train Loss: 1.3193 Acc: 0.4604\n",
            "val Loss: 1.2024 Acc: 0.5348\n",
            "\n",
            "Training complete in 2m 49s\n",
            "Best val Acc: 0.553920\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stage 2"
      ],
      "metadata": {
        "id": "u_wQ03h7Bjvb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For simplicity, first unfreeze all layers\n",
        "for param in resnet50_model.parameters():\n",
        "    param.requires_grad = True"
      ],
      "metadata": {
        "id": "v5zLvWdXPGm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet50_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCrRkyLDdPtO",
        "outputId": "9cf4d37c-8755-4715-d9e7-e329eda38e9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=2048, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "layer_count = 0\n",
        "for child in resnet50_model.children():\n",
        "  print(\"Child \", layer_count)\n",
        "  print(child)\n",
        "  children_of_child_counter = 0\n",
        "  for children_of_child in child.children():\n",
        "    print(\"child \", children_of_child_counter, \"of child\", layer_count)\n",
        "    print(children_of_child)\n",
        "    children_of_child_counter += 1 \n",
        "  layer_count += 1\n",
        "\n",
        "# print(\"total layers: \", layer_count)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oAZQQ3-aPpV",
        "outputId": "b84c7ee3-10e6-4a84-a140-4a8ac8e35a22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Child  0\n",
            "Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "Child  1\n",
            "BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "Child  2\n",
            "ReLU(inplace=True)\n",
            "Child  3\n",
            "MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "Child  4\n",
            "Sequential(\n",
            "  (0): Bottleneck(\n",
            "    (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (downsample): Sequential(\n",
            "      (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (1): Bottleneck(\n",
            "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "  )\n",
            "  (2): Bottleneck(\n",
            "    (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "  )\n",
            ")\n",
            "child  0 of child 4\n",
            "Bottleneck(\n",
            "  (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (downsample): Sequential(\n",
            "    (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            ")\n",
            "child  1 of child 4\n",
            "Bottleneck(\n",
            "  (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            ")\n",
            "child  2 of child 4\n",
            "Bottleneck(\n",
            "  (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            ")\n",
            "Child  5\n",
            "Sequential(\n",
            "  (0): Bottleneck(\n",
            "    (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (downsample): Sequential(\n",
            "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (1): Bottleneck(\n",
            "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "  )\n",
            "  (2): Bottleneck(\n",
            "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "  )\n",
            "  (3): Bottleneck(\n",
            "    (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "  )\n",
            ")\n",
            "child  0 of child 5\n",
            "Bottleneck(\n",
            "  (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (downsample): Sequential(\n",
            "    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            ")\n",
            "child  1 of child 5\n",
            "Bottleneck(\n",
            "  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            ")\n",
            "child  2 of child 5\n",
            "Bottleneck(\n",
            "  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            ")\n",
            "child  3 of child 5\n",
            "Bottleneck(\n",
            "  (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            ")\n",
            "Child  6\n",
            "Sequential(\n",
            "  (0): Bottleneck(\n",
            "    (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (downsample): Sequential(\n",
            "      (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "      (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (1): Bottleneck(\n",
            "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "  )\n",
            "  (2): Bottleneck(\n",
            "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "  )\n",
            "  (3): Bottleneck(\n",
            "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "  )\n",
            "  (4): Bottleneck(\n",
            "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "  )\n",
            "  (5): Bottleneck(\n",
            "    (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "  )\n",
            ")\n",
            "child  0 of child 6\n",
            "Bottleneck(\n",
            "  (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (downsample): Sequential(\n",
            "    (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            ")\n",
            "child  1 of child 6\n",
            "Bottleneck(\n",
            "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            ")\n",
            "child  2 of child 6\n",
            "Bottleneck(\n",
            "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            ")\n",
            "child  3 of child 6\n",
            "Bottleneck(\n",
            "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            ")\n",
            "child  4 of child 6\n",
            "Bottleneck(\n",
            "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            ")\n",
            "child  5 of child 6\n",
            "Bottleneck(\n",
            "  (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            ")\n",
            "Child  7\n",
            "Sequential(\n",
            "  (0): Bottleneck(\n",
            "    (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (downsample): Sequential(\n",
            "      (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "      (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (1): Bottleneck(\n",
            "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "  )\n",
            "  (2): Bottleneck(\n",
            "    (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "  )\n",
            ")\n",
            "child  0 of child 7\n",
            "Bottleneck(\n",
            "  (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (downsample): Sequential(\n",
            "    (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "    (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            ")\n",
            "child  1 of child 7\n",
            "Bottleneck(\n",
            "  (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            ")\n",
            "child  2 of child 7\n",
            "Bottleneck(\n",
            "  (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "  (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            ")\n",
            "Child  8\n",
            "AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "Child  9\n",
            "Linear(in_features=2048, out_features=5, bias=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now selectively freeze layers\n",
        "child_counter = 0\n",
        "for child in resnet50_model.children():\n",
        "  if child_counter < 7:\n",
        "    print(\"child\", child_counter, \"was frozen\")\n",
        "    for param in child.parameters():\n",
        "      param.requires_grad = False\n",
        "  elif child_counter == 7:\n",
        "    children_of_child_counter = 0\n",
        "    for children_of_child in child.children():\n",
        "      if children_of_child_counter < 2:\n",
        "        for param in children_of_child.parameters():\n",
        "          param.requires_grad = False\n",
        "        print(\"child\", children_of_child_counter, \"of child\", child_counter, \"was frozen\")\n",
        "      else:\n",
        "        print('child ', children_of_child_counter, 'of child',child_counter,' was not frozen')\n",
        "      children_of_child_counter += 1\n",
        "  else:\n",
        "    print(\"child \",child_counter,\" was not frozen\")\n",
        "  child_counter += 1\n",
        "    \n",
        "    # print(\"child \",child_counter,\" was frozen\")\n",
        "    # for param in child.parameters():\n",
        "    #     param.requires_grad = False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9EgFNKAfQxm",
        "outputId": "8aeafcd1-0aa6-4e34-a688-4a887763feb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "child 0 was frozen\n",
            "child 1 was frozen\n",
            "child 2 was frozen\n",
            "child 3 was frozen\n",
            "child 4 was frozen\n",
            "child 5 was frozen\n",
            "child 6 was frozen\n",
            "child 0 of child 7 was frozen\n",
            "child 1 of child 7 was frozen\n",
            "child  2 of child 7  was not frozen\n",
            "child  8  was not frozen\n",
            "child  9  was not frozen\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resnet50_model = resnet50_model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized --> change for each stage\n",
        "optimizer = optim.Adam(resnet50_model.parameters(), lr=0.0001)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 10 epochs\n",
        "# If don't want to decay, then set the step_size to very high\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=11, gamma=0.1)"
      ],
      "metadata": {
        "id": "n8O5Pvbs_tf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet50_model = train_model(resnet50_model, criterion, optimizer, exp_lr_scheduler,\n",
        "                       num_epochs=10)"
      ],
      "metadata": {
        "id": "1feiatrhaKfT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d66d425-50c9-4e15-cf25-04673aef8fdf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/9\n",
            "----------\n",
            "train Loss: 1.2893 Acc: 0.4803\n",
            "val Loss: 1.1549 Acc: 0.5565\n",
            "\n",
            "Epoch 1/9\n",
            "----------\n",
            "train Loss: 1.2117 Acc: 0.5072\n",
            "val Loss: 1.0484 Acc: 0.5889\n",
            "\n",
            "Epoch 2/9\n",
            "----------\n",
            "train Loss: 1.1480 Acc: 0.5469\n",
            "val Loss: 1.0121 Acc: 0.6069\n",
            "\n",
            "Epoch 3/9\n",
            "----------\n",
            "train Loss: 1.1020 Acc: 0.5558\n",
            "val Loss: 0.9959 Acc: 0.6242\n",
            "\n",
            "Epoch 4/9\n",
            "----------\n",
            "train Loss: 1.0805 Acc: 0.5558\n",
            "val Loss: 0.9762 Acc: 0.6235\n",
            "\n",
            "Epoch 5/9\n",
            "----------\n",
            "train Loss: 1.0583 Acc: 0.5709\n",
            "val Loss: 0.9677 Acc: 0.6378\n",
            "\n",
            "Epoch 6/9\n",
            "----------\n",
            "train Loss: 1.0377 Acc: 0.5760\n",
            "val Loss: 0.9219 Acc: 0.6511\n",
            "\n",
            "Epoch 7/9\n",
            "----------\n",
            "train Loss: 1.0069 Acc: 0.5915\n",
            "val Loss: 0.9754 Acc: 0.6216\n",
            "\n",
            "Epoch 8/9\n",
            "----------\n",
            "train Loss: 1.0107 Acc: 0.5859\n",
            "val Loss: 0.9803 Acc: 0.6286\n",
            "\n",
            "Epoch 9/9\n",
            "----------\n",
            "train Loss: 1.0053 Acc: 0.6080\n",
            "val Loss: 0.9406 Acc: 0.6334\n",
            "\n",
            "Training complete in 9m 13s\n",
            "Best val Acc: 0.651086\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stage 3"
      ],
      "metadata": {
        "id": "QTYWJnitCLMk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Unfreeze all parameters\n",
        "for param in resnet50_model.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "resnet50_model = resnet50_model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized --> change for each stage\n",
        "optimizer = optim.Adam(resnet50_model.parameters(), lr=0.00001)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 10 epochs\n",
        "# If don't want to decay, then set the step_size to very high\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)"
      ],
      "metadata": {
        "id": "UzZVLnHMBUzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet50_model = train_model(resnet50_model, criterion, optimizer, exp_lr_scheduler,\n",
        "                       num_epochs=37)"
      ],
      "metadata": {
        "id": "EjYC1BpnCuY2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3683bddb-d227-43ad-fee7-29436157563e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/36\n",
            "----------\n",
            "train Loss: 0.9882 Acc: 0.6058\n",
            "val Loss: 0.8974 Acc: 0.6618\n",
            "\n",
            "Epoch 1/36\n",
            "----------\n",
            "train Loss: 0.9340 Acc: 0.6308\n",
            "val Loss: 0.8735 Acc: 0.6669\n",
            "\n",
            "Epoch 2/36\n",
            "----------\n",
            "train Loss: 0.9258 Acc: 0.6264\n",
            "val Loss: 0.8486 Acc: 0.6772\n",
            "\n",
            "Epoch 3/36\n",
            "----------\n",
            "train Loss: 0.8934 Acc: 0.6445\n",
            "val Loss: 0.8423 Acc: 0.6791\n",
            "\n",
            "Epoch 4/36\n",
            "----------\n",
            "train Loss: 0.8747 Acc: 0.6544\n",
            "val Loss: 0.8970 Acc: 0.6570\n",
            "\n",
            "Epoch 5/36\n",
            "----------\n",
            "train Loss: 0.8586 Acc: 0.6573\n",
            "val Loss: 0.8144 Acc: 0.6956\n",
            "\n",
            "Epoch 6/36\n",
            "----------\n",
            "train Loss: 0.8128 Acc: 0.6824\n",
            "val Loss: 0.7678 Acc: 0.7137\n",
            "\n",
            "Epoch 7/36\n",
            "----------\n",
            "train Loss: 0.7592 Acc: 0.6975\n",
            "val Loss: 0.8007 Acc: 0.7008\n",
            "\n",
            "Epoch 8/36\n",
            "----------\n",
            "train Loss: 0.7818 Acc: 0.6838\n",
            "val Loss: 0.7590 Acc: 0.7177\n",
            "\n",
            "Epoch 9/36\n",
            "----------\n",
            "train Loss: 0.7325 Acc: 0.6982\n",
            "val Loss: 0.7519 Acc: 0.7203\n",
            "\n",
            "Epoch 10/36\n",
            "----------\n",
            "train Loss: 0.7420 Acc: 0.7089\n",
            "val Loss: 0.7492 Acc: 0.7195\n",
            "\n",
            "Epoch 11/36\n",
            "----------\n",
            "train Loss: 0.6979 Acc: 0.7159\n",
            "val Loss: 0.7358 Acc: 0.7199\n",
            "\n",
            "Epoch 12/36\n",
            "----------\n",
            "train Loss: 0.6907 Acc: 0.7232\n",
            "val Loss: 0.7177 Acc: 0.7339\n",
            "\n",
            "Epoch 13/36\n",
            "----------\n",
            "train Loss: 0.7052 Acc: 0.7210\n",
            "val Loss: 0.7068 Acc: 0.7335\n",
            "\n",
            "Epoch 14/36\n",
            "----------\n",
            "train Loss: 0.6888 Acc: 0.7332\n",
            "val Loss: 0.7203 Acc: 0.7295\n",
            "\n",
            "Epoch 15/36\n",
            "----------\n",
            "train Loss: 0.6617 Acc: 0.7361\n",
            "val Loss: 0.7146 Acc: 0.7376\n",
            "\n",
            "Epoch 16/36\n",
            "----------\n",
            "train Loss: 0.6357 Acc: 0.7486\n",
            "val Loss: 0.7036 Acc: 0.7424\n",
            "\n",
            "Epoch 17/36\n",
            "----------\n",
            "train Loss: 0.6635 Acc: 0.7431\n",
            "val Loss: 0.6882 Acc: 0.7541\n",
            "\n",
            "Epoch 18/36\n",
            "----------\n",
            "train Loss: 0.6036 Acc: 0.7648\n",
            "val Loss: 0.6828 Acc: 0.7449\n",
            "\n",
            "Epoch 19/36\n",
            "----------\n",
            "train Loss: 0.6092 Acc: 0.7619\n",
            "val Loss: 0.6908 Acc: 0.7335\n",
            "\n",
            "Epoch 20/36\n",
            "----------\n",
            "train Loss: 0.6094 Acc: 0.7545\n",
            "val Loss: 0.6638 Acc: 0.7597\n",
            "\n",
            "Epoch 21/36\n",
            "----------\n",
            "train Loss: 0.5822 Acc: 0.7748\n",
            "val Loss: 0.6767 Acc: 0.7453\n",
            "\n",
            "Epoch 22/36\n",
            "----------\n",
            "train Loss: 0.5691 Acc: 0.7836\n",
            "val Loss: 0.6813 Acc: 0.7457\n",
            "\n",
            "Epoch 23/36\n",
            "----------\n",
            "train Loss: 0.5531 Acc: 0.7880\n",
            "val Loss: 0.6794 Acc: 0.7516\n",
            "\n",
            "Epoch 24/36\n",
            "----------\n",
            "train Loss: 0.5664 Acc: 0.7806\n",
            "val Loss: 0.6736 Acc: 0.7494\n",
            "\n",
            "Epoch 25/36\n",
            "----------\n",
            "train Loss: 0.5363 Acc: 0.7924\n",
            "val Loss: 0.6649 Acc: 0.7560\n",
            "\n",
            "Epoch 26/36\n",
            "----------\n",
            "train Loss: 0.5230 Acc: 0.8060\n",
            "val Loss: 0.6679 Acc: 0.7541\n",
            "\n",
            "Epoch 27/36\n",
            "----------\n",
            "train Loss: 0.5096 Acc: 0.8035\n",
            "val Loss: 0.6747 Acc: 0.7523\n",
            "\n",
            "Epoch 28/36\n",
            "----------\n",
            "train Loss: 0.5247 Acc: 0.7946\n",
            "val Loss: 0.6650 Acc: 0.7534\n",
            "\n",
            "Epoch 29/36\n",
            "----------\n",
            "train Loss: 0.5019 Acc: 0.8060\n",
            "val Loss: 0.6655 Acc: 0.7527\n",
            "\n",
            "Epoch 30/36\n",
            "----------\n",
            "train Loss: 0.4675 Acc: 0.8200\n",
            "val Loss: 0.6637 Acc: 0.7549\n",
            "\n",
            "Epoch 31/36\n",
            "----------\n",
            "train Loss: 0.4484 Acc: 0.8303\n",
            "val Loss: 0.6579 Acc: 0.7663\n",
            "\n",
            "Epoch 32/36\n",
            "----------\n",
            "train Loss: 0.4659 Acc: 0.8178\n",
            "val Loss: 0.6710 Acc: 0.7615\n",
            "\n",
            "Epoch 33/36\n",
            "----------\n",
            "train Loss: 0.4561 Acc: 0.8200\n",
            "val Loss: 0.6677 Acc: 0.7633\n",
            "\n",
            "Epoch 34/36\n",
            "----------\n",
            "train Loss: 0.4468 Acc: 0.8244\n",
            "val Loss: 0.6716 Acc: 0.7652\n",
            "\n",
            "Epoch 35/36\n",
            "----------\n",
            "train Loss: 0.4432 Acc: 0.8307\n",
            "val Loss: 0.6594 Acc: 0.7689\n",
            "\n",
            "Epoch 36/36\n",
            "----------\n",
            "train Loss: 0.3862 Acc: 0.8631\n",
            "val Loss: 0.6519 Acc: 0.7718\n",
            "\n",
            "Training complete in 36m 29s\n",
            "Best val Acc: 0.771807\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the best model --> checkpoint\n",
        "torch.save(resnet50_model.state_dict(), \n",
        "           save_models_dir + \"best_resnet50_multistage_train.pt\")"
      ],
      "metadata": {
        "id": "nUZ-ppAwSxS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Continue with the above, so going to 100 epochs"
      ],
      "metadata": {
        "id": "sLnVo1DFZzKj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet50_model = train_model(resnet50_model, criterion, optimizer, exp_lr_scheduler,\n",
        "                       num_epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MntWTmKFZ06Q",
        "outputId": "9535bc35-ffb9-485b-8b87-bdee13b45179"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/49\n",
            "----------\n",
            "train Loss: 0.4078 Acc: 0.8476\n",
            "val Loss: 0.6840 Acc: 0.7586\n",
            "\n",
            "Epoch 1/49\n",
            "----------\n",
            "train Loss: 0.3722 Acc: 0.8627\n",
            "val Loss: 0.6709 Acc: 0.7622\n",
            "\n",
            "Epoch 2/49\n",
            "----------\n",
            "train Loss: 0.3637 Acc: 0.8668\n",
            "val Loss: 0.6854 Acc: 0.7611\n",
            "\n",
            "Epoch 3/49\n",
            "----------\n",
            "train Loss: 0.3626 Acc: 0.8653\n",
            "val Loss: 0.6646 Acc: 0.7648\n",
            "\n",
            "Epoch 4/49\n",
            "----------\n",
            "train Loss: 0.3472 Acc: 0.8800\n",
            "val Loss: 0.6832 Acc: 0.7670\n",
            "\n",
            "Epoch 5/49\n",
            "----------\n",
            "train Loss: 0.3416 Acc: 0.8734\n",
            "val Loss: 0.6845 Acc: 0.7644\n",
            "\n",
            "Epoch 6/49\n",
            "----------\n",
            "train Loss: 0.3365 Acc: 0.8763\n",
            "val Loss: 0.7069 Acc: 0.7667\n",
            "\n",
            "Epoch 7/49\n",
            "----------\n",
            "train Loss: 0.3579 Acc: 0.8671\n",
            "val Loss: 0.6753 Acc: 0.7696\n",
            "\n",
            "Epoch 8/49\n",
            "----------\n",
            "train Loss: 0.3174 Acc: 0.8837\n",
            "val Loss: 0.7006 Acc: 0.7637\n",
            "\n",
            "Epoch 9/49\n",
            "----------\n",
            "train Loss: 0.3093 Acc: 0.8929\n",
            "val Loss: 0.6888 Acc: 0.7755\n",
            "\n",
            "Epoch 10/49\n",
            "----------\n",
            "train Loss: 0.2931 Acc: 0.8914\n",
            "val Loss: 0.7001 Acc: 0.7648\n",
            "\n",
            "Epoch 11/49\n",
            "----------\n",
            "train Loss: 0.2829 Acc: 0.8966\n",
            "val Loss: 0.7060 Acc: 0.7703\n",
            "\n",
            "Epoch 12/49\n",
            "----------\n",
            "train Loss: 0.2733 Acc: 0.9028\n",
            "val Loss: 0.6913 Acc: 0.7762\n",
            "\n",
            "Epoch 13/49\n",
            "----------\n",
            "train Loss: 0.2638 Acc: 0.9054\n",
            "val Loss: 0.7001 Acc: 0.7703\n",
            "\n",
            "Epoch 14/49\n",
            "----------\n",
            "train Loss: 0.2735 Acc: 0.9032\n",
            "val Loss: 0.7053 Acc: 0.7740\n",
            "\n",
            "Epoch 15/49\n",
            "----------\n",
            "train Loss: 0.2575 Acc: 0.9106\n",
            "val Loss: 0.7048 Acc: 0.7725\n",
            "\n",
            "Epoch 16/49\n",
            "----------\n",
            "train Loss: 0.2650 Acc: 0.8980\n",
            "val Loss: 0.7145 Acc: 0.7714\n",
            "\n",
            "Epoch 17/49\n",
            "----------\n",
            "train Loss: 0.2670 Acc: 0.9039\n",
            "val Loss: 0.7099 Acc: 0.7736\n",
            "\n",
            "Epoch 18/49\n",
            "----------\n",
            "train Loss: 0.2809 Acc: 0.8929\n",
            "val Loss: 0.7075 Acc: 0.7744\n",
            "\n",
            "Epoch 19/49\n",
            "----------\n",
            "train Loss: 0.2651 Acc: 0.9084\n",
            "val Loss: 0.7104 Acc: 0.7718\n",
            "\n",
            "Epoch 20/49\n",
            "----------\n",
            "train Loss: 0.2517 Acc: 0.9165\n",
            "val Loss: 0.7088 Acc: 0.7707\n",
            "\n",
            "Epoch 21/49\n",
            "----------\n",
            "train Loss: 0.2655 Acc: 0.9065\n",
            "val Loss: 0.7112 Acc: 0.7718\n",
            "\n",
            "Epoch 22/49\n",
            "----------\n",
            "train Loss: 0.2461 Acc: 0.9153\n",
            "val Loss: 0.7125 Acc: 0.7722\n",
            "\n",
            "Epoch 23/49\n",
            "----------\n",
            "train Loss: 0.2376 Acc: 0.9176\n",
            "val Loss: 0.7149 Acc: 0.7707\n",
            "\n",
            "Epoch 24/49\n",
            "----------\n",
            "train Loss: 0.2680 Acc: 0.9006\n",
            "val Loss: 0.7053 Acc: 0.7748\n",
            "\n",
            "Epoch 25/49\n",
            "----------\n",
            "train Loss: 0.2574 Acc: 0.9039\n",
            "val Loss: 0.7065 Acc: 0.7759\n",
            "\n",
            "Epoch 26/49\n",
            "----------\n",
            "train Loss: 0.2527 Acc: 0.9095\n",
            "val Loss: 0.7098 Acc: 0.7755\n",
            "\n",
            "Epoch 27/49\n",
            "----------\n",
            "train Loss: 0.2529 Acc: 0.9102\n",
            "val Loss: 0.7110 Acc: 0.7766\n",
            "\n",
            "Epoch 28/49\n",
            "----------\n",
            "train Loss: 0.2734 Acc: 0.9003\n",
            "val Loss: 0.7193 Acc: 0.7659\n",
            "\n",
            "Epoch 29/49\n",
            "----------\n",
            "train Loss: 0.2430 Acc: 0.9216\n",
            "val Loss: 0.7121 Acc: 0.7722\n",
            "\n",
            "Epoch 30/49\n",
            "----------\n",
            "train Loss: 0.2371 Acc: 0.9150\n",
            "val Loss: 0.7119 Acc: 0.7751\n",
            "\n",
            "Epoch 31/49\n",
            "----------\n",
            "train Loss: 0.2492 Acc: 0.9113\n",
            "val Loss: 0.7104 Acc: 0.7725\n",
            "\n",
            "Epoch 32/49\n",
            "----------\n",
            "train Loss: 0.2624 Acc: 0.9084\n",
            "val Loss: 0.7087 Acc: 0.7733\n",
            "\n",
            "Epoch 33/49\n",
            "----------\n",
            "train Loss: 0.2482 Acc: 0.9153\n",
            "val Loss: 0.7119 Acc: 0.7707\n",
            "\n",
            "Epoch 34/49\n",
            "----------\n",
            "train Loss: 0.2418 Acc: 0.9168\n",
            "val Loss: 0.7263 Acc: 0.7648\n",
            "\n",
            "Epoch 35/49\n",
            "----------\n",
            "train Loss: 0.2363 Acc: 0.9172\n",
            "val Loss: 0.7191 Acc: 0.7659\n",
            "\n",
            "Epoch 36/49\n",
            "----------\n",
            "train Loss: 0.2574 Acc: 0.9098\n",
            "val Loss: 0.7122 Acc: 0.7751\n",
            "\n",
            "Epoch 37/49\n",
            "----------\n",
            "train Loss: 0.2173 Acc: 0.9297\n",
            "val Loss: 0.7066 Acc: 0.7773\n",
            "\n",
            "Epoch 38/49\n",
            "----------\n",
            "train Loss: 0.2210 Acc: 0.9260\n",
            "val Loss: 0.7085 Acc: 0.7718\n",
            "\n",
            "Epoch 39/49\n",
            "----------\n",
            "train Loss: 0.2419 Acc: 0.9153\n",
            "val Loss: 0.7229 Acc: 0.7714\n",
            "\n",
            "Epoch 40/49\n",
            "----------\n",
            "train Loss: 0.2314 Acc: 0.9179\n",
            "val Loss: 0.7166 Acc: 0.7736\n",
            "\n",
            "Epoch 41/49\n",
            "----------\n",
            "train Loss: 0.2437 Acc: 0.9139\n",
            "val Loss: 0.7198 Acc: 0.7777\n",
            "\n",
            "Epoch 42/49\n",
            "----------\n",
            "train Loss: 0.2317 Acc: 0.9205\n",
            "val Loss: 0.7148 Acc: 0.7792\n",
            "\n",
            "Epoch 43/49\n",
            "----------\n",
            "train Loss: 0.2368 Acc: 0.9172\n",
            "val Loss: 0.7157 Acc: 0.7711\n",
            "\n",
            "Epoch 44/49\n",
            "----------\n",
            "train Loss: 0.2388 Acc: 0.9172\n",
            "val Loss: 0.7212 Acc: 0.7792\n",
            "\n",
            "Epoch 45/49\n",
            "----------\n",
            "train Loss: 0.2323 Acc: 0.9201\n",
            "val Loss: 0.7143 Acc: 0.7729\n",
            "\n",
            "Epoch 46/49\n",
            "----------\n",
            "train Loss: 0.2446 Acc: 0.9113\n",
            "val Loss: 0.7208 Acc: 0.7714\n",
            "\n",
            "Epoch 47/49\n",
            "----------\n",
            "train Loss: 0.2417 Acc: 0.9128\n",
            "val Loss: 0.7201 Acc: 0.7725\n",
            "\n",
            "Epoch 48/49\n",
            "----------\n",
            "train Loss: 0.2471 Acc: 0.9102\n",
            "val Loss: 0.7176 Acc: 0.7689\n",
            "\n",
            "Epoch 49/49\n",
            "----------\n",
            "train Loss: 0.2295 Acc: 0.9150\n",
            "val Loss: 0.7200 Acc: 0.7725\n",
            "\n",
            "Training complete in 48m 41s\n",
            "Best val Acc: 0.779168\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the best model --> checkpoint\n",
        "torch.save(resnet50_model.state_dict(), \n",
        "           save_models_dir + \"best_resnet50_multistage_train.pt\")"
      ],
      "metadata": {
        "id": "F8awZr-ze0c4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keep...going...(150 epochs)"
      ],
      "metadata": {
        "id": "TDPnXtGklGsN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "resnet50_model = train_model(resnet50_model, criterion, optimizer, exp_lr_scheduler,\n",
        "                       num_epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_t6Bz15lETq",
        "outputId": "c69a93c3-2cb9-495c-e7e8-9d5c616b5677"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/49\n",
            "----------\n",
            "train Loss: 0.2426 Acc: 0.9172\n",
            "val Loss: 0.7228 Acc: 0.7670\n",
            "\n",
            "Epoch 1/49\n",
            "----------\n",
            "train Loss: 0.2324 Acc: 0.9216\n",
            "val Loss: 0.7220 Acc: 0.7692\n",
            "\n",
            "Epoch 2/49\n",
            "----------\n",
            "train Loss: 0.2195 Acc: 0.9264\n",
            "val Loss: 0.7093 Acc: 0.7784\n",
            "\n",
            "Epoch 3/49\n",
            "----------\n",
            "train Loss: 0.2277 Acc: 0.9124\n",
            "val Loss: 0.7207 Acc: 0.7751\n",
            "\n",
            "Epoch 4/49\n",
            "----------\n",
            "train Loss: 0.2209 Acc: 0.9268\n",
            "val Loss: 0.7239 Acc: 0.7652\n",
            "\n",
            "Epoch 5/49\n",
            "----------\n",
            "train Loss: 0.2331 Acc: 0.9220\n",
            "val Loss: 0.7302 Acc: 0.7644\n",
            "\n",
            "Epoch 6/49\n",
            "----------\n",
            "train Loss: 0.2514 Acc: 0.9084\n",
            "val Loss: 0.7318 Acc: 0.7736\n",
            "\n",
            "Epoch 7/49\n",
            "----------\n",
            "train Loss: 0.2234 Acc: 0.9234\n",
            "val Loss: 0.7202 Acc: 0.7722\n",
            "\n",
            "Epoch 8/49\n",
            "----------\n",
            "train Loss: 0.2176 Acc: 0.9290\n",
            "val Loss: 0.7201 Acc: 0.7736\n",
            "\n",
            "Epoch 9/49\n",
            "----------\n",
            "train Loss: 0.2315 Acc: 0.9183\n",
            "val Loss: 0.7291 Acc: 0.7703\n",
            "\n",
            "Epoch 10/49\n",
            "----------\n",
            "train Loss: 0.2199 Acc: 0.9279\n",
            "val Loss: 0.7208 Acc: 0.7788\n",
            "\n",
            "Epoch 11/49\n",
            "----------\n",
            "train Loss: 0.2391 Acc: 0.9165\n",
            "val Loss: 0.7119 Acc: 0.7751\n",
            "\n",
            "Epoch 12/49\n",
            "----------\n",
            "train Loss: 0.2162 Acc: 0.9253\n",
            "val Loss: 0.7250 Acc: 0.7707\n",
            "\n",
            "Epoch 13/49\n",
            "----------\n",
            "train Loss: 0.2155 Acc: 0.9338\n",
            "val Loss: 0.7177 Acc: 0.7729\n",
            "\n",
            "Epoch 14/49\n",
            "----------\n",
            "train Loss: 0.2271 Acc: 0.9190\n",
            "val Loss: 0.7238 Acc: 0.7703\n",
            "\n",
            "Epoch 15/49\n",
            "----------\n",
            "train Loss: 0.1989 Acc: 0.9345\n",
            "val Loss: 0.7212 Acc: 0.7711\n",
            "\n",
            "Epoch 16/49\n",
            "----------\n",
            "train Loss: 0.2272 Acc: 0.9238\n",
            "val Loss: 0.7191 Acc: 0.7718\n",
            "\n",
            "Epoch 17/49\n",
            "----------\n",
            "train Loss: 0.2115 Acc: 0.9271\n",
            "val Loss: 0.7221 Acc: 0.7722\n",
            "\n",
            "Epoch 18/49\n",
            "----------\n",
            "train Loss: 0.2139 Acc: 0.9253\n",
            "val Loss: 0.7345 Acc: 0.7689\n",
            "\n",
            "Epoch 19/49\n",
            "----------\n",
            "train Loss: 0.2246 Acc: 0.9205\n",
            "val Loss: 0.7245 Acc: 0.7733\n",
            "\n",
            "Epoch 20/49\n",
            "----------\n",
            "train Loss: 0.2288 Acc: 0.9279\n",
            "val Loss: 0.7285 Acc: 0.7773\n",
            "\n",
            "Epoch 21/49\n",
            "----------\n",
            "train Loss: 0.2313 Acc: 0.9187\n",
            "val Loss: 0.7236 Acc: 0.7674\n",
            "\n",
            "Epoch 22/49\n",
            "----------\n",
            "train Loss: 0.2454 Acc: 0.9102\n",
            "val Loss: 0.7368 Acc: 0.7659\n",
            "\n",
            "Epoch 23/49\n",
            "----------\n",
            "train Loss: 0.2226 Acc: 0.9231\n",
            "val Loss: 0.7250 Acc: 0.7770\n",
            "\n",
            "Epoch 24/49\n",
            "----------\n",
            "train Loss: 0.2162 Acc: 0.9301\n",
            "val Loss: 0.7260 Acc: 0.7696\n",
            "\n",
            "Epoch 25/49\n",
            "----------\n",
            "train Loss: 0.2271 Acc: 0.9205\n",
            "val Loss: 0.7301 Acc: 0.7718\n",
            "\n",
            "Epoch 26/49\n",
            "----------\n",
            "train Loss: 0.2061 Acc: 0.9286\n",
            "val Loss: 0.7184 Acc: 0.7722\n",
            "\n",
            "Epoch 27/49\n",
            "----------\n",
            "train Loss: 0.2468 Acc: 0.9065\n",
            "val Loss: 0.7269 Acc: 0.7685\n",
            "\n",
            "Epoch 28/49\n",
            "----------\n",
            "train Loss: 0.2168 Acc: 0.9264\n",
            "val Loss: 0.7197 Acc: 0.7670\n",
            "\n",
            "Epoch 29/49\n",
            "----------\n",
            "train Loss: 0.2392 Acc: 0.9165\n",
            "val Loss: 0.7312 Acc: 0.7711\n",
            "\n",
            "Epoch 30/49\n",
            "----------\n",
            "train Loss: 0.2232 Acc: 0.9198\n",
            "val Loss: 0.7255 Acc: 0.7722\n",
            "\n",
            "Epoch 31/49\n",
            "----------\n",
            "train Loss: 0.2288 Acc: 0.9238\n",
            "val Loss: 0.7279 Acc: 0.7696\n",
            "\n",
            "Epoch 32/49\n",
            "----------\n",
            "train Loss: 0.2264 Acc: 0.9198\n",
            "val Loss: 0.7243 Acc: 0.7689\n",
            "\n",
            "Epoch 33/49\n",
            "----------\n",
            "train Loss: 0.2125 Acc: 0.9293\n",
            "val Loss: 0.7248 Acc: 0.7729\n",
            "\n",
            "Epoch 34/49\n",
            "----------\n",
            "train Loss: 0.2151 Acc: 0.9227\n",
            "val Loss: 0.7263 Acc: 0.7729\n",
            "\n",
            "Epoch 35/49\n",
            "----------\n",
            "train Loss: 0.2059 Acc: 0.9282\n",
            "val Loss: 0.7245 Acc: 0.7678\n",
            "\n",
            "Epoch 36/49\n",
            "----------\n",
            "train Loss: 0.2234 Acc: 0.9238\n",
            "val Loss: 0.7341 Acc: 0.7711\n",
            "\n",
            "Epoch 37/49\n",
            "----------\n",
            "train Loss: 0.2270 Acc: 0.9165\n",
            "val Loss: 0.7272 Acc: 0.7689\n",
            "\n",
            "Epoch 38/49\n",
            "----------\n",
            "train Loss: 0.2301 Acc: 0.9205\n",
            "val Loss: 0.7303 Acc: 0.7718\n",
            "\n",
            "Epoch 39/49\n",
            "----------\n",
            "train Loss: 0.2143 Acc: 0.9201\n",
            "val Loss: 0.7214 Acc: 0.7692\n",
            "\n",
            "Epoch 40/49\n",
            "----------\n",
            "train Loss: 0.2304 Acc: 0.9220\n",
            "val Loss: 0.7228 Acc: 0.7674\n",
            "\n",
            "Epoch 41/49\n",
            "----------\n",
            "train Loss: 0.2253 Acc: 0.9216\n",
            "val Loss: 0.7314 Acc: 0.7685\n",
            "\n",
            "Epoch 42/49\n",
            "----------\n",
            "train Loss: 0.2070 Acc: 0.9282\n",
            "val Loss: 0.7108 Acc: 0.7759\n",
            "\n",
            "Epoch 43/49\n",
            "----------\n",
            "train Loss: 0.2069 Acc: 0.9326\n",
            "val Loss: 0.7287 Acc: 0.7689\n",
            "\n",
            "Epoch 44/49\n",
            "----------\n",
            "train Loss: 0.2093 Acc: 0.9282\n",
            "val Loss: 0.7252 Acc: 0.7711\n",
            "\n",
            "Epoch 45/49\n",
            "----------\n",
            "train Loss: 0.2232 Acc: 0.9231\n",
            "val Loss: 0.7247 Acc: 0.7681\n",
            "\n",
            "Epoch 46/49\n",
            "----------\n",
            "train Loss: 0.2212 Acc: 0.9183\n",
            "val Loss: 0.7298 Acc: 0.7667\n",
            "\n",
            "Epoch 47/49\n",
            "----------\n",
            "train Loss: 0.2235 Acc: 0.9231\n",
            "val Loss: 0.7256 Acc: 0.7711\n",
            "\n",
            "Epoch 48/49\n",
            "----------\n",
            "train Loss: 0.2256 Acc: 0.9194\n",
            "val Loss: 0.7326 Acc: 0.7689\n",
            "\n",
            "Epoch 49/49\n",
            "----------\n",
            "train Loss: 0.2142 Acc: 0.9268\n",
            "val Loss: 0.7189 Acc: 0.7725\n",
            "\n",
            "Training complete in 49m 36s\n",
            "Best val Acc: 0.778800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Is it possible to pop out of a local minima?"
      ],
      "metadata": {
        "id": "em0Uja1yxx8L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Observe that all parameters are being optimized --> change for each stage\n",
        "optimizer = optim.Adam(resnet50_model.parameters(), lr=0.0001)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 10 epochs\n",
        "# If don't want to decay, then set the step_size to very high\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.1)"
      ],
      "metadata": {
        "id": "Jv374P2Tx0eg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet50_model = train_model(resnet50_model, criterion, optimizer, exp_lr_scheduler,\n",
        "                       num_epochs=25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLfUM36yyGDf",
        "outputId": "ef5c6f20-2288-470c-84ca-399de24e3aa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/24\n",
            "----------\n",
            "train Loss: 0.4094 Acc: 0.8439\n",
            "val Loss: 0.8726 Acc: 0.7114\n",
            "\n",
            "Epoch 1/24\n",
            "----------\n",
            "train Loss: 0.4034 Acc: 0.8506\n",
            "val Loss: 0.7413 Acc: 0.7460\n",
            "\n",
            "Epoch 2/24\n",
            "----------\n",
            "train Loss: 0.3636 Acc: 0.8690\n",
            "val Loss: 0.8714 Acc: 0.7111\n",
            "\n",
            "Epoch 3/24\n",
            "----------\n",
            "train Loss: 0.3238 Acc: 0.8815\n",
            "val Loss: 0.7631 Acc: 0.7512\n",
            "\n",
            "Epoch 4/24\n",
            "----------\n",
            "train Loss: 0.2946 Acc: 0.8881\n",
            "val Loss: 0.8012 Acc: 0.7563\n",
            "\n",
            "Epoch 5/24\n",
            "----------\n",
            "train Loss: 0.2676 Acc: 0.9021\n",
            "val Loss: 0.8877 Acc: 0.7446\n",
            "\n",
            "Epoch 6/24\n",
            "----------\n",
            "train Loss: 0.2777 Acc: 0.9017\n",
            "val Loss: 0.7746 Acc: 0.7575\n",
            "\n",
            "Epoch 7/24\n",
            "----------\n",
            "train Loss: 0.2391 Acc: 0.9131\n",
            "val Loss: 0.8625 Acc: 0.7332\n",
            "\n",
            "Epoch 8/24\n",
            "----------\n",
            "train Loss: 0.2177 Acc: 0.9172\n",
            "val Loss: 0.8090 Acc: 0.7644\n",
            "\n",
            "Epoch 9/24\n",
            "----------\n",
            "train Loss: 0.2020 Acc: 0.9257\n",
            "val Loss: 0.8628 Acc: 0.7468\n",
            "\n",
            "Epoch 10/24\n",
            "----------\n",
            "train Loss: 0.1783 Acc: 0.9341\n",
            "val Loss: 0.8273 Acc: 0.7711\n",
            "\n",
            "Epoch 11/24\n",
            "----------\n",
            "train Loss: 0.1846 Acc: 0.9356\n",
            "val Loss: 0.8500 Acc: 0.7589\n",
            "\n",
            "Epoch 12/24\n",
            "----------\n",
            "train Loss: 0.1671 Acc: 0.9448\n",
            "val Loss: 0.9176 Acc: 0.7508\n",
            "\n",
            "Epoch 13/24\n",
            "----------\n",
            "train Loss: 0.1399 Acc: 0.9525\n",
            "val Loss: 0.9268 Acc: 0.7685\n",
            "\n",
            "Epoch 14/24\n",
            "----------\n",
            "train Loss: 0.1476 Acc: 0.9496\n",
            "val Loss: 0.9419 Acc: 0.7556\n",
            "\n",
            "Epoch 15/24\n",
            "----------\n",
            "train Loss: 0.1302 Acc: 0.9503\n",
            "val Loss: 0.8465 Acc: 0.7751\n",
            "\n",
            "Epoch 16/24\n",
            "----------\n",
            "train Loss: 0.1496 Acc: 0.9496\n",
            "val Loss: 0.9154 Acc: 0.7597\n",
            "\n",
            "Epoch 17/24\n",
            "----------\n",
            "train Loss: 0.1312 Acc: 0.9544\n",
            "val Loss: 0.8729 Acc: 0.7770\n",
            "\n",
            "Epoch 18/24\n",
            "----------\n",
            "train Loss: 0.1263 Acc: 0.9573\n",
            "val Loss: 0.8573 Acc: 0.7748\n",
            "\n",
            "Epoch 19/24\n",
            "----------\n",
            "train Loss: 0.1209 Acc: 0.9566\n",
            "val Loss: 0.9158 Acc: 0.7836\n",
            "\n",
            "Epoch 20/24\n",
            "----------\n",
            "train Loss: 0.0998 Acc: 0.9647\n",
            "val Loss: 0.8842 Acc: 0.7843\n",
            "\n",
            "Epoch 21/24\n",
            "----------\n",
            "train Loss: 0.1205 Acc: 0.9577\n",
            "val Loss: 0.8931 Acc: 0.7748\n",
            "\n",
            "Epoch 22/24\n",
            "----------\n",
            "train Loss: 0.0914 Acc: 0.9672\n",
            "val Loss: 0.8759 Acc: 0.7799\n",
            "\n",
            "Epoch 23/24\n",
            "----------\n",
            "train Loss: 0.0946 Acc: 0.9698\n",
            "val Loss: 0.9210 Acc: 0.7714\n",
            "\n",
            "Epoch 24/24\n",
            "----------\n",
            "train Loss: 0.0813 Acc: 0.9742\n",
            "val Loss: 0.9439 Acc: 0.7685\n",
            "\n",
            "Training complete in 24m 50s\n",
            "Best val Acc: 0.784321\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the best model\n",
        "torch.save(resnet50_model.state_dict(), \n",
        "           save_models_dir + \"best_resnet50_multistage_train_incrLRlate.pt\")"
      ],
      "metadata": {
        "id": "ggcQUZdb3VUe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## With separate train and validation data transforms. Increased train data augmentations with training-only transforms. And previous features (Adam Optim + Address Class Imbalance)"
      ],
      "metadata": {
        "id": "nH9RtY2r7Tuq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft = models.resnet50(weights=\"DEFAULT\")\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "\n",
        "model_ft.fc = nn.Linear(num_ftrs, 5)\n",
        "\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.0001)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 10 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "32f8271547304ae1aafb32310ff54c35",
            "734ac6165a9249c5876a457c212c1c60",
            "403e4715220f42adb25fac4c2695cc46",
            "54fdd649fd0441e8855f80e69afa7a50",
            "375655f7cc0b4d2e9498cf40c83e2c5e",
            "a173dd845f14489796f89577e68eed54",
            "2906782e87044fbd9288de5fb7376265",
            "59da3b6759ac40d8b8bfab58f063a14b",
            "751fc6f6fd7941e88fb44e2a5fd92d8a",
            "10c07aea6b4a4bcf86b5a12700bceee3",
            "eb7355fc9d0148aea10690fe49eb8232"
          ]
        },
        "id": "3F1ZA1Nz7g0I",
        "outputId": "e11eca48-b820-4bac-8839-46aceae298fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "32f8271547304ae1aafb32310ff54c35"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
        "                       num_epochs=25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0It6fTiv7l3h",
        "outputId": "fbccfcc4-3d73-489f-e45e-8fa96b437d49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/24\n",
            "----------\n",
            "train Loss: 1.4243 Acc: 0.4218\n",
            "val Loss: 1.2147 Acc: 0.5661\n",
            "\n",
            "Epoch 1/24\n",
            "----------\n",
            "train Loss: 0.9581 Acc: 0.6143\n",
            "val Loss: 0.8882 Acc: 0.6768\n",
            "\n",
            "Epoch 2/24\n",
            "----------\n",
            "train Loss: 0.7908 Acc: 0.7011\n",
            "val Loss: 0.7619 Acc: 0.7151\n",
            "\n",
            "Epoch 3/24\n",
            "----------\n",
            "train Loss: 0.6667 Acc: 0.7321\n",
            "val Loss: 0.7221 Acc: 0.7247\n",
            "\n",
            "Epoch 4/24\n",
            "----------\n",
            "train Loss: 0.5804 Acc: 0.7781\n",
            "val Loss: 0.7499 Acc: 0.7173\n",
            "\n",
            "Epoch 5/24\n",
            "----------\n",
            "train Loss: 0.5681 Acc: 0.7755\n",
            "val Loss: 0.6627 Acc: 0.7604\n",
            "\n",
            "Epoch 6/24\n",
            "----------\n",
            "train Loss: 0.4890 Acc: 0.8116\n",
            "val Loss: 0.6639 Acc: 0.7586\n",
            "\n",
            "Epoch 7/24\n",
            "----------\n",
            "train Loss: 0.4474 Acc: 0.8307\n",
            "val Loss: 0.6518 Acc: 0.7714\n",
            "\n",
            "Epoch 8/24\n",
            "----------\n",
            "train Loss: 0.4122 Acc: 0.8480\n",
            "val Loss: 0.6306 Acc: 0.7740\n",
            "\n",
            "Epoch 9/24\n",
            "----------\n",
            "train Loss: 0.3784 Acc: 0.8568\n",
            "val Loss: 0.7550 Acc: 0.7357\n",
            "\n",
            "Epoch 10/24\n",
            "----------\n",
            "train Loss: 0.2972 Acc: 0.8866\n",
            "val Loss: 0.6556 Acc: 0.7733\n",
            "\n",
            "Epoch 11/24\n",
            "----------\n",
            "train Loss: 0.2967 Acc: 0.8911\n",
            "val Loss: 0.6457 Acc: 0.7770\n",
            "\n",
            "Epoch 12/24\n",
            "----------\n",
            "train Loss: 0.2564 Acc: 0.9073\n",
            "val Loss: 0.6448 Acc: 0.7751\n",
            "\n",
            "Epoch 13/24\n",
            "----------\n",
            "train Loss: 0.2373 Acc: 0.9128\n",
            "val Loss: 0.6479 Acc: 0.7784\n",
            "\n",
            "Epoch 14/24\n",
            "----------\n",
            "train Loss: 0.2363 Acc: 0.9216\n",
            "val Loss: 0.6541 Acc: 0.7777\n",
            "\n",
            "Epoch 15/24\n",
            "----------\n",
            "train Loss: 0.2358 Acc: 0.9238\n",
            "val Loss: 0.6547 Acc: 0.7773\n",
            "\n",
            "Epoch 16/24\n",
            "----------\n",
            "train Loss: 0.2177 Acc: 0.9260\n",
            "val Loss: 0.6610 Acc: 0.7810\n",
            "\n",
            "Epoch 17/24\n",
            "----------\n",
            "train Loss: 0.2026 Acc: 0.9323\n",
            "val Loss: 0.6654 Acc: 0.7759\n",
            "\n",
            "Epoch 18/24\n",
            "----------\n",
            "train Loss: 0.2096 Acc: 0.9260\n",
            "val Loss: 0.6708 Acc: 0.7777\n",
            "\n",
            "Epoch 19/24\n",
            "----------\n",
            "train Loss: 0.2003 Acc: 0.9301\n",
            "val Loss: 0.6764 Acc: 0.7736\n",
            "\n",
            "Epoch 20/24\n",
            "----------\n",
            "train Loss: 0.2085 Acc: 0.9297\n",
            "val Loss: 0.6765 Acc: 0.7773\n",
            "\n",
            "Epoch 21/24\n",
            "----------\n",
            "train Loss: 0.1875 Acc: 0.9345\n",
            "val Loss: 0.6704 Acc: 0.7788\n",
            "\n",
            "Epoch 22/24\n",
            "----------\n",
            "train Loss: 0.2021 Acc: 0.9312\n",
            "val Loss: 0.6785 Acc: 0.7777\n",
            "\n",
            "Epoch 23/24\n",
            "----------\n",
            "train Loss: 0.1718 Acc: 0.9382\n",
            "val Loss: 0.6751 Acc: 0.7733\n",
            "\n",
            "Epoch 24/24\n",
            "----------\n",
            "train Loss: 0.1793 Acc: 0.9396\n",
            "val Loss: 0.6753 Acc: 0.7795\n",
            "\n",
            "Training complete in 26m 8s\n",
            "Best val Acc: 0.781008\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the best model\n",
        "torch.save(model_ft.state_dict(), '/content/drive/MyDrive/ML for BDS/Hackathon - graddiss/best_resnet50_balanced_AdamOptim.pt')"
      ],
      "metadata": {
        "id": "7iK4RcMs7twg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## With the RandomWeightedSample (i.e. addressing class imbalance) + Adam Optimizer"
      ],
      "metadata": {
        "id": "0CLPWGZKAY_d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft = models.resnet50(weights=\"DEFAULT\")\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "\n",
        "model_ft.fc = nn.Linear(num_ftrs, 5)\n",
        "\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.0001)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 10 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)"
      ],
      "metadata": {
        "id": "_Ls2KyntE8-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
        "                       num_epochs=25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUVgP_pVFHq-",
        "outputId": "31681253-cf6a-4f6b-a982-82cf4ccf5fc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/24\n",
            "----------\n",
            "train Loss: 1.3826 Acc: 0.4682\n",
            "val Loss: 1.4448 Acc: 0.4269\n",
            "\n",
            "Epoch 1/24\n",
            "----------\n",
            "train Loss: 0.8711 Acc: 0.6989\n",
            "val Loss: 0.9535 Acc: 0.6511\n",
            "\n",
            "Epoch 2/24\n",
            "----------\n",
            "train Loss: 0.5757 Acc: 0.7968\n",
            "val Loss: 0.8412 Acc: 0.6835\n",
            "\n",
            "Epoch 3/24\n",
            "----------\n",
            "train Loss: 0.3476 Acc: 0.8929\n",
            "val Loss: 0.8667 Acc: 0.7067\n",
            "\n",
            "Epoch 4/24\n",
            "----------\n",
            "train Loss: 0.2713 Acc: 0.9124\n",
            "val Loss: 0.8027 Acc: 0.7206\n",
            "\n",
            "Epoch 5/24\n",
            "----------\n",
            "train Loss: 0.1595 Acc: 0.9547\n",
            "val Loss: 0.8914 Acc: 0.7236\n",
            "\n",
            "Epoch 6/24\n",
            "----------\n",
            "train Loss: 0.1518 Acc: 0.9533\n",
            "val Loss: 0.8893 Acc: 0.7192\n",
            "\n",
            "Epoch 7/24\n",
            "----------\n",
            "train Loss: 0.1182 Acc: 0.9647\n",
            "val Loss: 0.8691 Acc: 0.7306\n",
            "\n",
            "Epoch 8/24\n",
            "----------\n",
            "train Loss: 0.0703 Acc: 0.9779\n",
            "val Loss: 1.0150 Acc: 0.7328\n",
            "\n",
            "Epoch 9/24\n",
            "----------\n",
            "train Loss: 0.0557 Acc: 0.9838\n",
            "val Loss: 0.9582 Acc: 0.7357\n",
            "\n",
            "Epoch 10/24\n",
            "----------\n",
            "train Loss: 0.0531 Acc: 0.9845\n",
            "val Loss: 0.9877 Acc: 0.7527\n",
            "\n",
            "Epoch 11/24\n",
            "----------\n",
            "train Loss: 0.0314 Acc: 0.9919\n",
            "val Loss: 1.0010 Acc: 0.7516\n",
            "\n",
            "Epoch 12/24\n",
            "----------\n",
            "train Loss: 0.0269 Acc: 0.9937\n",
            "val Loss: 0.9967 Acc: 0.7527\n",
            "\n",
            "Epoch 13/24\n",
            "----------\n",
            "train Loss: 0.0198 Acc: 0.9952\n",
            "val Loss: 0.9955 Acc: 0.7563\n",
            "\n",
            "Epoch 14/24\n",
            "----------\n",
            "train Loss: 0.0198 Acc: 0.9960\n",
            "val Loss: 0.9735 Acc: 0.7567\n",
            "\n",
            "Epoch 15/24\n",
            "----------\n",
            "train Loss: 0.0210 Acc: 0.9937\n",
            "val Loss: 0.9982 Acc: 0.7560\n",
            "\n",
            "Epoch 16/24\n",
            "----------\n",
            "train Loss: 0.0165 Acc: 0.9971\n",
            "val Loss: 0.9785 Acc: 0.7571\n",
            "\n",
            "Epoch 17/24\n",
            "----------\n",
            "train Loss: 0.0138 Acc: 0.9978\n",
            "val Loss: 0.9923 Acc: 0.7563\n",
            "\n",
            "Epoch 18/24\n",
            "----------\n",
            "train Loss: 0.0149 Acc: 0.9974\n",
            "val Loss: 1.0104 Acc: 0.7530\n",
            "\n",
            "Epoch 19/24\n",
            "----------\n",
            "train Loss: 0.0115 Acc: 0.9982\n",
            "val Loss: 1.0271 Acc: 0.7541\n",
            "\n",
            "Epoch 20/24\n",
            "----------\n",
            "train Loss: 0.0129 Acc: 0.9967\n",
            "val Loss: 1.0137 Acc: 0.7575\n",
            "\n",
            "Epoch 21/24\n",
            "----------\n",
            "train Loss: 0.0132 Acc: 0.9974\n",
            "val Loss: 1.0153 Acc: 0.7549\n",
            "\n",
            "Epoch 22/24\n",
            "----------\n",
            "train Loss: 0.0160 Acc: 0.9971\n",
            "val Loss: 0.9941 Acc: 0.7586\n",
            "\n",
            "Epoch 23/24\n",
            "----------\n",
            "train Loss: 0.0123 Acc: 0.9974\n",
            "val Loss: 1.0126 Acc: 0.7600\n",
            "\n",
            "Epoch 24/24\n",
            "----------\n",
            "train Loss: 0.0162 Acc: 0.9952\n",
            "val Loss: 1.0401 Acc: 0.7486\n",
            "\n",
            "Training complete in 17m 24s\n",
            "Best val Acc: 0.760029\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the best model\n",
        "torch.save(model_ft.state_dict(), '/content/drive/MyDrive/ML for BDS/Hackathon - graddiss/best_resnet50_balanced_AdamOptim.pt')"
      ],
      "metadata": {
        "id": "GoLy1pbDG_wk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## With preliminary class balancing using a RandomWeightedSample (see above)"
      ],
      "metadata": {
        "id": "u0i4jm-wNOjd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft = models.resnet50(weights=\"DEFAULT\")\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "\n",
        "model_ft.fc = nn.Linear(num_ftrs, 5)\n",
        "\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 10 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "0b834068d5494a1986b60b35f8907b23",
            "d1fdb6f6cf8146779d342b0021bb4853",
            "a5b587fa9c0a4949b2a51bac7c8bc31e",
            "2c1a5dfa3fc6450b82f173fefadbb866",
            "8d6ac9fb1a9b4bcdb0030f2eef286412",
            "20bde88faca84ce489d5b57b6aaf6a77",
            "9ef2aab606b84a3190690cac3970d3eb",
            "7a97f915392649bdbb556f1ef741c576",
            "2981e1b0a1b6422db473944e5d277f0e",
            "111c3849277a48fc96e1c9192792a526",
            "8bcb5f05c5614cdb8277c0eebe1858f3"
          ]
        },
        "id": "Qct4jGoINIDt",
        "outputId": "dbe70b69-73a2-42d7-828b-441d2a269097"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0b834068d5494a1986b60b35f8907b23"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
        "                       num_epochs=25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bU7rzGE6Spc",
        "outputId": "8af872b4-0ce2-4013-cfec-0aa817598aba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/24\n",
            "----------\n",
            "train Loss: 1.5758 Acc: 0.2827\n",
            "val Loss: 1.5102 Acc: 0.4895\n",
            "\n",
            "Epoch 1/24\n",
            "----------\n",
            "train Loss: 1.4501 Acc: 0.4008\n",
            "val Loss: 1.3647 Acc: 0.4895\n",
            "\n",
            "Epoch 2/24\n",
            "----------\n",
            "train Loss: 1.3602 Acc: 0.4623\n",
            "val Loss: 1.2716 Acc: 0.5215\n",
            "\n",
            "Epoch 3/24\n",
            "----------\n",
            "train Loss: 1.2926 Acc: 0.4807\n",
            "val Loss: 1.2811 Acc: 0.5285\n",
            "\n",
            "Epoch 4/24\n",
            "----------\n",
            "train Loss: 1.2216 Acc: 0.5392\n",
            "val Loss: 1.2410 Acc: 0.5326\n",
            "\n",
            "Epoch 5/24\n",
            "----------\n",
            "train Loss: 1.1188 Acc: 0.5709\n",
            "val Loss: 1.1484 Acc: 0.5661\n",
            "\n",
            "Epoch 6/24\n",
            "----------\n",
            "train Loss: 1.0317 Acc: 0.6301\n",
            "val Loss: 1.0408 Acc: 0.6032\n",
            "\n",
            "Epoch 7/24\n",
            "----------\n",
            "train Loss: 0.9633 Acc: 0.6445\n",
            "val Loss: 1.0629 Acc: 0.5918\n",
            "\n",
            "Epoch 8/24\n",
            "----------\n",
            "train Loss: 0.8968 Acc: 0.6699\n",
            "val Loss: 0.9713 Acc: 0.6275\n",
            "\n",
            "Epoch 9/24\n",
            "----------\n",
            "train Loss: 0.7644 Acc: 0.7302\n",
            "val Loss: 0.9305 Acc: 0.6378\n",
            "\n",
            "Epoch 10/24\n",
            "----------\n",
            "train Loss: 0.7036 Acc: 0.7523\n",
            "val Loss: 0.9019 Acc: 0.6456\n",
            "\n",
            "Epoch 11/24\n",
            "----------\n",
            "train Loss: 0.6986 Acc: 0.7622\n",
            "val Loss: 0.8945 Acc: 0.6529\n",
            "\n",
            "Epoch 12/24\n",
            "----------\n",
            "train Loss: 0.6696 Acc: 0.7696\n",
            "val Loss: 0.8854 Acc: 0.6566\n",
            "\n",
            "Epoch 13/24\n",
            "----------\n",
            "train Loss: 0.6539 Acc: 0.7674\n",
            "val Loss: 0.8753 Acc: 0.6632\n",
            "\n",
            "Epoch 14/24\n",
            "----------\n",
            "train Loss: 0.6674 Acc: 0.7696\n",
            "val Loss: 0.8679 Acc: 0.6699\n",
            "\n",
            "Epoch 15/24\n",
            "----------\n",
            "train Loss: 0.6593 Acc: 0.7714\n",
            "val Loss: 0.8688 Acc: 0.6702\n",
            "\n",
            "Epoch 16/24\n",
            "----------\n",
            "train Loss: 0.6203 Acc: 0.7972\n",
            "val Loss: 0.8603 Acc: 0.6669\n",
            "\n",
            "Epoch 17/24\n",
            "----------\n",
            "train Loss: 0.6312 Acc: 0.7898\n",
            "val Loss: 0.8572 Acc: 0.6654\n",
            "\n",
            "Epoch 18/24\n",
            "----------\n",
            "train Loss: 0.6201 Acc: 0.7954\n",
            "val Loss: 0.8655 Acc: 0.6665\n",
            "\n",
            "Epoch 19/24\n",
            "----------\n",
            "train Loss: 0.6179 Acc: 0.7957\n",
            "val Loss: 0.8708 Acc: 0.6618\n",
            "\n",
            "Epoch 20/24\n",
            "----------\n",
            "train Loss: 0.5882 Acc: 0.8167\n",
            "val Loss: 0.8419 Acc: 0.6791\n",
            "\n",
            "Epoch 21/24\n",
            "----------\n",
            "train Loss: 0.5895 Acc: 0.8079\n",
            "val Loss: 0.8680 Acc: 0.6673\n",
            "\n",
            "Epoch 22/24\n",
            "----------\n",
            "train Loss: 0.5773 Acc: 0.8086\n",
            "val Loss: 0.8676 Acc: 0.6684\n",
            "\n",
            "Epoch 23/24\n",
            "----------\n",
            "train Loss: 0.5740 Acc: 0.7998\n",
            "val Loss: 0.8562 Acc: 0.6721\n",
            "\n",
            "Epoch 24/24\n",
            "----------\n",
            "train Loss: 0.5921 Acc: 0.8013\n",
            "val Loss: 0.8540 Acc: 0.6728\n",
            "\n",
            "Training complete in 17m 17s\n",
            "Best val Acc: 0.679058\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the best model\n",
        "torch.save(model_ft.state_dict(), '/content/drive/MyDrive/ML for BDS/Hackathon - graddiss/best_resnet50_balanced_model.pt')"
      ],
      "metadata": {
        "id": "cqUz85xqAYhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The following is 50 epochs, preliminary balanced dataset, and SGD optimizer "
      ],
      "metadata": {
        "id": "QoqKxD3g6Vge"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
        "                       num_epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCB9LxcIky0_",
        "outputId": "d3bb2521-54f3-497f-df7f-43b9d576b7a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/49\n",
            "----------\n",
            "train Loss: 1.5786 Acc: 0.2867\n",
            "val Loss: 1.5297 Acc: 0.3828\n",
            "\n",
            "Epoch 1/49\n",
            "----------\n",
            "train Loss: 1.4890 Acc: 0.3563\n",
            "val Loss: 1.3771 Acc: 0.4505\n",
            "\n",
            "Epoch 2/49\n",
            "----------\n",
            "train Loss: 1.4008 Acc: 0.4085\n",
            "val Loss: 1.3282 Acc: 0.4796\n",
            "\n",
            "Epoch 3/49\n",
            "----------\n",
            "train Loss: 1.3996 Acc: 0.4148\n",
            "val Loss: 1.2348 Acc: 0.5013\n",
            "\n",
            "Epoch 4/49\n",
            "----------\n",
            "train Loss: 1.3535 Acc: 0.4442\n",
            "val Loss: 1.2306 Acc: 0.5098\n",
            "\n",
            "Epoch 5/49\n",
            "----------\n",
            "train Loss: 1.3219 Acc: 0.4619\n",
            "val Loss: 1.1829 Acc: 0.5370\n",
            "\n",
            "Epoch 6/49\n",
            "----------\n",
            "train Loss: 1.2694 Acc: 0.4902\n",
            "val Loss: 1.2848 Acc: 0.5098\n",
            "\n",
            "Epoch 7/49\n",
            "----------\n",
            "train Loss: 1.2611 Acc: 0.4925\n",
            "val Loss: 1.1739 Acc: 0.5477\n",
            "\n",
            "Epoch 8/49\n",
            "----------\n",
            "train Loss: 1.2176 Acc: 0.5090\n",
            "val Loss: 1.1132 Acc: 0.5697\n",
            "\n",
            "Epoch 9/49\n",
            "----------\n",
            "train Loss: 1.1562 Acc: 0.5425\n",
            "val Loss: 1.0910 Acc: 0.5841\n",
            "\n",
            "Epoch 10/49\n",
            "----------\n",
            "train Loss: 1.1426 Acc: 0.5561\n",
            "val Loss: 1.0720 Acc: 0.5852\n",
            "\n",
            "Epoch 11/49\n",
            "----------\n",
            "train Loss: 1.1188 Acc: 0.5657\n",
            "val Loss: 1.0427 Acc: 0.6077\n",
            "\n",
            "Epoch 12/49\n",
            "----------\n",
            "train Loss: 1.1304 Acc: 0.5455\n",
            "val Loss: 1.0236 Acc: 0.6018\n",
            "\n",
            "Epoch 13/49\n",
            "----------\n",
            "train Loss: 1.1296 Acc: 0.5506\n",
            "val Loss: 1.0405 Acc: 0.5999\n",
            "\n",
            "Epoch 14/49\n",
            "----------\n",
            "train Loss: 1.1021 Acc: 0.5594\n",
            "val Loss: 1.0188 Acc: 0.6054\n",
            "\n",
            "Epoch 15/49\n",
            "----------\n",
            "train Loss: 1.0902 Acc: 0.5701\n",
            "val Loss: 1.0370 Acc: 0.6066\n",
            "\n",
            "Epoch 16/49\n",
            "----------\n",
            "train Loss: 1.1078 Acc: 0.5543\n",
            "val Loss: 1.0328 Acc: 0.5951\n",
            "\n",
            "Epoch 17/49\n",
            "----------\n",
            "train Loss: 1.0776 Acc: 0.5812\n",
            "val Loss: 1.0217 Acc: 0.6121\n",
            "\n",
            "Epoch 18/49\n",
            "----------\n",
            "train Loss: 1.0980 Acc: 0.5734\n",
            "val Loss: 1.0214 Acc: 0.6051\n",
            "\n",
            "Epoch 19/49\n",
            "----------\n",
            "train Loss: 1.0720 Acc: 0.5834\n",
            "val Loss: 1.0195 Acc: 0.6143\n",
            "\n",
            "Epoch 20/49\n",
            "----------\n",
            "train Loss: 1.0934 Acc: 0.5642\n",
            "val Loss: 0.9937 Acc: 0.6268\n",
            "\n",
            "Epoch 21/49\n",
            "----------\n",
            "train Loss: 1.0703 Acc: 0.5797\n",
            "val Loss: 0.9904 Acc: 0.6139\n",
            "\n",
            "Epoch 22/49\n",
            "----------\n",
            "train Loss: 1.0704 Acc: 0.5764\n",
            "val Loss: 1.0000 Acc: 0.6113\n",
            "\n",
            "Epoch 23/49\n",
            "----------\n",
            "train Loss: 1.0899 Acc: 0.5642\n",
            "val Loss: 0.9922 Acc: 0.6161\n",
            "\n",
            "Epoch 24/49\n",
            "----------\n",
            "train Loss: 1.0705 Acc: 0.5801\n",
            "val Loss: 1.0188 Acc: 0.6054\n",
            "\n",
            "Epoch 25/49\n",
            "----------\n",
            "train Loss: 1.0574 Acc: 0.5937\n",
            "val Loss: 1.0082 Acc: 0.6088\n",
            "\n",
            "Epoch 26/49\n",
            "----------\n",
            "train Loss: 1.0944 Acc: 0.5605\n",
            "val Loss: 1.0142 Acc: 0.6146\n",
            "\n",
            "Epoch 27/49\n",
            "----------\n",
            "train Loss: 1.0535 Acc: 0.5933\n",
            "val Loss: 0.9933 Acc: 0.6205\n",
            "\n",
            "Epoch 28/49\n",
            "----------\n",
            "train Loss: 1.0686 Acc: 0.5804\n",
            "val Loss: 1.0266 Acc: 0.6073\n",
            "\n",
            "Epoch 29/49\n",
            "----------\n",
            "train Loss: 1.0608 Acc: 0.5907\n",
            "val Loss: 0.9986 Acc: 0.6139\n",
            "\n",
            "Epoch 30/49\n",
            "----------\n",
            "train Loss: 1.0726 Acc: 0.5786\n",
            "val Loss: 0.9861 Acc: 0.6128\n",
            "\n",
            "Epoch 31/49\n",
            "----------\n",
            "train Loss: 1.1040 Acc: 0.5565\n",
            "val Loss: 1.0156 Acc: 0.6025\n",
            "\n",
            "Epoch 32/49\n",
            "----------\n",
            "train Loss: 1.0903 Acc: 0.5624\n",
            "val Loss: 0.9880 Acc: 0.6135\n",
            "\n",
            "Epoch 33/49\n",
            "----------\n",
            "train Loss: 1.0915 Acc: 0.5723\n",
            "val Loss: 1.0048 Acc: 0.6054\n",
            "\n",
            "Epoch 34/49\n",
            "----------\n",
            "train Loss: 1.0740 Acc: 0.5738\n",
            "val Loss: 1.0066 Acc: 0.6066\n",
            "\n",
            "Epoch 35/49\n",
            "----------\n",
            "train Loss: 1.0816 Acc: 0.5823\n",
            "val Loss: 0.9997 Acc: 0.6165\n",
            "\n",
            "Epoch 36/49\n",
            "----------\n",
            "train Loss: 1.0726 Acc: 0.5635\n",
            "val Loss: 0.9999 Acc: 0.6066\n",
            "\n",
            "Epoch 37/49\n",
            "----------\n",
            "train Loss: 1.1016 Acc: 0.5506\n",
            "val Loss: 1.0034 Acc: 0.6172\n",
            "\n",
            "Epoch 38/49\n",
            "----------\n",
            "train Loss: 1.0697 Acc: 0.5904\n",
            "val Loss: 1.0119 Acc: 0.6073\n",
            "\n",
            "Epoch 39/49\n",
            "----------\n",
            "train Loss: 1.0663 Acc: 0.5697\n",
            "val Loss: 1.0055 Acc: 0.6139\n",
            "\n",
            "Epoch 40/49\n",
            "----------\n",
            "train Loss: 1.0956 Acc: 0.5558\n",
            "val Loss: 1.0049 Acc: 0.6117\n",
            "\n",
            "Epoch 41/49\n",
            "----------\n",
            "train Loss: 1.0882 Acc: 0.5753\n",
            "val Loss: 0.9967 Acc: 0.6095\n",
            "\n",
            "Epoch 42/49\n",
            "----------\n",
            "train Loss: 1.0965 Acc: 0.5683\n",
            "val Loss: 1.0041 Acc: 0.6069\n",
            "\n",
            "Epoch 43/49\n",
            "----------\n",
            "train Loss: 1.0792 Acc: 0.5653\n",
            "val Loss: 0.9990 Acc: 0.6172\n",
            "\n",
            "Epoch 44/49\n",
            "----------\n",
            "train Loss: 1.0923 Acc: 0.5723\n",
            "val Loss: 1.0057 Acc: 0.6062\n",
            "\n",
            "Epoch 45/49\n",
            "----------\n",
            "train Loss: 1.0869 Acc: 0.5731\n",
            "val Loss: 1.0080 Acc: 0.6169\n",
            "\n",
            "Epoch 46/49\n",
            "----------\n",
            "train Loss: 1.0573 Acc: 0.5904\n",
            "val Loss: 1.0138 Acc: 0.6077\n",
            "\n",
            "Epoch 47/49\n",
            "----------\n",
            "train Loss: 1.0894 Acc: 0.5683\n",
            "val Loss: 1.0173 Acc: 0.6040\n",
            "\n",
            "Epoch 48/49\n",
            "----------\n",
            "train Loss: 1.0910 Acc: 0.5793\n",
            "val Loss: 0.9928 Acc: 0.6113\n",
            "\n",
            "Epoch 49/49\n",
            "----------\n",
            "train Loss: 1.0702 Acc: 0.5830\n",
            "val Loss: 1.0080 Acc: 0.6117\n",
            "\n",
            "Training complete in 34m 3s\n",
            "Best val Acc: 0.626794\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the best model\n",
        "torch.save(model_ft.state_dict(), '/content/drive/MyDrive/ML for BDS/Hackathon - graddiss/best_resnet50_balanced_model_50epochs.pt')"
      ],
      "metadata": {
        "id": "D_VPA5RBmS9C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Older code for 25 epochs (not yet addressing class imbalance)"
      ],
      "metadata": {
        "id": "SeF5NuYsk9Y5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
        "                       num_epochs=25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkJ3tTdmNLBA",
        "outputId": "1d0728d2-d9b6-4773-d351-a82b096d3098"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/24\n",
            "----------\n",
            "train Loss: 1.5717 Acc: 0.2908\n",
            "val Loss: 1.4866 Acc: 0.4468\n",
            "\n",
            "Epoch 1/24\n",
            "----------\n",
            "train Loss: 1.4874 Acc: 0.3658\n",
            "val Loss: 1.3742 Acc: 0.4707\n",
            "\n",
            "Epoch 2/24\n",
            "----------\n",
            "train Loss: 1.4528 Acc: 0.3780\n",
            "val Loss: 1.3592 Acc: 0.4634\n",
            "\n",
            "Epoch 3/24\n",
            "----------\n",
            "train Loss: 1.4139 Acc: 0.4130\n",
            "val Loss: 1.3409 Acc: 0.4663\n",
            "\n",
            "Epoch 4/24\n",
            "----------\n",
            "train Loss: 1.3500 Acc: 0.4424\n",
            "val Loss: 1.2601 Acc: 0.5138\n",
            "\n",
            "Epoch 5/24\n",
            "----------\n",
            "train Loss: 1.3262 Acc: 0.4579\n",
            "val Loss: 1.2356 Acc: 0.5120\n",
            "\n",
            "Epoch 6/24\n",
            "----------\n",
            "train Loss: 1.3203 Acc: 0.4608\n",
            "val Loss: 1.2636 Acc: 0.4976\n",
            "\n",
            "Epoch 7/24\n",
            "----------\n",
            "train Loss: 1.2598 Acc: 0.4785\n",
            "val Loss: 1.2206 Acc: 0.5013\n",
            "\n",
            "Epoch 8/24\n",
            "----------\n",
            "train Loss: 1.2279 Acc: 0.5190\n",
            "val Loss: 1.1969 Acc: 0.5377\n",
            "\n",
            "Epoch 9/24\n",
            "----------\n",
            "train Loss: 1.1764 Acc: 0.5285\n",
            "val Loss: 1.1718 Acc: 0.5388\n",
            "\n",
            "Epoch 10/24\n",
            "----------\n",
            "train Loss: 1.1358 Acc: 0.5536\n",
            "val Loss: 1.1716 Acc: 0.5477\n",
            "\n",
            "Epoch 11/24\n",
            "----------\n",
            "train Loss: 1.1513 Acc: 0.5429\n",
            "val Loss: 1.1349 Acc: 0.5521\n",
            "\n",
            "Epoch 12/24\n",
            "----------\n",
            "train Loss: 1.1296 Acc: 0.5683\n",
            "val Loss: 1.1202 Acc: 0.5631\n",
            "\n",
            "Epoch 13/24\n",
            "----------\n",
            "train Loss: 1.1430 Acc: 0.5451\n",
            "val Loss: 1.1244 Acc: 0.5554\n",
            "\n",
            "Epoch 14/24\n",
            "----------\n",
            "train Loss: 1.1278 Acc: 0.5532\n",
            "val Loss: 1.1025 Acc: 0.5723\n",
            "\n",
            "Epoch 15/24\n",
            "----------\n",
            "train Loss: 1.1255 Acc: 0.5429\n",
            "val Loss: 1.1033 Acc: 0.5764\n",
            "\n",
            "Epoch 16/24\n",
            "----------\n",
            "train Loss: 1.1066 Acc: 0.5646\n",
            "val Loss: 1.1044 Acc: 0.5646\n",
            "\n",
            "Epoch 17/24\n",
            "----------\n",
            "train Loss: 1.1341 Acc: 0.5499\n",
            "val Loss: 1.0867 Acc: 0.5789\n",
            "\n",
            "Epoch 18/24\n",
            "----------\n",
            "train Loss: 1.1197 Acc: 0.5624\n",
            "val Loss: 1.0979 Acc: 0.5731\n",
            "\n",
            "Epoch 19/24\n",
            "----------\n",
            "train Loss: 1.1235 Acc: 0.5543\n",
            "val Loss: 1.0926 Acc: 0.5720\n",
            "\n",
            "Epoch 20/24\n",
            "----------\n",
            "train Loss: 1.1062 Acc: 0.5613\n",
            "val Loss: 1.1034 Acc: 0.5709\n",
            "\n",
            "Epoch 21/24\n",
            "----------\n",
            "train Loss: 1.1022 Acc: 0.5561\n",
            "val Loss: 1.0781 Acc: 0.5845\n",
            "\n",
            "Epoch 22/24\n",
            "----------\n",
            "train Loss: 1.1459 Acc: 0.5421\n",
            "val Loss: 1.0939 Acc: 0.5775\n",
            "\n",
            "Epoch 23/24\n",
            "----------\n",
            "train Loss: 1.1262 Acc: 0.5583\n",
            "val Loss: 1.0846 Acc: 0.5815\n",
            "\n",
            "Epoch 24/24\n",
            "----------\n",
            "train Loss: 1.1150 Acc: 0.5554\n",
            "val Loss: 1.1120 Acc: 0.5565\n",
            "\n",
            "Training complete in 16m 38s\n",
            "Best val Acc: 0.584468\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the best model\n",
        "torch.save(model_ft.state_dict(), '/content/drive/MyDrive/ML for BDS/Hackathon - graddiss/best_resnet50_balanced_model.pt')"
      ],
      "metadata": {
        "id": "A5pWQ1iGRrFz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Without class balancing: just trying to see how increasing training epochs may impact performance"
      ],
      "metadata": {
        "id": "iwcd2iFBNSB9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft = models.resnet50(weights=\"DEFAULT\")\n",
        "num_ftrs = model_ft.fc.in_features\n",
        "\n",
        "model_ft.fc = nn.Linear(num_ftrs, 5)\n",
        "\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 10 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)"
      ],
      "metadata": {
        "id": "OcYDqi2vCwwh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "0f131bec477647dd8b541ac0006e4694",
            "c8c2b4d7bdcb44bcb69503603383e863",
            "328a742e0cf146b7984deb87bb6696dd",
            "98a46eac179d4abfaf2915e0f10d6ff2",
            "50f6418ebe1c427e9ecf9eb885de2f40",
            "1ae756f4c3a14f48ad02559a95b55fed",
            "fd109b4361b642b3b62cecc3275f1920",
            "4e1ed00787894406b065b6080e576694",
            "36688f3c56b345f28e3fecbd224cdd5f",
            "5327b0ce1508453e892242fd0d89e628",
            "2ba9eab7632f4197b19ffa734ffeadc8"
          ]
        },
        "outputId": "4416c06c-e9f5-4c8d-e6db-c45ef4ab341d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0f131bec477647dd8b541ac0006e4694"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
        "                       num_epochs=25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "niHgUr99ZwXB",
        "outputId": "ebb25e4c-21a7-4234-c001-6edfb72a7a6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/24\n",
            "----------\n",
            "train Loss: 1.4132 Acc: 0.4284\n",
            "val Loss: 1.3550 Acc: 0.4556\n",
            "\n",
            "Epoch 1/24\n",
            "----------\n",
            "train Loss: 1.2369 Acc: 0.4921\n",
            "val Loss: 1.2800 Acc: 0.4641\n",
            "\n",
            "Epoch 2/24\n",
            "----------\n",
            "train Loss: 1.2021 Acc: 0.5024\n",
            "val Loss: 1.2410 Acc: 0.4914\n",
            "\n",
            "Epoch 3/24\n",
            "----------\n",
            "train Loss: 1.1729 Acc: 0.5307\n",
            "val Loss: 1.1839 Acc: 0.5186\n",
            "\n",
            "Epoch 4/24\n",
            "----------\n",
            "train Loss: 1.1519 Acc: 0.5300\n",
            "val Loss: 1.1733 Acc: 0.5179\n",
            "\n",
            "Epoch 5/24\n",
            "----------\n",
            "train Loss: 1.1303 Acc: 0.5484\n",
            "val Loss: 1.1665 Acc: 0.5237\n",
            "\n",
            "Epoch 6/24\n",
            "----------\n",
            "train Loss: 1.1254 Acc: 0.5510\n",
            "val Loss: 1.1246 Acc: 0.5392\n",
            "\n",
            "Epoch 7/24\n",
            "----------\n",
            "train Loss: 1.0978 Acc: 0.5635\n",
            "val Loss: 1.1021 Acc: 0.5624\n",
            "\n",
            "Epoch 8/24\n",
            "----------\n",
            "train Loss: 1.0745 Acc: 0.5767\n",
            "val Loss: 1.0884 Acc: 0.5587\n",
            "\n",
            "Epoch 9/24\n",
            "----------\n",
            "train Loss: 1.0540 Acc: 0.5893\n",
            "val Loss: 1.0594 Acc: 0.5801\n",
            "\n",
            "Epoch 10/24\n",
            "----------\n",
            "train Loss: 1.0161 Acc: 0.5874\n",
            "val Loss: 1.0533 Acc: 0.5874\n",
            "\n",
            "Epoch 11/24\n",
            "----------\n",
            "train Loss: 1.0308 Acc: 0.5929\n",
            "val Loss: 1.0365 Acc: 0.6021\n",
            "\n",
            "Epoch 12/24\n",
            "----------\n",
            "train Loss: 1.0238 Acc: 0.5977\n",
            "val Loss: 1.0500 Acc: 0.6018\n",
            "\n",
            "Epoch 13/24\n",
            "----------\n",
            "train Loss: 1.0242 Acc: 0.6021\n",
            "val Loss: 1.0522 Acc: 0.5937\n",
            "\n",
            "Epoch 14/24\n",
            "----------\n",
            "train Loss: 1.0168 Acc: 0.5985\n",
            "val Loss: 1.0563 Acc: 0.6003\n",
            "\n",
            "Epoch 15/24\n",
            "----------\n",
            "train Loss: 1.0157 Acc: 0.6069\n",
            "val Loss: 1.0496 Acc: 0.5948\n",
            "\n",
            "Epoch 16/24\n",
            "----------\n",
            "train Loss: 1.0075 Acc: 0.6073\n",
            "val Loss: 1.0371 Acc: 0.6069\n",
            "\n",
            "Epoch 17/24\n",
            "----------\n",
            "train Loss: 0.9927 Acc: 0.6150\n",
            "val Loss: 1.0254 Acc: 0.6032\n",
            "\n",
            "Epoch 18/24\n",
            "----------\n",
            "train Loss: 1.0043 Acc: 0.6018\n",
            "val Loss: 1.0333 Acc: 0.5985\n",
            "\n",
            "Epoch 19/24\n",
            "----------\n",
            "train Loss: 0.9910 Acc: 0.6121\n",
            "val Loss: 1.0237 Acc: 0.5981\n",
            "\n",
            "Epoch 20/24\n",
            "----------\n",
            "train Loss: 1.0064 Acc: 0.6135\n",
            "val Loss: 1.0320 Acc: 0.6014\n",
            "\n",
            "Epoch 21/24\n",
            "----------\n",
            "train Loss: 1.0005 Acc: 0.6135\n",
            "val Loss: 1.0277 Acc: 0.6077\n",
            "\n",
            "Epoch 22/24\n",
            "----------\n",
            "train Loss: 0.9934 Acc: 0.6058\n",
            "val Loss: 1.0233 Acc: 0.6106\n",
            "\n",
            "Epoch 23/24\n",
            "----------\n",
            "train Loss: 0.9865 Acc: 0.6169\n",
            "val Loss: 1.0269 Acc: 0.5999\n",
            "\n",
            "Epoch 24/24\n",
            "----------\n",
            "train Loss: 0.9866 Acc: 0.6099\n",
            "val Loss: 1.0259 Acc: 0.6073\n",
            "\n",
            "Training complete in 16m 54s\n",
            "Best val Acc: 0.610600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
        "                       num_epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8nlAT5XOfTac",
        "outputId": "0ce14ae7-575a-43e3-96c5-4c7f3a0191f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/49\n",
            "----------\n",
            "train Loss: 0.9894 Acc: 0.6187\n",
            "val Loss: 1.0324 Acc: 0.6010\n",
            "\n",
            "Epoch 1/49\n",
            "----------\n",
            "train Loss: 0.9959 Acc: 0.6132\n",
            "val Loss: 1.0185 Acc: 0.6146\n",
            "\n",
            "Epoch 2/49\n",
            "----------\n",
            "train Loss: 0.9967 Acc: 0.6110\n",
            "val Loss: 1.0106 Acc: 0.6121\n",
            "\n",
            "Epoch 3/49\n",
            "----------\n",
            "train Loss: 0.9819 Acc: 0.6084\n",
            "val Loss: 1.0169 Acc: 0.6099\n",
            "\n",
            "Epoch 4/49\n",
            "----------\n",
            "train Loss: 0.9892 Acc: 0.6154\n",
            "val Loss: 1.0180 Acc: 0.6205\n",
            "\n",
            "Epoch 5/49\n",
            "----------\n",
            "train Loss: 1.0022 Acc: 0.6018\n",
            "val Loss: 1.0357 Acc: 0.6003\n",
            "\n",
            "Epoch 6/49\n",
            "----------\n",
            "train Loss: 0.9854 Acc: 0.6238\n",
            "val Loss: 1.0153 Acc: 0.6066\n",
            "\n",
            "Epoch 7/49\n",
            "----------\n",
            "train Loss: 0.9941 Acc: 0.6169\n",
            "val Loss: 1.0261 Acc: 0.6062\n",
            "\n",
            "Epoch 8/49\n",
            "----------\n",
            "train Loss: 0.9868 Acc: 0.6110\n",
            "val Loss: 1.0175 Acc: 0.6132\n",
            "\n",
            "Epoch 9/49\n",
            "----------\n",
            "train Loss: 0.9961 Acc: 0.6191\n",
            "val Loss: 1.0278 Acc: 0.6080\n",
            "\n",
            "Epoch 10/49\n",
            "----------\n",
            "train Loss: 0.9923 Acc: 0.6099\n",
            "val Loss: 1.0259 Acc: 0.6025\n",
            "\n",
            "Epoch 11/49\n",
            "----------\n",
            "train Loss: 0.9970 Acc: 0.6084\n",
            "val Loss: 1.0266 Acc: 0.6029\n",
            "\n",
            "Epoch 12/49\n",
            "----------\n",
            "train Loss: 0.9815 Acc: 0.6213\n",
            "val Loss: 1.0299 Acc: 0.5985\n",
            "\n",
            "Epoch 13/49\n",
            "----------\n",
            "train Loss: 0.9878 Acc: 0.6146\n",
            "val Loss: 1.0249 Acc: 0.6084\n",
            "\n",
            "Epoch 14/49\n",
            "----------\n",
            "train Loss: 0.9909 Acc: 0.6117\n",
            "val Loss: 1.0257 Acc: 0.6054\n",
            "\n",
            "Epoch 15/49\n",
            "----------\n",
            "train Loss: 1.0025 Acc: 0.6043\n",
            "val Loss: 1.0170 Acc: 0.6161\n",
            "\n",
            "Epoch 16/49\n",
            "----------\n",
            "train Loss: 1.0059 Acc: 0.6036\n",
            "val Loss: 1.0267 Acc: 0.6084\n",
            "\n",
            "Epoch 17/49\n",
            "----------\n",
            "train Loss: 0.9992 Acc: 0.6121\n",
            "val Loss: 1.0381 Acc: 0.6036\n",
            "\n",
            "Epoch 18/49\n",
            "----------\n",
            "train Loss: 0.9813 Acc: 0.6216\n",
            "val Loss: 1.0265 Acc: 0.6139\n",
            "\n",
            "Epoch 19/49\n",
            "----------\n",
            "train Loss: 1.0021 Acc: 0.6084\n",
            "val Loss: 1.0304 Acc: 0.6062\n",
            "\n",
            "Epoch 20/49\n",
            "----------\n",
            "train Loss: 1.0032 Acc: 0.6043\n",
            "val Loss: 1.0280 Acc: 0.6047\n",
            "\n",
            "Epoch 21/49\n",
            "----------\n",
            "train Loss: 0.9945 Acc: 0.6084\n",
            "val Loss: 1.0308 Acc: 0.6113\n",
            "\n",
            "Epoch 22/49\n",
            "----------\n",
            "train Loss: 1.0025 Acc: 0.6047\n",
            "val Loss: 1.0336 Acc: 0.6161\n",
            "\n",
            "Epoch 23/49\n",
            "----------\n",
            "train Loss: 0.9886 Acc: 0.6169\n",
            "val Loss: 1.0250 Acc: 0.6054\n",
            "\n",
            "Epoch 24/49\n",
            "----------\n",
            "train Loss: 0.9946 Acc: 0.6058\n",
            "val Loss: 1.0275 Acc: 0.6124\n",
            "\n",
            "Epoch 25/49\n",
            "----------\n",
            "train Loss: 0.9924 Acc: 0.6117\n",
            "val Loss: 1.0304 Acc: 0.6069\n",
            "\n",
            "Epoch 26/49\n",
            "----------\n",
            "train Loss: 0.9884 Acc: 0.6165\n",
            "val Loss: 1.0171 Acc: 0.6150\n",
            "\n",
            "Epoch 27/49\n",
            "----------\n",
            "train Loss: 0.9934 Acc: 0.6128\n",
            "val Loss: 1.0250 Acc: 0.5981\n",
            "\n",
            "Epoch 28/49\n",
            "----------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-b66261c2394a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n\u001b[0m\u001b[1;32m      2\u001b[0m                        num_epochs=50)\n",
            "\u001b[0;32m<ipython-input-19-93acec95e350>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0;31m# statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                 \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m                 \u001b[0mrunning_corrects\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the best model\n",
        "torch.save(model_ft.state_dict(), 'best_resnet50_bnmodel.pt')"
      ],
      "metadata": {
        "id": "W1vxe6stazwk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Try VGG16_BN"
      ],
      "metadata": {
        "id": "bI4U_0ev7uCU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Try with balanced, Adam Optim, lr=0.0001"
      ],
      "metadata": {
        "id": "4RIYgaGEfNAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft = models.vgg16_bn(weights=\"DEFAULT\")\n",
        "# num_ftrs = model_ft.fc.in_features\n",
        "num_ftrs = model_ft.classifier[6].in_features # the 6 gets me to the linear layer of VGG\n",
        "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
        "model_ft.fc = nn.Linear(num_ftrs, 5)\n",
        "\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.0001)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)"
      ],
      "metadata": {
        "id": "nXOjO9hwjRcf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
        "                       num_epochs=25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AoLxbiiCjTQz",
        "outputId": "3c9984a5-5cde-4db8-88c9-293253854106"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/24\n",
            "----------\n",
            "train Loss: 1.8474 Acc: 0.3625\n",
            "val Loss: 1.1004 Acc: 0.5856\n",
            "\n",
            "Epoch 1/24\n",
            "----------\n",
            "train Loss: 1.0082 Acc: 0.6088\n",
            "val Loss: 0.8230 Acc: 0.6875\n",
            "\n",
            "Epoch 2/24\n",
            "----------\n",
            "train Loss: 0.7671 Acc: 0.6989\n",
            "val Loss: 0.7308 Acc: 0.7310\n",
            "\n",
            "Epoch 3/24\n",
            "----------\n",
            "train Loss: 0.6851 Acc: 0.7420\n",
            "val Loss: 0.6936 Acc: 0.7549\n",
            "\n",
            "Epoch 4/24\n",
            "----------\n",
            "train Loss: 0.6451 Acc: 0.7435\n",
            "val Loss: 0.6469 Acc: 0.7611\n",
            "\n",
            "Epoch 5/24\n",
            "----------\n",
            "train Loss: 0.5828 Acc: 0.7759\n",
            "val Loss: 0.6237 Acc: 0.7792\n",
            "\n",
            "Epoch 6/24\n",
            "----------\n",
            "train Loss: 0.5108 Acc: 0.8108\n",
            "val Loss: 0.7026 Acc: 0.7556\n",
            "\n",
            "Epoch 7/24\n",
            "----------\n",
            "train Loss: 0.4747 Acc: 0.8208\n",
            "val Loss: 0.6379 Acc: 0.7781\n",
            "\n",
            "Epoch 8/24\n",
            "----------\n",
            "train Loss: 0.4458 Acc: 0.8274\n",
            "val Loss: 0.7139 Acc: 0.7604\n",
            "\n",
            "Epoch 9/24\n",
            "----------\n",
            "train Loss: 0.4329 Acc: 0.8399\n",
            "val Loss: 0.6811 Acc: 0.7689\n",
            "\n",
            "Epoch 10/24\n",
            "----------\n",
            "train Loss: 0.3232 Acc: 0.8760\n",
            "val Loss: 0.6453 Acc: 0.7840\n",
            "\n",
            "Epoch 11/24\n",
            "----------\n",
            "train Loss: 0.2825 Acc: 0.8929\n",
            "val Loss: 0.6604 Acc: 0.7884\n",
            "\n",
            "Epoch 12/24\n",
            "----------\n",
            "train Loss: 0.2964 Acc: 0.8874\n",
            "val Loss: 0.6553 Acc: 0.7950\n",
            "\n",
            "Epoch 13/24\n",
            "----------\n",
            "train Loss: 0.2705 Acc: 0.9032\n",
            "val Loss: 0.6901 Acc: 0.7909\n",
            "\n",
            "Epoch 14/24\n",
            "----------\n",
            "train Loss: 0.2654 Acc: 0.9021\n",
            "val Loss: 0.6845 Acc: 0.7895\n",
            "\n",
            "Epoch 15/24\n",
            "----------\n",
            "train Loss: 0.2363 Acc: 0.9124\n",
            "val Loss: 0.6770 Acc: 0.7939\n",
            "\n",
            "Epoch 16/24\n",
            "----------\n",
            "train Loss: 0.2415 Acc: 0.9087\n",
            "val Loss: 0.6834 Acc: 0.7939\n",
            "\n",
            "Epoch 17/24\n",
            "----------\n",
            "train Loss: 0.2139 Acc: 0.9223\n",
            "val Loss: 0.7190 Acc: 0.7935\n",
            "\n",
            "Epoch 18/24\n",
            "----------\n",
            "train Loss: 0.2199 Acc: 0.9187\n",
            "val Loss: 0.7179 Acc: 0.7876\n",
            "\n",
            "Epoch 19/24\n",
            "----------\n",
            "train Loss: 0.2172 Acc: 0.9179\n",
            "val Loss: 0.7219 Acc: 0.7884\n",
            "\n",
            "Epoch 20/24\n",
            "----------\n",
            "train Loss: 0.2020 Acc: 0.9304\n",
            "val Loss: 0.7250 Acc: 0.7928\n",
            "\n",
            "Epoch 21/24\n",
            "----------\n",
            "train Loss: 0.1986 Acc: 0.9334\n",
            "val Loss: 0.7191 Acc: 0.7965\n",
            "\n",
            "Epoch 22/24\n",
            "----------\n",
            "train Loss: 0.1912 Acc: 0.9349\n",
            "val Loss: 0.7206 Acc: 0.7891\n",
            "\n",
            "Epoch 23/24\n",
            "----------\n",
            "train Loss: 0.1764 Acc: 0.9389\n",
            "val Loss: 0.7217 Acc: 0.7909\n",
            "\n",
            "Epoch 24/24\n",
            "----------\n",
            "train Loss: 0.1894 Acc: 0.9378\n",
            "val Loss: 0.7194 Acc: 0.7928\n",
            "\n",
            "Training complete in 28m 48s\n",
            "Best val Acc: 0.796467\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the best model\n",
        "torch.save(model_ft.state_dict(), '/content/drive/MyDrive/ML for BDS/Hackathon - graddiss/best_vgg16_bnmodel_Adam_balanced.pt')"
      ],
      "metadata": {
        "id": "BRLelg-KkTQK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Try with balanced dataset (TO DO)"
      ],
      "metadata": {
        "id": "5-QwjQifMctb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft = models.vgg16_bn(weights=\"DEFAULT\")\n",
        "# num_ftrs = model_ft.fc.in_features\n",
        "num_ftrs = model_ft.classifier[6].in_features # the 6 gets me to the linear layer of VGG\n",
        "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
        "model_ft.fc = nn.Linear(num_ftrs, 5)\n",
        "\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "0321b4b871234720b53798c7d1bfef40",
            "6b459d4fb37d41909124507a0e192e69",
            "f997e3d042d946d79c83adba3e45e3c1",
            "4827a411cf7147879e3127832e0ecae4",
            "fb5da4b2760c435aadcd56c167e6941f",
            "6626c611a0be41beb7067fe5e481e75d",
            "896e66e1995e4c3599f383d4c3b5bb3b",
            "2ea29be0de9a420bb85d705e8d2d09b9",
            "a1afcacaa0324d419bac6eb59fd836f6",
            "0da34c3291094098aa4cb7a6516a698b",
            "877309a5bfb8426db68f610e48112e6b"
          ]
        },
        "id": "ASy2nOJNpWAv",
        "outputId": "6cd4822b-cf66-4cd9-c24e-e0025702ae07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16_bn-6c64b313.pth\" to /root/.cache/torch/hub/checkpoints/vgg16_bn-6c64b313.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/528M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0321b4b871234720b53798c7d1bfef40"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
        "                       num_epochs=25)"
      ],
      "metadata": {
        "id": "-UY3VvpbMa2K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e3e31ee-e819-464b-a1e9-41c8024b070a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/24\n",
            "----------\n",
            "train Loss: 2.5397 Acc: 0.2724\n",
            "val Loss: 1.3808 Acc: 0.4803\n",
            "\n",
            "Epoch 1/24\n",
            "----------\n",
            "train Loss: 1.4094 Acc: 0.3824\n",
            "val Loss: 1.2152 Acc: 0.5153\n",
            "\n",
            "Epoch 2/24\n",
            "----------\n",
            "train Loss: 1.1777 Acc: 0.5046\n",
            "val Loss: 1.0572 Acc: 0.5937\n",
            "\n",
            "Epoch 3/24\n",
            "----------\n",
            "train Loss: 1.0591 Acc: 0.5631\n",
            "val Loss: 0.8758 Acc: 0.6676\n",
            "\n",
            "Epoch 4/24\n",
            "----------\n",
            "train Loss: 0.9608 Acc: 0.6154\n",
            "val Loss: 0.8097 Acc: 0.6846\n",
            "\n",
            "Epoch 5/24\n",
            "----------\n",
            "train Loss: 0.8547 Acc: 0.6603\n",
            "val Loss: 0.7499 Acc: 0.7155\n",
            "\n",
            "Epoch 6/24\n",
            "----------\n",
            "train Loss: 0.8031 Acc: 0.6824\n",
            "val Loss: 0.7318 Acc: 0.7199\n",
            "\n",
            "Epoch 7/24\n",
            "----------\n",
            "train Loss: 0.7825 Acc: 0.6927\n",
            "val Loss: 0.7363 Acc: 0.7254\n",
            "\n",
            "Epoch 8/24\n",
            "----------\n",
            "train Loss: 0.7420 Acc: 0.7019\n",
            "val Loss: 0.6909 Acc: 0.7394\n",
            "\n",
            "Epoch 9/24\n",
            "----------\n",
            "train Loss: 0.6735 Acc: 0.7357\n",
            "val Loss: 0.7066 Acc: 0.7346\n",
            "\n",
            "Epoch 10/24\n",
            "----------\n",
            "train Loss: 0.6169 Acc: 0.7622\n",
            "val Loss: 0.6605 Acc: 0.7501\n",
            "\n",
            "Epoch 11/24\n",
            "----------\n",
            "train Loss: 0.6240 Acc: 0.7593\n",
            "val Loss: 0.6499 Acc: 0.7527\n",
            "\n",
            "Epoch 12/24\n",
            "----------\n",
            "train Loss: 0.6189 Acc: 0.7512\n",
            "val Loss: 0.6384 Acc: 0.7567\n",
            "\n",
            "Epoch 13/24\n",
            "----------\n",
            "train Loss: 0.6163 Acc: 0.7615\n",
            "val Loss: 0.6491 Acc: 0.7541\n",
            "\n",
            "Epoch 14/24\n",
            "----------\n",
            "train Loss: 0.6053 Acc: 0.7633\n",
            "val Loss: 0.6449 Acc: 0.7589\n",
            "\n",
            "Epoch 15/24\n",
            "----------\n",
            "train Loss: 0.6234 Acc: 0.7578\n",
            "val Loss: 0.6356 Acc: 0.7633\n",
            "\n",
            "Epoch 16/24\n",
            "----------\n",
            "train Loss: 0.5942 Acc: 0.7714\n",
            "val Loss: 0.6470 Acc: 0.7571\n",
            "\n",
            "Epoch 17/24\n",
            "----------\n",
            "train Loss: 0.5869 Acc: 0.7630\n",
            "val Loss: 0.6437 Acc: 0.7593\n",
            "\n",
            "Epoch 18/24\n",
            "----------\n",
            "train Loss: 0.5728 Acc: 0.7788\n",
            "val Loss: 0.6446 Acc: 0.7563\n",
            "\n",
            "Epoch 19/24\n",
            "----------\n",
            "train Loss: 0.5676 Acc: 0.7825\n",
            "val Loss: 0.6440 Acc: 0.7604\n",
            "\n",
            "Epoch 20/24\n",
            "----------\n",
            "train Loss: 0.6159 Acc: 0.7644\n",
            "val Loss: 0.6467 Acc: 0.7589\n",
            "\n",
            "Epoch 21/24\n",
            "----------\n",
            "train Loss: 0.5733 Acc: 0.7817\n",
            "val Loss: 0.6458 Acc: 0.7589\n",
            "\n",
            "Epoch 22/24\n",
            "----------\n",
            "train Loss: 0.6106 Acc: 0.7637\n",
            "val Loss: 0.6533 Acc: 0.7593\n",
            "\n",
            "Epoch 23/24\n",
            "----------\n",
            "train Loss: 0.5882 Acc: 0.7692\n",
            "val Loss: 0.6528 Acc: 0.7575\n",
            "\n",
            "Epoch 24/24\n",
            "----------\n",
            "train Loss: 0.5795 Acc: 0.7663\n",
            "val Loss: 0.6454 Acc: 0.7622\n",
            "\n",
            "Training complete in 30m 7s\n",
            "Best val Acc: 0.763342\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the best model\n",
        "torch.save(model_ft.state_dict(), '/content/drive/MyDrive/ML for BDS/Hackathon - graddiss/best_vgg16_bnmodel_balanced.pt')"
      ],
      "metadata": {
        "id": "C5WXFG2CRRse"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Try VGG16_bn with a multi-stage training strategy (as described by Shen) (TO DO)"
      ],
      "metadata": {
        "id": "eV98bL1i4s4-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_conv = torchvision.models.vgg16_bn(weights=\"DEFAULT\")\n",
        "for param in model_conv.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "for param in model_conv.classifier[6].parameters():\n",
        "  param.requires_grad = True\n",
        "# Parameters of newly constructed modules have requires_grad=True by default\n",
        "# num_ftrs = model_conv.fc.in_features\n",
        "# model_conv.fc = nn.Linear(num_ftrs, 2)\n",
        "num_ftrs = model_conv.classifier[6].in_features\n",
        "model_conv.fc = nn.Linear(num_ftrs, 5)\n",
        "\n",
        "model_conv = model_conv.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that only parameters of final layer are being optimized as\n",
        "# opposed to before.\n",
        "optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=10, gamma=0.1)"
      ],
      "metadata": {
        "id": "9Y74tahl5OaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_conv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "baXKaWoX7ciY",
        "outputId": "615e0b44-a3b9-4479-d9f1-8709afc4f9d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (12): ReLU(inplace=True)\n",
              "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (16): ReLU(inplace=True)\n",
              "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (19): ReLU(inplace=True)\n",
              "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (26): ReLU(inplace=True)\n",
              "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (32): ReLU(inplace=True)\n",
              "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (36): ReLU(inplace=True)\n",
              "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (39): ReLU(inplace=True)\n",
              "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (42): ReLU(inplace=True)\n",
              "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "  )\n",
              "  (fc): Linear(in_features=4096, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the last layer for 3 epochs at lr = 0.001 \n",
        "model_conv = train_model(model_conv, criterion, optimizer_conv,\n",
        "                         exp_lr_scheduler, num_epochs=3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "id": "bnP7JqWz5wce",
        "outputId": "8900a806-2ca5-4634-a04a-5fb5c2850654"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/2\n",
            "----------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-bafa75441026>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train the last layer for 3 epochs at lr = 0.001\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m model_conv = train_model(model_conv, criterion, optimizer_conv,\n\u001b[0m\u001b[1;32m      3\u001b[0m                          exp_lr_scheduler, num_epochs=3)\n",
            "\u001b[0;32m<ipython-input-24-93acec95e350>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     37\u001b[0m                 \u001b[0;31m# track history if only in train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m                     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/models/vgg.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavgpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/pooling.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         return F.max_pool2d(input, self.kernel_size, self.stride,\n\u001b[0m\u001b[1;32m    167\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mceil_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m                             return_indices=self.return_indices)\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/_jit_internal.py\u001b[0m in \u001b[0;36mfn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    483\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mif_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mif_false\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_max_pool2d\u001b[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[1;32m    780\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstride\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m         \u001b[0mstride\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 782\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mceil_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unfreeze the top layer\n",
        "for param in model_conv.features[17:44].parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# Parameters of newly constructed modules have requires_grad=True by default\n",
        "# num_ftrs = model_conv.fc.in_features\n",
        "# model_conv.fc = nn.Linear(num_ftrs, 2)\n",
        "num_ftrs = model_conv.classifier[6].in_features\n",
        "model_conv.fc = nn.Linear(num_ftrs, 5)\n",
        "\n",
        "model_conv = model_conv.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that only parameters of final layer are being optimized as\n",
        "# opposed to before.\n",
        "optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.0001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=10, gamma=0.1)"
      ],
      "metadata": {
        "id": "dG5IBgve59n0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the last layer for 3 epochs at lr = 0.001 \n",
        "model_conv = train_model(model_conv, criterion, optimizer_conv,\n",
        "                         exp_lr_scheduler, num_epochs=10)"
      ],
      "metadata": {
        "id": "WgxL9rPP-O8V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unfreeze all layers and train for 37 epochs\n",
        "# Unfreeze the top layer\n",
        "for param in model_conv.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "# Parameters of newly constructed modules have requires_grad=True by default\n",
        "# num_ftrs = model_conv.fc.in_features\n",
        "# model_conv.fc = nn.Linear(num_ftrs, 2)\n",
        "num_ftrs = model_conv.classifier[6].in_features\n",
        "model_conv.fc = nn.Linear(num_ftrs, 5)\n",
        "\n",
        "model_conv = model_conv.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that only parameters of final layer are being optimized as\n",
        "# opposed to before.\n",
        "optimizer_conv = optim.SGD(model_conv.fc.parameters(), lr=0.00001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_conv, step_size=10, gamma=0.1)"
      ],
      "metadata": {
        "id": "9bDz3OU4-SvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_conv = train_model(model_conv, criterion, optimizer_conv,\n",
        "                         exp_lr_scheduler, num_epochs=37)"
      ],
      "metadata": {
        "id": "ro9w6Paz-f3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model_ft = models.vgg16_bn(weights=\"DEFAULT\") # ImageNet weights\n",
        "# # num_ftrs = model_ft.fc.in_features\n",
        "# num_ftrs = model_ft.classifier[6].in_features # the 6 gets me to the linear layer of VGG\n",
        "# # Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
        "# model_ft.fc = nn.Linear(num_ftrs, 5)\n",
        "\n",
        "# model_ft = model_ft.to(device)\n",
        "\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# # Observe that all parameters are being optimized\n",
        "# optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# # Decay LR by a factor of 0.1 every 10 epochs\n",
        "# exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)"
      ],
      "metadata": {
        "id": "UIKv6fa14yXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Unbalanced classes, only flip transform to train and val, SGD Optim, baseline model"
      ],
      "metadata": {
        "id": "14ZuNcJjD3-f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft = models.vgg16_bn(weights=\"DEFAULT\")\n",
        "# num_ftrs = model_ft.fc.in_features\n",
        "num_ftrs = model_ft.classifier[6].in_features # the 6 gets me to the linear layer of VGG\n",
        "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
        "model_ft.fc = nn.Linear(num_ftrs, 5)\n",
        "\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 10 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "a08580a712f244afa4619bdbf37ae7ea",
            "e18fffdf4d384f8ca4dc17dfc4b159c8",
            "65491fe73d10425bbc1a927cc2e7b27c",
            "99c4609262394538a61b9457eadc855e",
            "cca0dcf98f624e1a84ff7534a0a44417",
            "4579aa68acbe437093728086589717eb",
            "b6d110dcbf424c248dc75bf6a10e62db",
            "860ed5d389884893bc44fc91fd80a348",
            "e0ead0e47e7740eaaf96d8f51bcd62dd",
            "f6f8af237cb9487d99bad0bf14a2343d",
            "1e2a07d04e284f5ebe8f0ae5e85700f9"
          ]
        },
        "id": "2LrEtvcW665D",
        "outputId": "1a49cc82-ecf7-4778-d61c-58b11dc94927"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16_bn-6c64b313.pth\" to /root/.cache/torch/hub/checkpoints/vgg16_bn-6c64b313.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/528M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a08580a712f244afa4619bdbf37ae7ea"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
        "                       num_epochs=25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yAFT2469NTq",
        "outputId": "abc376e6-3280-47b5-d860-56dcdf4f4bf3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/24\n",
            "----------\n",
            "train Loss: 2.4024 Acc: 0.4122\n",
            "val Loss: 1.3302 Acc: 0.4700\n",
            "\n",
            "Epoch 1/24\n",
            "----------\n",
            "train Loss: 1.2372 Acc: 0.5145\n",
            "val Loss: 1.1772 Acc: 0.5477\n",
            "\n",
            "Epoch 2/24\n",
            "----------\n",
            "train Loss: 1.1135 Acc: 0.5620\n",
            "val Loss: 1.0671 Acc: 0.5830\n",
            "\n",
            "Epoch 3/24\n",
            "----------\n",
            "train Loss: 1.0607 Acc: 0.5852\n",
            "val Loss: 1.0019 Acc: 0.6158\n",
            "\n",
            "Epoch 4/24\n",
            "----------\n",
            "train Loss: 0.9589 Acc: 0.6327\n",
            "val Loss: 0.9736 Acc: 0.6283\n",
            "\n",
            "Epoch 5/24\n",
            "----------\n",
            "train Loss: 0.9424 Acc: 0.6290\n",
            "val Loss: 0.9498 Acc: 0.6297\n",
            "\n",
            "Epoch 6/24\n",
            "----------\n",
            "train Loss: 0.8968 Acc: 0.6478\n",
            "val Loss: 0.9059 Acc: 0.6540\n",
            "\n",
            "Epoch 7/24\n",
            "----------\n",
            "train Loss: 0.8500 Acc: 0.6765\n",
            "val Loss: 0.9662 Acc: 0.6290\n",
            "\n",
            "Epoch 8/24\n",
            "----------\n",
            "train Loss: 0.8489 Acc: 0.6783\n",
            "val Loss: 0.8984 Acc: 0.6548\n",
            "\n",
            "Epoch 9/24\n",
            "----------\n",
            "train Loss: 0.8221 Acc: 0.6868\n",
            "val Loss: 0.8837 Acc: 0.6610\n",
            "\n",
            "Epoch 10/24\n",
            "----------\n",
            "train Loss: 0.7686 Acc: 0.7067\n",
            "val Loss: 0.8659 Acc: 0.6651\n",
            "\n",
            "Epoch 11/24\n",
            "----------\n",
            "train Loss: 0.7600 Acc: 0.7137\n",
            "val Loss: 0.8474 Acc: 0.6724\n",
            "\n",
            "Epoch 12/24\n",
            "----------\n",
            "train Loss: 0.7325 Acc: 0.7232\n",
            "val Loss: 0.8454 Acc: 0.6654\n",
            "\n",
            "Epoch 13/24\n",
            "----------\n",
            "train Loss: 0.7625 Acc: 0.6997\n",
            "val Loss: 0.8278 Acc: 0.6813\n",
            "\n",
            "Epoch 14/24\n",
            "----------\n",
            "train Loss: 0.7556 Acc: 0.7059\n",
            "val Loss: 0.8224 Acc: 0.6838\n",
            "\n",
            "Epoch 15/24\n",
            "----------\n",
            "train Loss: 0.7513 Acc: 0.7033\n",
            "val Loss: 0.8436 Acc: 0.6702\n",
            "\n",
            "Epoch 16/24\n",
            "----------\n",
            "train Loss: 0.7660 Acc: 0.7100\n",
            "val Loss: 0.8553 Acc: 0.6757\n",
            "\n",
            "Epoch 17/24\n",
            "----------\n",
            "train Loss: 0.7617 Acc: 0.7096\n",
            "val Loss: 0.8612 Acc: 0.6699\n",
            "\n",
            "Epoch 18/24\n",
            "----------\n",
            "train Loss: 0.7406 Acc: 0.7081\n",
            "val Loss: 0.8477 Acc: 0.6739\n",
            "\n",
            "Epoch 19/24\n",
            "----------\n",
            "train Loss: 0.7563 Acc: 0.7081\n",
            "val Loss: 0.8401 Acc: 0.6872\n",
            "\n",
            "Epoch 20/24\n",
            "----------\n",
            "train Loss: 0.7484 Acc: 0.7144\n",
            "val Loss: 0.8381 Acc: 0.6768\n",
            "\n",
            "Epoch 21/24\n",
            "----------\n",
            "train Loss: 0.7606 Acc: 0.6986\n",
            "val Loss: 0.8601 Acc: 0.6717\n",
            "\n",
            "Epoch 22/24\n",
            "----------\n",
            "train Loss: 0.7428 Acc: 0.7162\n",
            "val Loss: 0.8604 Acc: 0.6684\n",
            "\n",
            "Epoch 23/24\n",
            "----------\n",
            "train Loss: 0.7176 Acc: 0.7265\n",
            "val Loss: 0.8413 Acc: 0.6743\n",
            "\n",
            "Epoch 24/24\n",
            "----------\n",
            "train Loss: 0.7196 Acc: 0.7251\n",
            "val Loss: 0.8419 Acc: 0.6864\n",
            "\n",
            "Training complete in 25m 42s\n",
            "Best val Acc: 0.687155\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Try an Adam Optimizer (lr=0.001) with weight decay"
      ],
      "metadata": {
        "id": "3nxrzegTwdq9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft = models.vgg16_bn(weights=\"DEFAULT\")\n",
        "# num_ftrs = model_ft.fc.in_features\n",
        "num_ftrs = model_ft.classifier[6].in_features # the 6 gets me to the linear layer of VGG\n",
        "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
        "model_ft.fc = nn.Linear(num_ftrs, 5)\n",
        "\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.001, weight_decay=0.001)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
      ],
      "metadata": {
        "id": "ZqxS9PLpvtbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
        "                       num_epochs=25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dp-7OX1PvxpP",
        "outputId": "f4a38810-b0a7-42de-8adb-f17f62c9bea6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/24\n",
            "----------\n",
            "train Loss: 1.8276 Acc: 0.4181\n",
            "val Loss: 1.2708 Acc: 0.4590\n",
            "\n",
            "Epoch 1/24\n",
            "----------\n",
            "train Loss: 1.3267 Acc: 0.4464\n",
            "val Loss: 1.3244 Acc: 0.4590\n",
            "\n",
            "Epoch 2/24\n",
            "----------\n",
            "train Loss: 1.3151 Acc: 0.4534\n",
            "val Loss: 1.2655 Acc: 0.4932\n",
            "\n",
            "Epoch 3/24\n",
            "----------\n",
            "train Loss: 1.3026 Acc: 0.4512\n",
            "val Loss: 1.2679 Acc: 0.4972\n",
            "\n",
            "Epoch 4/24\n",
            "----------\n",
            "train Loss: 1.2949 Acc: 0.4615\n",
            "val Loss: 1.2588 Acc: 0.5024\n",
            "\n",
            "Epoch 5/24\n",
            "----------\n",
            "train Loss: 1.3240 Acc: 0.4586\n",
            "val Loss: 1.2716 Acc: 0.4612\n",
            "\n",
            "Epoch 6/24\n",
            "----------\n",
            "train Loss: 1.3071 Acc: 0.4612\n",
            "val Loss: 1.2654 Acc: 0.4615\n",
            "\n",
            "Epoch 7/24\n",
            "----------\n",
            "train Loss: 1.2672 Acc: 0.4674\n",
            "val Loss: 1.2279 Acc: 0.5035\n",
            "\n",
            "Epoch 8/24\n",
            "----------\n",
            "train Loss: 1.2498 Acc: 0.4770\n",
            "val Loss: 1.2212 Acc: 0.5002\n",
            "\n",
            "Epoch 9/24\n",
            "----------\n",
            "train Loss: 1.2444 Acc: 0.4814\n",
            "val Loss: 1.2136 Acc: 0.5068\n",
            "\n",
            "Epoch 10/24\n",
            "----------\n",
            "train Loss: 1.2507 Acc: 0.4770\n",
            "val Loss: 1.2092 Acc: 0.5109\n",
            "\n",
            "Epoch 11/24\n",
            "----------\n",
            "train Loss: 1.2553 Acc: 0.4704\n",
            "val Loss: 1.2030 Acc: 0.5123\n",
            "\n",
            "Epoch 12/24\n",
            "----------\n",
            "train Loss: 1.2402 Acc: 0.4788\n",
            "val Loss: 1.2080 Acc: 0.5101\n",
            "\n",
            "Epoch 13/24\n",
            "----------\n",
            "train Loss: 1.2556 Acc: 0.4814\n",
            "val Loss: 1.2038 Acc: 0.5075\n",
            "\n",
            "Epoch 14/24\n",
            "----------\n",
            "train Loss: 1.2260 Acc: 0.4895\n",
            "val Loss: 1.2003 Acc: 0.5035\n",
            "\n",
            "Epoch 15/24\n",
            "----------\n",
            "train Loss: 1.2410 Acc: 0.4818\n",
            "val Loss: 1.1949 Acc: 0.5175\n",
            "\n",
            "Epoch 16/24\n",
            "----------\n",
            "train Loss: 1.2381 Acc: 0.4921\n",
            "val Loss: 1.1934 Acc: 0.5116\n",
            "\n",
            "Epoch 17/24\n",
            "----------\n",
            "train Loss: 1.2400 Acc: 0.4840\n",
            "val Loss: 1.1886 Acc: 0.5160\n",
            "\n",
            "Epoch 18/24\n",
            "----------\n",
            "train Loss: 1.2245 Acc: 0.4866\n",
            "val Loss: 1.1914 Acc: 0.5167\n",
            "\n",
            "Epoch 19/24\n",
            "----------\n",
            "train Loss: 1.2404 Acc: 0.4796\n",
            "val Loss: 1.1976 Acc: 0.5105\n",
            "\n",
            "Epoch 20/24\n",
            "----------\n",
            "train Loss: 1.2358 Acc: 0.4821\n",
            "val Loss: 1.1883 Acc: 0.5127\n",
            "\n",
            "Epoch 21/24\n",
            "----------\n",
            "train Loss: 1.2137 Acc: 0.4873\n",
            "val Loss: 1.1929 Acc: 0.5123\n",
            "\n",
            "Epoch 22/24\n",
            "----------\n",
            "train Loss: 1.2203 Acc: 0.4829\n",
            "val Loss: 1.1946 Acc: 0.5171\n",
            "\n",
            "Epoch 23/24\n",
            "----------\n",
            "train Loss: 1.2200 Acc: 0.4910\n",
            "val Loss: 1.1886 Acc: 0.5156\n",
            "\n",
            "Epoch 24/24\n",
            "----------\n",
            "train Loss: 1.2277 Acc: 0.4914\n",
            "val Loss: 1.1997 Acc: 0.5039\n",
            "\n",
            "Training complete in 25m 57s\n",
            "Best val Acc: 0.517483\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving Models Locally (use Magic Wormhole)"
      ],
      "metadata": {
        "id": "xBDXd0whAHfe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install magic-wormhole"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIl4ysPQfZea",
        "outputId": "cd9bd4fd-1102-4aa1-dae2-7913451e2a5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting magic-wormhole\n",
            "  Downloading magic_wormhole-0.12.0-py2.py3-none-any.whl (201 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m201.6/201.6 KB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.9/dist-packages (from magic-wormhole) (22.2.0)\n",
            "Collecting automat\n",
            "  Downloading Automat-22.10.0-py2.py3-none-any.whl (26 kB)\n",
            "Collecting twisted[tls]>=17.5.0\n",
            "  Downloading Twisted-22.10.0-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m97.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from magic-wormhole) (8.1.3)\n",
            "Requirement already satisfied: tqdm>=4.13.0 in /usr/local/lib/python3.9/dist-packages (from magic-wormhole) (4.65.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from magic-wormhole) (1.15.0)\n",
            "Collecting spake2==0.8\n",
            "  Downloading spake2-0.8-py2.py3-none-any.whl (39 kB)\n",
            "Collecting hkdf\n",
            "  Downloading hkdf-0.0.3.tar.gz (4.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting txtorcon>=18.0.2\n",
            "  Downloading txtorcon-23.0.0-py3-none-any.whl (260 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m260.5/260.5 KB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autobahn[twisted]>=0.14.1\n",
            "  Downloading autobahn-23.1.2.tar.gz (480 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m480.7/480.7 KB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.9/dist-packages (from magic-wormhole) (4.6.0)\n",
            "Collecting pynacl\n",
            "  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m856.7/856.7 KB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting txaio>=21.2.1\n",
            "  Downloading txaio-23.1.1-py2.py3-none-any.whl (30 kB)\n",
            "Collecting cryptography>=3.4.6\n",
            "  Downloading cryptography-39.0.2-cp36-abi3-manylinux_2_28_x86_64.whl (4.2 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m103.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hyperlink>=21.0.0\n",
            "  Downloading hyperlink-21.0.0-py2.py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m74.6/74.6 KB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from autobahn[twisted]>=0.14.1->magic-wormhole) (63.4.3)\n",
            "Collecting zope.interface>=5.2.0\n",
            "  Downloading zope.interface-6.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (246 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m246.1/246.1 KB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting incremental>=21.3.0\n",
            "  Downloading incremental-22.10.0-py2.py3-none-any.whl (16 kB)\n",
            "Collecting constantly>=15.1\n",
            "  Downloading constantly-15.1.0-py2.py3-none-any.whl (7.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.9/dist-packages (from twisted[tls]>=17.5.0->magic-wormhole) (4.5.0)\n",
            "Collecting service-identity>=18.1.0\n",
            "  Downloading service_identity-21.1.0-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: idna>=2.4 in /usr/local/lib/python3.9/dist-packages (from twisted[tls]>=17.5.0->magic-wormhole) (3.4)\n",
            "Collecting pyopenssl>=21.0.0\n",
            "  Downloading pyOpenSSL-23.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m57.3/57.3 KB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cffi>=1.4.1 in /usr/local/lib/python3.9/dist-packages (from pynacl->magic-wormhole) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/dist-packages (from cffi>=1.4.1->pynacl->magic-wormhole) (2.21)\n",
            "Requirement already satisfied: pyasn1-modules in /usr/local/lib/python3.9/dist-packages (from service-identity>=18.1.0->twisted[tls]>=17.5.0->magic-wormhole) (0.2.8)\n",
            "Requirement already satisfied: pyasn1 in /usr/local/lib/python3.9/dist-packages (from service-identity>=18.1.0->twisted[tls]>=17.5.0->magic-wormhole) (0.4.8)\n",
            "Building wheels for collected packages: hkdf, autobahn\n",
            "  Building wheel for hkdf (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hkdf: filename=hkdf-0.0.3-py3-none-any.whl size=3734 sha256=8cb0e3f98dab16546a82adc3bbf941c8c607c49fc2d9dfdab0f8ad6652ef84d8\n",
            "  Stored in directory: /root/.cache/pip/wheels/07/18/fe/05eda020b559d7d4ff5c614fb30acbb7b7df18b21f503b9346\n",
            "  Building wheel for autobahn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for autobahn: filename=autobahn-23.1.2-cp39-cp39-linux_x86_64.whl size=706969 sha256=57785588b1814ecd1bea72dff1a93a5ff710607887e5b319da749d045f05290d\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/b2/da/d39c6c5ff78abfd09d37663025e174f8920ca01e3d6eccecd9\n",
            "Successfully built hkdf autobahn\n",
            "Installing collected packages: incremental, hkdf, constantly, zope.interface, txaio, spake2, hyperlink, automat, twisted, pynacl, cryptography, service-identity, pyopenssl, autobahn, txtorcon, magic-wormhole\n",
            "Successfully installed autobahn-23.1.2 automat-22.10.0 constantly-15.1.0 cryptography-39.0.2 hkdf-0.0.3 hyperlink-21.0.0 incremental-22.10.0 magic-wormhole-0.12.0 pynacl-1.5.0 pyopenssl-23.0.0 service-identity-21.1.0 spake2-0.8 twisted-22.10.0 txaio-23.1.1 txtorcon-23.0.0 zope.interface-6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wormhole send best_vgg16_bnmodel.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1wGR9PLfoBq",
        "outputId": "f4b999bb-72d0-4b83-863e-53b4b0403fff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sending 553.6 MB file named 'best_vgg16_bnmodel.pt'\n",
            "Wormhole code is: 5-gadgetry-cubic\n",
            "On the other computer, please run:\n",
            "\n",
            "wormhole receive 5-gadgetry-cubic\n",
            "\n",
            "Sending (->relay:tcp:magic-wormhole-transit.debian.net:4001)..\n",
            "100% 554M/554M [00:59<00:00, 9.34MB/s]\n",
            "File sent.. waiting for confirmation\n",
            "Confirmation received. Transfer complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Try VGG19"
      ],
      "metadata": {
        "id": "03fTagr2akM1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft = models.vgg19_bn(weights=\"DEFAULT\")\n",
        "# num_ftrs = model_ft.fc.in_features\n",
        "num_ftrs = model_ft.classifier[6].in_features # the 6 gets me to the linear layer of VGG\n",
        "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
        "model_ft.fc = nn.Linear(num_ftrs, 5)\n",
        "\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.0001)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "7bf5900fb3b44cb992c74dbafc64229f",
            "4be8e338641f45188bc72a9ccdcdf82e",
            "53f6c856bc7e4ccb8279597ce6fad0b5",
            "cd449605f18346d68224e0c4cb20ae89",
            "3238da51c33645b492a1e8cbdfe09ce0",
            "06d17cf925fa445996845b347c8961cd",
            "b22c0503622444f6b8ecbe144b29313c",
            "76571277318e4940a4c50266c2722d68",
            "6f2550717e2e4345b63a45cb8d23e090",
            "829b84e6701645ffbeeae9dfa61edcb9",
            "8b804fa629994e5cbec910e9747ea67f"
          ]
        },
        "id": "hHQIBAHbxjrK",
        "outputId": "fd8a3911-53f6-4b2b-d26d-abe37e0377a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg19_bn-c79401a0.pth\" to /root/.cache/torch/hub/checkpoints/vgg19_bn-c79401a0.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7bf5900fb3b44cb992c74dbafc64229f"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
        "                       num_epochs=25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XhVaHkYI8CgH",
        "outputId": "ee31faed-f2e8-4973-ecd4-6299b7cf31fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/24\n",
            "----------\n",
            "train Loss: 1.3203 Acc: 0.5078\n",
            "val Loss: 0.7889 Acc: 0.7059\n",
            "\n",
            "Epoch 1/24\n",
            "----------\n",
            "train Loss: 0.7750 Acc: 0.7016\n",
            "val Loss: 0.6421 Acc: 0.7390\n",
            "\n",
            "Epoch 2/24\n",
            "----------\n",
            "train Loss: 0.6871 Acc: 0.7305\n",
            "val Loss: 0.6540 Acc: 0.7574\n",
            "\n",
            "Epoch 3/24\n",
            "----------\n",
            "train Loss: 0.6319 Acc: 0.7554\n",
            "val Loss: 0.5077 Acc: 0.8143\n",
            "\n",
            "Epoch 4/24\n",
            "----------\n",
            "train Loss: 0.5956 Acc: 0.7740\n",
            "val Loss: 0.8488 Acc: 0.7188\n",
            "\n",
            "Epoch 5/24\n",
            "----------\n",
            "train Loss: 0.5681 Acc: 0.7798\n",
            "val Loss: 0.5402 Acc: 0.7794\n",
            "\n",
            "Epoch 6/24\n",
            "----------\n",
            "train Loss: 0.5116 Acc: 0.8061\n",
            "val Loss: 0.5025 Acc: 0.8033\n",
            "\n",
            "Epoch 7/24\n",
            "----------\n",
            "train Loss: 0.4956 Acc: 0.8076\n",
            "val Loss: 0.6144 Acc: 0.7776\n",
            "\n",
            "Epoch 8/24\n",
            "----------\n",
            "train Loss: 0.4627 Acc: 0.8213\n",
            "val Loss: 0.5654 Acc: 0.7978\n",
            "\n",
            "Epoch 9/24\n",
            "----------\n",
            "train Loss: 0.4617 Acc: 0.8297\n",
            "val Loss: 0.6648 Acc: 0.7408\n",
            "\n",
            "Epoch 10/24\n",
            "----------\n",
            "train Loss: 0.3644 Acc: 0.8677\n",
            "val Loss: 0.4999 Acc: 0.8125\n",
            "\n",
            "Epoch 11/24\n",
            "----------\n",
            "train Loss: 0.3301 Acc: 0.8779\n",
            "val Loss: 0.5163 Acc: 0.8180\n",
            "\n",
            "Epoch 12/24\n",
            "----------\n",
            "train Loss: 0.3140 Acc: 0.8824\n",
            "val Loss: 0.5244 Acc: 0.8033\n",
            "\n",
            "Epoch 13/24\n",
            "----------\n",
            "train Loss: 0.2775 Acc: 0.8982\n",
            "val Loss: 0.5663 Acc: 0.8033\n",
            "\n",
            "Epoch 14/24\n",
            "----------\n",
            "train Loss: 0.2765 Acc: 0.8988\n",
            "val Loss: 0.5445 Acc: 0.8070\n",
            "\n",
            "Epoch 15/24\n",
            "----------\n",
            "train Loss: 0.2392 Acc: 0.9170\n",
            "val Loss: 0.5736 Acc: 0.8088\n",
            "\n",
            "Epoch 16/24\n",
            "----------\n",
            "train Loss: 0.2401 Acc: 0.9110\n",
            "val Loss: 0.5796 Acc: 0.8180\n",
            "\n",
            "Epoch 17/24\n",
            "----------\n",
            "train Loss: 0.2203 Acc: 0.9252\n",
            "val Loss: 0.5836 Acc: 0.8180\n",
            "\n",
            "Epoch 18/24\n",
            "----------\n",
            "train Loss: 0.2170 Acc: 0.9235\n",
            "val Loss: 0.6096 Acc: 0.8235\n",
            "\n",
            "Epoch 19/24\n",
            "----------\n",
            "train Loss: 0.1841 Acc: 0.9350\n",
            "val Loss: 0.6155 Acc: 0.8125\n",
            "\n",
            "Epoch 20/24\n",
            "----------\n",
            "train Loss: 0.1976 Acc: 0.9337\n",
            "val Loss: 0.5996 Acc: 0.8199\n",
            "\n",
            "Epoch 21/24\n",
            "----------\n",
            "train Loss: 0.1936 Acc: 0.9297\n",
            "val Loss: 0.5994 Acc: 0.8162\n",
            "\n",
            "Epoch 22/24\n",
            "----------\n",
            "train Loss: 0.1898 Acc: 0.9319\n",
            "val Loss: 0.5964 Acc: 0.8235\n",
            "\n",
            "Epoch 23/24\n",
            "----------\n",
            "train Loss: 0.1945 Acc: 0.9286\n",
            "val Loss: 0.6054 Acc: 0.8199\n",
            "\n",
            "Epoch 24/24\n",
            "----------\n",
            "train Loss: 0.1830 Acc: 0.9356\n",
            "val Loss: 0.6027 Acc: 0.8199\n",
            "\n",
            "Training complete in 46m 4s\n",
            "Best val Acc: 0.823529\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "torch.save(model_ft.state_dict(), save_models_dir+'best_vgg19_bn_model.pt')"
      ],
      "metadata": {
        "id": "jA5OetOL9mBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Try EfficientNet"
      ],
      "metadata": {
        "id": "q7t__QCm2eCK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "efficentnet_model = models.efficientnet_b4(weights=\"DEFAULT\")\n",
        "num_ftrs = efficentnet_model.classifier[1].in_features\n",
        "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
        "efficentnet_model.fc = nn.Linear(num_ftrs, 5)\n",
        "\n",
        "efficentnet_model = efficentnet_model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.Adam(efficentnet_model.parameters(), lr=0.0001)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every (step_size) epochs\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)# Save the best model"
      ],
      "metadata": {
        "id": "KvqmKFVI2gtR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87,
          "referenced_widgets": [
            "81d5653d9a354a5e8d289833502ce9e3",
            "d191500ce3744b799fa3b3981045edf2",
            "a9dfbd6ecd204187b05ead23e91c70b6",
            "171edc66d92d4482b679175ea3f5256d",
            "b3f8b706919840a0873c6438349df4f9",
            "29d5a8543f6e435ca3d13d62462aab72",
            "e92d8c4542b3409eab4ee6ff8e2ffe17",
            "158c50f9acdf466c935c8dd6632deeac",
            "ac8c5d29f57a4c6a8d57d57ba9160f5e",
            "e345a5e19e16451c9fc6889a9ad2085d",
            "9e983ade7c6445579c81d68e8651758e"
          ]
        },
        "outputId": "bd5fd49a-6aa9-4e80-f0b3-73359ebd1a4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b4_rwightman-7eb33cd5.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b4_rwightman-7eb33cd5.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/74.5M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "81d5653d9a354a5e8d289833502ce9e3"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "efficentnet_model = train_model(efficentnet_model, criterion, optimizer_ft, exp_lr_scheduler,\n",
        "                       num_epochs=25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "LIVRx7_GeC8Z",
        "outputId": "608b86f5-1d0c-41f4-e3fa-0f6a14fd2c94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/24\n",
            "----------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-d9e00a544a72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m efficentnet_model = train_model(efficentnet_model, criterion, optimizer_ft, exp_lr_scheduler,\n\u001b[0m\u001b[1;32m      2\u001b[0m                        num_epochs=25)\n",
            "\u001b[0;32m<ipython-input-24-93acec95e350>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     37\u001b[0m                 \u001b[0;31m# track history if only in train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m                     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m                     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/models/efficientnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/models/efficientnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavgpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/models/efficientnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_res_connect\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstochastic_depth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msilu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    397\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36msilu\u001b[0;34m(input, inplace)\u001b[0m\n\u001b[1;32m   2056\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msilu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2057\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2058\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msilu_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2059\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msilu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 74.00 MiB (GPU 0; 14.75 GiB total capacity; 13.18 GiB already allocated; 16.81 MiB free; 13.62 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Ensemble"
      ],
      "metadata": {
        "id": "q9TwnMT_MHUZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make sure to adjust the output features of the desired models"
      ],
      "metadata": {
        "id": "-HzVV8qfZHhx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EnsembleModel(nn.Module):   \n",
        "    def __init__(self, modelA, modelB, modelC):\n",
        "        super().__init__()\n",
        "        self.modelA = modelA\n",
        "        self.modelB = modelB\n",
        "        self.modelC = modelC\n",
        "        self.classifier = nn.Linear(5 * 3, 5) # 5 output classes\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x1 = self.modelA(x)\n",
        "        x2 = self.modelB(x)\n",
        "        x3 = self.modelC(x)\n",
        "        x = torch.cat((x1, x2, x3), dim=1)\n",
        "        out = self.classifier(x)\n",
        "        return out"
      ],
      "metadata": {
        "id": "AbMJFoJIMO9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ResNet50\n",
        "resnet50_model = models.resnet50(weights=\"DEFAULT\")\n",
        "num_ftrs = resnet50_model.fc.in_features\n",
        "resnet50_model.fc = nn.Linear(num_ftrs, 5)\n",
        "\n",
        "# VGG16_BN\n",
        "vgg16_bn_model = models.vgg16_bn(weights=\"DEFAULT\")\n",
        "num_ftrs = vgg16_bn_model.classifier[6].in_features\n",
        "vgg16_bn_model.fc = nn.Linear(num_ftrs, 5)\n",
        "\n",
        "ensemble_model = EnsembleModel()"
      ],
      "metadata": {
        "id": "GPRNN9iXQLGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Entry Submissions"
      ],
      "metadata": {
        "id": "rIDySUirgqDd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_test(model):\n",
        "  results = {}\n",
        "  \n",
        "  model.to(device)\n",
        "  with torch.no_grad():\n",
        "    for i, (inputs, labels) in enumerate(dataloaders['test']):\n",
        "      inputs = inputs.to(device)\n",
        "      # labels = labels.to(device)\n",
        "      # print(len(labels))\n",
        "\n",
        "      outputs = model(inputs)\n",
        "      _, preds = torch.max(outputs, 1)\n",
        "\n",
        "      # print(preds)\n",
        "      preds_list = [num_labels[x.item()] for x in preds]\n",
        "      # print(len(preds_list))\n",
        "\n",
        "      for i in range(len(labels)):\n",
        "        results[labels[i]] = preds_list[i]\n",
        "\n",
        "  return results\n",
        "\n",
        "      # num_labels[x.item()]"
      ],
      "metadata": {
        "id": "gB9w9ef5hqYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ResNet50 with normalization and lr 0.0005"
      ],
      "metadata": {
        "id": "6oA-rRQP5MhX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet50()\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 5)\n",
        "\n",
        "model.load_state_dict(torch.load(save_models_dir+'best_resnet50_dsnormalized_lrincr.pt'))\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Scvy8EyS5Rq2",
        "outputId": "9278ce5a-07d8-4b39-f93c-b79691db7550"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=2048, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = model_test(model)\n",
        "submission_df = pd.DataFrame.from_dict(results, orient=\"index\",\n",
        "                                       columns=[\"label\"])\n",
        "submission_df = submission_df.reset_index()\n",
        "submission_df = submission_df.rename({\"index\":\"id\"}, axis=\"columns\")\n",
        "submission_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "rGDATj9v5kKM",
        "outputId": "06a0ef4e-5d4d-4ad1-cfdf-87722e90fd2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           id       label\n",
              "0     P100000  background\n",
              "1     P100001    calc_ben\n",
              "2     P100002  background\n",
              "3     P100003    mass_ben\n",
              "4     P100004    mass_ben\n",
              "...       ...         ...\n",
              "1230  P101230    mass_ben\n",
              "1231  P101231    calc_ben\n",
              "1232  P101232  background\n",
              "1233  P101233  background\n",
              "1234  P101234    calc_ben\n",
              "\n",
              "[1235 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0e76713e-7dbc-481b-a821-00f8e87321ab\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>P100000</td>\n",
              "      <td>background</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>P100001</td>\n",
              "      <td>calc_ben</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>P100002</td>\n",
              "      <td>background</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>P100003</td>\n",
              "      <td>mass_ben</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>P100004</td>\n",
              "      <td>mass_ben</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1230</th>\n",
              "      <td>P101230</td>\n",
              "      <td>mass_ben</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1231</th>\n",
              "      <td>P101231</td>\n",
              "      <td>calc_ben</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1232</th>\n",
              "      <td>P101232</td>\n",
              "      <td>background</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1233</th>\n",
              "      <td>P101233</td>\n",
              "      <td>background</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1234</th>\n",
              "      <td>P101234</td>\n",
              "      <td>calc_ben</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1235 rows √ó 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0e76713e-7dbc-481b-a821-00f8e87321ab')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0e76713e-7dbc-481b-a821-00f8e87321ab button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0e76713e-7dbc-481b-a821-00f8e87321ab');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save to two places - Google Drive and content\n",
        "submission_df.to_csv(save_models_dir+'submissions/resnet50dsnorm_incrlr_submission.csv',\n",
        "                    index=False)\n",
        "\n",
        "submission_df.to_csv('/content/submission.csv',\n",
        "                    index=False)"
      ],
      "metadata": {
        "id": "eOj7J4Ng5yGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ResNet50 with normalization"
      ],
      "metadata": {
        "id": "iYgULgj06z_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet50()\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 5)\n",
        "\n",
        "model.load_state_dict(torch.load(save_models_dir+'best_resnet50_dsnormalized.pt'))\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd16349d-3359-4ab0-decc-4747ed4f5f44",
        "id": "6AkrtVs16z_s"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=2048, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = model_test(model)\n",
        "submission_df = pd.DataFrame.from_dict(results, orient=\"index\",\n",
        "                                       columns=[\"label\"])\n",
        "submission_df = submission_df.reset_index()\n",
        "submission_df = submission_df.rename({\"index\":\"id\"}, axis=\"columns\")\n",
        "submission_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "1a4adf09-8056-4f3a-9b64-051ef127b179",
        "id": "s_nhTwc76z_u"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           id       label\n",
              "0     P100000  background\n",
              "1     P100001  background\n",
              "2     P100002  background\n",
              "3     P100003    mass_ben\n",
              "4     P100004  background\n",
              "...       ...         ...\n",
              "1230  P101230    mass_ben\n",
              "1231  P101231    calc_ben\n",
              "1232  P101232    calc_mal\n",
              "1233  P101233  background\n",
              "1234  P101234    calc_ben\n",
              "\n",
              "[1235 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8b37e584-f099-4a9e-b2c7-cc4400521db3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>P100000</td>\n",
              "      <td>background</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>P100001</td>\n",
              "      <td>background</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>P100002</td>\n",
              "      <td>background</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>P100003</td>\n",
              "      <td>mass_ben</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>P100004</td>\n",
              "      <td>background</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1230</th>\n",
              "      <td>P101230</td>\n",
              "      <td>mass_ben</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1231</th>\n",
              "      <td>P101231</td>\n",
              "      <td>calc_ben</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1232</th>\n",
              "      <td>P101232</td>\n",
              "      <td>calc_mal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1233</th>\n",
              "      <td>P101233</td>\n",
              "      <td>background</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1234</th>\n",
              "      <td>P101234</td>\n",
              "      <td>calc_ben</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1235 rows √ó 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8b37e584-f099-4a9e-b2c7-cc4400521db3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8b37e584-f099-4a9e-b2c7-cc4400521db3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8b37e584-f099-4a9e-b2c7-cc4400521db3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save to two places - Google Drive and content\n",
        "submission_df.to_csv(save_models_dir+'submissions/resnet50dsnorm_submission.csv',\n",
        "                    index=False)\n",
        "\n",
        "submission_df.to_csv('/content/submission.csv',\n",
        "                    index=False)"
      ],
      "metadata": {
        "id": "OPCG4Z0W6z_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## VGG16_BN"
      ],
      "metadata": {
        "id": "dv9EOmZgAW6I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.vgg16_bn(weights=\"DEFAULT\")\n",
        "num_ftrs = model.classifier[6].in_features # the 6 gets me to the linear layer of VGG\n",
        "model.fc = nn.Linear(num_ftrs, 5)\n",
        "\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/ML for BDS/Hackathon - graddiss/best_vgg16_bnmodel_Adam_balanced.pt'))\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XggdLFyIhDU6",
        "outputId": "88e7b049-e60b-4e62-fdb0-f8dddd03e4ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (7): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (9): ReLU(inplace=True)\n",
              "    (10): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (12): ReLU(inplace=True)\n",
              "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (14): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (16): ReLU(inplace=True)\n",
              "    (17): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (19): ReLU(inplace=True)\n",
              "    (20): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (26): ReLU(inplace=True)\n",
              "    (27): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (32): ReLU(inplace=True)\n",
              "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (36): ReLU(inplace=True)\n",
              "    (37): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (39): ReLU(inplace=True)\n",
              "    (40): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (42): ReLU(inplace=True)\n",
              "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "  )\n",
              "  (fc): Linear(in_features=4096, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = model_test(model)"
      ],
      "metadata": {
        "id": "Le6gwcPPxEB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission_df = pd.DataFrame.from_dict(results, orient=\"index\",\n",
        "                                       columns=[\"label\"])\n",
        "submission_df = submission_df.reset_index()\n",
        "submission_df = submission_df.rename({\"index\":\"id\"}, axis=\"columns\")\n",
        "submission_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "ryQcLhiUo4_K",
        "outputId": "0cde969b-1b4e-4d4c-b444-99b330260676"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           id       label\n",
              "0     P100000  background\n",
              "1     P100001  background\n",
              "2     P100002  background\n",
              "3     P100003    mass_ben\n",
              "4     P100004  background\n",
              "...       ...         ...\n",
              "1230  P101230    calc_mal\n",
              "1231  P101231    calc_ben\n",
              "1232  P101232  background\n",
              "1233  P101233  background\n",
              "1234  P101234    calc_ben\n",
              "\n",
              "[1235 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ca75461c-02ac-4de6-8ec9-bcee7e6835a2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>P100000</td>\n",
              "      <td>background</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>P100001</td>\n",
              "      <td>background</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>P100002</td>\n",
              "      <td>background</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>P100003</td>\n",
              "      <td>mass_ben</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>P100004</td>\n",
              "      <td>background</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1230</th>\n",
              "      <td>P101230</td>\n",
              "      <td>calc_mal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1231</th>\n",
              "      <td>P101231</td>\n",
              "      <td>calc_ben</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1232</th>\n",
              "      <td>P101232</td>\n",
              "      <td>background</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1233</th>\n",
              "      <td>P101233</td>\n",
              "      <td>background</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1234</th>\n",
              "      <td>P101234</td>\n",
              "      <td>calc_ben</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1235 rows √ó 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ca75461c-02ac-4de6-8ec9-bcee7e6835a2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ca75461c-02ac-4de6-8ec9-bcee7e6835a2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ca75461c-02ac-4de6-8ec9-bcee7e6835a2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save to two places - Google Drive and content\n",
        "submission_df.to_csv('/content/drive/MyDrive/ML for BDS/Hackathon - graddiss/submissions/submission.csv',\n",
        "                    index=False)\n",
        "\n",
        "submission_df.to_csv('/content/submission.csv',\n",
        "                    index=False)"
      ],
      "metadata": {
        "id": "dYyNEGBw4Oqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !kaggle competitions submit -c mammography-image-patch-classification-2023 -f submission.csv -m \"GradientDissenters - 03212023\""
      ],
      "metadata": {
        "id": "HbIGShd8g8WD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b968c5e2-a961-498b-f44d-07e00b50d68b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 21.7k/21.7k [00:03<00:00, 6.65kB/s]\n",
            "Successfully submitted to Mammography image patch classification 2023"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ResNet50 multistage"
      ],
      "metadata": {
        "id": "MM-SJANrAdlX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet50(weights=\"DEFAULT\")\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 5)\n",
        "\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/ML for BDS/Hackathon - graddiss/best_resnet50_multistage_train.pt'))\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzTCTbH0AhOK",
        "outputId": "b74a8824-ca4d-4948-d4df-a419218d9a83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=2048, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = model_test(model)"
      ],
      "metadata": {
        "id": "Vd3vvGmdBvpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission_df = pd.DataFrame.from_dict(results, orient=\"index\",\n",
        "                                       columns=[\"label\"])\n",
        "submission_df = submission_df.reset_index()\n",
        "submission_df = submission_df.rename({\"index\":\"id\"}, axis=\"columns\")\n",
        "submission_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Awebazz3Bx-a",
        "outputId": "4f83d7ed-62fd-4a41-e69b-3187164bcc8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           id       label\n",
              "0     P100000  background\n",
              "1     P100001    calc_ben\n",
              "2     P100002  background\n",
              "3     P100003    mass_ben\n",
              "4     P100004  background\n",
              "...       ...         ...\n",
              "1230  P101230    mass_ben\n",
              "1231  P101231    mass_ben\n",
              "1232  P101232    calc_mal\n",
              "1233  P101233  background\n",
              "1234  P101234    calc_ben\n",
              "\n",
              "[1235 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-298dd4b0-a0d3-4dc4-8a73-5e465cd418e0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>P100000</td>\n",
              "      <td>background</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>P100001</td>\n",
              "      <td>calc_ben</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>P100002</td>\n",
              "      <td>background</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>P100003</td>\n",
              "      <td>mass_ben</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>P100004</td>\n",
              "      <td>background</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1230</th>\n",
              "      <td>P101230</td>\n",
              "      <td>mass_ben</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1231</th>\n",
              "      <td>P101231</td>\n",
              "      <td>mass_ben</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1232</th>\n",
              "      <td>P101232</td>\n",
              "      <td>calc_mal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1233</th>\n",
              "      <td>P101233</td>\n",
              "      <td>background</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1234</th>\n",
              "      <td>P101234</td>\n",
              "      <td>calc_ben</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1235 rows √ó 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-298dd4b0-a0d3-4dc4-8a73-5e465cd418e0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-298dd4b0-a0d3-4dc4-8a73-5e465cd418e0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-298dd4b0-a0d3-4dc4-8a73-5e465cd418e0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save to two places - Google Drive and content\n",
        "submission_df.to_csv('/content/drive/MyDrive/ML for BDS/Hackathon - graddiss/submissions/resnet50_submission.csv',\n",
        "                    index=False)\n",
        "\n",
        "submission_df.to_csv('/content/submission.csv',\n",
        "                    index=False)"
      ],
      "metadata": {
        "id": "WSqE9DcRB6Z7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ResNet50 - 90/10 train/val"
      ],
      "metadata": {
        "id": "UcJJ38S6cWbJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet50()\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 5)\n",
        "\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/ML for BDS/Hackathon - graddiss/best_resnet50_balanced_AdamOptim.pt'))\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQ-IIGdPcU-P",
        "outputId": "f6606185-9aa7-46f3-d590-698825e65585"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=2048, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = model_test(model)"
      ],
      "metadata": {
        "id": "qemCx2uqct_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission_df = pd.DataFrame.from_dict(results, orient=\"index\",\n",
        "                                       columns=[\"label\"])\n",
        "submission_df = submission_df.reset_index()\n",
        "submission_df = submission_df.rename({\"index\":\"id\"}, axis=\"columns\")\n",
        "submission_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "zSJ2Q_bOc-3C",
        "outputId": "2e1203e1-24de-44da-8122-be6a997590c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           id       label\n",
              "0     P100000  background\n",
              "1     P100001  background\n",
              "2     P100002  background\n",
              "3     P100003    mass_ben\n",
              "4     P100004  background\n",
              "...       ...         ...\n",
              "1230  P101230    mass_ben\n",
              "1231  P101231    calc_ben\n",
              "1232  P101232    calc_mal\n",
              "1233  P101233  background\n",
              "1234  P101234    calc_ben\n",
              "\n",
              "[1235 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d8241dac-5dca-4def-a857-d2a6149af616\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>P100000</td>\n",
              "      <td>background</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>P100001</td>\n",
              "      <td>background</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>P100002</td>\n",
              "      <td>background</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>P100003</td>\n",
              "      <td>mass_ben</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>P100004</td>\n",
              "      <td>background</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1230</th>\n",
              "      <td>P101230</td>\n",
              "      <td>mass_ben</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1231</th>\n",
              "      <td>P101231</td>\n",
              "      <td>calc_ben</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1232</th>\n",
              "      <td>P101232</td>\n",
              "      <td>calc_mal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1233</th>\n",
              "      <td>P101233</td>\n",
              "      <td>background</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1234</th>\n",
              "      <td>P101234</td>\n",
              "      <td>calc_ben</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1235 rows √ó 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d8241dac-5dca-4def-a857-d2a6149af616')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d8241dac-5dca-4def-a857-d2a6149af616 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d8241dac-5dca-4def-a857-d2a6149af616');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save to two places - Google Drive and content\n",
        "submission_df.to_csv('/content/drive/MyDrive/ML for BDS/Hackathon - graddiss/submissions/resnet50_90_10_submission.csv',\n",
        "                    index=False)\n",
        "\n",
        "submission_df.to_csv('/content/submission.csv',\n",
        "                    index=False)"
      ],
      "metadata": {
        "id": "P_412KQ_dM4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Multi-stage ResNet"
      ],
      "metadata": {
        "id": "YvuS1FSQ6g65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.resnet50()\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 5)\n",
        "\n",
        "model.load_state_dict(torch.load(save_models_dir + \"best_resnet50_multistage_train.pt\"))\n",
        "model.eval()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osYn2UJx6jfr",
        "outputId": "0611b6bb-99a2-4f5c-fb7c-c63d3d7e0796"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): Bottleneck(\n",
              "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Bottleneck(\n",
              "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=2048, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = model_test(model)"
      ],
      "metadata": {
        "id": "T2iF-U9A60zJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission_df = pd.DataFrame.from_dict(results, orient=\"index\",\n",
        "                                       columns=[\"label\"])\n",
        "submission_df = submission_df.reset_index()\n",
        "submission_df = submission_df.rename({\"index\":\"id\"}, axis=\"columns\")\n",
        "submission_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "WJCXq4Qe6_1j",
        "outputId": "1560f683-55ab-4c35-d765-d3c6f64758bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           id       label\n",
              "0     P100000  background\n",
              "1     P100001    calc_ben\n",
              "2     P100002  background\n",
              "3     P100003    mass_ben\n",
              "4     P100004  background\n",
              "...       ...         ...\n",
              "1230  P101230    mass_ben\n",
              "1231  P101231    mass_ben\n",
              "1232  P101232    calc_mal\n",
              "1233  P101233  background\n",
              "1234  P101234    calc_ben\n",
              "\n",
              "[1235 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7dd9ae3f-4ba6-4698-96b3-7c86c6657efc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>P100000</td>\n",
              "      <td>background</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>P100001</td>\n",
              "      <td>calc_ben</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>P100002</td>\n",
              "      <td>background</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>P100003</td>\n",
              "      <td>mass_ben</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>P100004</td>\n",
              "      <td>background</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1230</th>\n",
              "      <td>P101230</td>\n",
              "      <td>mass_ben</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1231</th>\n",
              "      <td>P101231</td>\n",
              "      <td>mass_ben</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1232</th>\n",
              "      <td>P101232</td>\n",
              "      <td>calc_mal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1233</th>\n",
              "      <td>P101233</td>\n",
              "      <td>background</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1234</th>\n",
              "      <td>P101234</td>\n",
              "      <td>calc_ben</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1235 rows √ó 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7dd9ae3f-4ba6-4698-96b3-7c86c6657efc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7dd9ae3f-4ba6-4698-96b3-7c86c6657efc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7dd9ae3f-4ba6-4698-96b3-7c86c6657efc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save to two places - Google Drive and content\n",
        "submission_df.to_csv('/content/drive/MyDrive/ML for BDS/Hackathon - graddiss/submissions/resnet50_multistage_submission.csv',\n",
        "                    index=False)\n",
        "\n",
        "submission_df.to_csv('/content/submission.csv',\n",
        "                    index=False)"
      ],
      "metadata": {
        "id": "-lwf0pUG7E_u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}